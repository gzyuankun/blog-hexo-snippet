{"meta":{"title":"勾三股四","subtitle":"","description":"","author":"yuan kun","url":"http://snippet.itshare.work"},"pages":[{"title":"categories","date":"2023-02-14T09:02:11.000Z","updated":"2023-02-14T12:44:12.396Z","comments":true,"path":"categories/index.html","permalink":"http://snippet.itshare.work/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2023-02-14T09:02:18.000Z","updated":"2023-02-14T12:39:03.346Z","comments":true,"path":"tags/index.html","permalink":"http://snippet.itshare.work/tags/index.html","excerpt":"","text":""},{"title":"关于作者","date":"2022-07-07T14:34:43.000Z","updated":"2022-12-17T04:19:25.902Z","comments":true,"path":"about/index.html","permalink":"http://snippet.itshare.work/about/index.html","excerpt":"","text":"关于博客为什么我要搭建这个博客呢？ 因为生命在于折腾 因为平时学习查找资料的时候，偶尔会发现一些非常精致的个人网站，那个时候就在想，什么时候俺也要整一个，然后用来写博客 。无奈由于各种原因 (懒)，一直没有捡起来，后来总算是找到一个不错的应用，折腾着建起来了，也打算督促自己克服懒癌，来记录一些东西。"}],"posts":[{"title":"Docker镜像加速","slug":"Docker镜像加速","date":"2023-03-07T10:45:45.000Z","updated":"2023-03-07T11:18:04.688Z","comments":true,"path":"2023/03/07/Docker镜像加速/","link":"","permalink":"http://snippet.itshare.work/2023/03/07/Docker%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F/","excerpt":"国内从DockerHub拉取镜像有时会遇到困难，此时可以配置镜像加速器。Docker官方和国内很多云服务商都提供了国内加速器服务，建议根据运行docker的云平台选择对应的镜像加速服务。","text":"Docker 镜像加速配置国内从DockerHub拉取镜像有时会遇到困难，此时可以配置镜像加速器。 Docker官方和国内很多云服务商都提供了国内加速器服务，建议根据运行docker的云平台选择对应的镜像加速服务。 下面列出国内常用的加速站点，排名不分先后,总体来说阿里云速度较稳定。 docker中国区官方镜像加速： 1https://registry.docker-cn.com 网易镜像加速： 1http://hub-mirror.c.163.com 中国科技大学镜像加速： 1https://docker.mirrors.ustc.edu.cn 腾讯云镜像加速： 1https://mirror.ccs.tencentyun.com 阿里云镜像加速： 1https://ung2thfc.mirror.aliyuncs.com 修改daemon配置文件&#x2F;etc&#x2F;docker&#x2F;daemon.json来使用加速器 1/etc/docker/daemon.json 加入如下内容 12345678&#123;&quot;registry-mirrors&quot;: [ &quot;https://ung2thfc.mirror.aliyuncs.com&quot;, &quot;https://mirror.ccs.tencentyun.com&quot;, &quot;https://registry.docker-cn.com&quot;, &quot;http://hub-mirror.c.163.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;]&#125; 加载重启docker 在终端输入以下命令 123systemctl daemon-reloadsystemctl restart docker 打开终端执行docker info命令，可见下面信息 123456789101112....Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: https://ung2thfc.mirror.aliyuncs.com/ https://mirror.ccs.tencentyun.com/ https://registry.docker-cn.com/ http://hub-mirror.c.163.com/ https://docker.mirrors.ustc.edu.cn/Live Restore Enabled: false 还可以使用如下脚本进行设置，执行前检查自己的环境,下列脚本可以用于新装Docker环境的机器 123456789101112#!/bin/bashtee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123;&quot;registry-mirrors&quot;: [ &quot;https://ung2thfc.mirror.aliyuncs.com&quot;, &quot;https://mirror.ccs.tencentyun.com&quot;, &quot;https://registry.docker-cn.com&quot;, &quot;http://hub-mirror.c.163.com&quot;, &quot;https://docker.mirrors.ustc.edu.cn&quot;]&#125;EOFsystemctl daemon-reload &amp;&amp; systemctl restart docker","categories":[{"name":"Docker","slug":"Docker","permalink":"http://snippet.itshare.work/categories/Docker/"}],"tags":[],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://snippet.itshare.work/categories/Docker/"}]},{"title":"Docker安装部署","slug":"docker-install","date":"2023-03-07T06:36:10.000Z","updated":"2023-03-07T11:31:50.443Z","comments":true,"path":"2023/03/07/docker-install/","link":"","permalink":"http://snippet.itshare.work/2023/03/07/docker-install/","excerpt":"Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。","text":"安装和删除方法官方文档 : https://docs.docker.com/engine/install/阿里云文档: https://developer.aliyun.com/mirror/docker-ce?spm=a2c6h.13651102.0.0.3e221b11gu Ubuntu 安装和删除Docker官方文档: https://docs.docker.com/install/linux/docker-ce/ubuntu/ CentOS 安装和删除Docker官方文档: https://docs.docker.com/install/linux/docker-ce/centos/CentOS 6 因内核太旧，即使支持安装docker，但会有各种问题，不建议安装CentOS 7 的 extras 源虽然可以安装docker，但包比较旧，建议从官方源或镜像源站点下载安装dockerCentOS 8 有新技术 podman 代替 docker因此建议在CentOS 7 上安装 docker参考阿里云文档: https://developer.aliyun.com/mirror/docker-ce?spm=a2c6h.13651102.0.0.3e221b11gu 二进制安装本方法适用于无法上网或无法通过包安装方式安装的主机上安装docker安装文档: https://docs.docker.com/install/linux/docker-ce/binaries/ 二进制安装下载路径https://download.docker.com/linux/https://mirrors.aliyun.com/docker-ce/linux/static/stable/x86_64/ 范例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566wget https://mirrors.aliyun.com/docker-ce/linux/static/stable/x86_64/docker-20.10.10.tgz?spm=a2c6h.25603864.0.0.1caf15acK1B2NZ# 解压[root@centos7 src]# tar xf docker-20.10.10.tgz# tree[root@centos7 src]# tree.├── docker│ ├── containerd│ ├── containerd-shim│ ├── containerd-shim-runc-v2│ ├── ctr│ ├── docker│ ├── dockerd│ ├── docker-init│ ├── docker-proxy│ └── runc└── docker-20.10.10.tgz1 directory, 10 files[root@centos7 src]# # 添加环境变量[root@centos7 src]# ln -s /usr/local/src/docker/* /usr/bin/#启动dockerd服务[root@centos7 src]#dockerd &amp;&gt;/dev/null &amp;# 编写service文件[root@centos7 ~]# cat /lib/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target docker.socket firewalld.service containerd.service time-set.targetWants=network-online.target containerd.service[Service]Type=notifyExecStart=/usr/bin/dockerd -H unix://var/run/docker.sockExecReload=/bin/kill -s HUP $MAINPIDTimeoutStartSec=0RestartSec=2Restart=alwaysStartLimitBurst=3StartLimitInterval=60s# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinity# Comment TasksMax if your systemd version does not support it.# Only systemd 226 and above support this option.TasksMax=infinity# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=processOOMScoreAdjust=-500[Install]WantedBy=multi-user.target","categories":[{"name":"Docker","slug":"Docker","permalink":"http://snippet.itshare.work/categories/Docker/"}],"tags":[],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://snippet.itshare.work/categories/Docker/"}]},{"title":"Zabbix介绍和部署","slug":"Zabbix","date":"2023-03-02T07:07:46.000Z","updated":"2023-03-03T10:12:59.432Z","comments":true,"path":"2023/03/02/Zabbix/","link":"","permalink":"http://snippet.itshare.work/2023/03/02/Zabbix/","excerpt":"Zabbix是一个企业级解决方案，支持实时监控数千台服务器，虚拟机和网络设备，采集百万级监控指标，适用于任何IT基础架构、服务、应用程序和资源的解决方案","text":"常见监控方案开源监控软件：cacti、nagios、zabbix、smokeping、open-falcon等 Zabbix使用场景及系统概述Zabbix是一个企业级解决方案，支持实时监控数千台服务器，虚拟机和网络设备，采集百万级监控指标，适用于任何IT基础架构、服务、应用程序和资源的解决方案。 zabbix使用场景 zabbix系统概述 数据采集： 周期性时序数据 12主机/对象：服务器、路由器、交换机、存储、防火墙、IP、PORT、URL、自定义监控对象...采集目标：监控项，指标数据（metrics data） 数据存储： 监控数据存储系统 123SQL: MySQL/MariaDB(Zabbix)NoSQL：Redis(Open-falcon)rrd: Round Robin Database(Cacti) 数据类型： 123历史数据: 每个监控项采集到的每个监控值趋势数据: 趋势表里主要保留某个监控项一个小时内历史数据的最大值、最小值和平均值以及该监控项一个小时内所采集到的数据个数。 阈值：可按照预定义的阈值等级实现分层报警告警机制：email,短信,微信,语音,故障自治愈 zabbix 核心任务：数据采集： 数据采集方式：zabbix-server，zabbix-proxy，zabbix-agent 12Agentless：SNMP,Telnet,ssh, IPMI, JMX,Agent：zabbix agent 数据存储：zabbix database数据展示：zabbix web 1graph -&gt; screen -&gt; slideshow(将多个screen以幻灯片的方式进行轮流展示) grafana: 1以zabbix为数据源展示更绚丽的界面 告警通知： 12host (host groups) &lt;- templates #从模板继承告警配置host -&gt; items -&gt; triggers -&gt; action (条件-conditions, 操作-operations) #自定义告警配置 规划部署部署环境： 服务器系统：centos7.9，ubuntu20.04 yum安装zabbix 安装说明 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# Install Zabbix repositorywget https://repo.zabbix.com/zabbix/5.0/rhel/7/x86_64/zabbix-release-5.0-1.el7.noarch.rpmyum install zabbix-release-5.0-1.el7.noarch.rpmyum clean all# 安装Zabbix server，Web前端，agentyum install zabbix-server-mysql zabbix-agent# Install Zabbix frontend# Enable Red Hat Software Collectionsyum install centos-release-scl# 编辑配置文件 /etc/yum.repos.d/zabbix.repo and enable zabbix-frontend repository.[zabbix-frontend]...enabled=1...# Install Zabbix frontend packages.yum install zabbix-web-mysql-scl zabbix-nginx-conf-scl# 安装数据库# 在线一键安装脚本地址https://itshare.work/2022/09/30/MySQLinstallScript/# 创建初始数据库# Make sure you have database server up and running.# 在数据库主机上运行以下代码mysql -uroot -pmysql&gt; create database zabbix character set utf8 collate utf8_bin;Query OK, 1 row affected (0.01 sec)mysql&gt; create user zabbix@localhost identified by &#x27;123456&#x27;;Query OK, 0 rows affected (0.00 sec)mysql&gt; grant all privileges on zabbix.* to zabbix@localhost;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global log_bin_trust_function_creators = 1;Query OK, 0 rows affected (0.00 sec)mysql&gt; quit;# 导入初始架构和数据，系统将提示您输入新创建的密码。[root@centos7 ~]# zcat /usr/share/doc/zabbix-server-mysql-5.0.31/create.sql.gz | mysql -uzabbix -p123456 zabbix#Disable log_bin_trust_function_creators option after importing database schema.# mysql -uroot -ppasswordmysql&gt; set global log_bin_trust_function_creators = 0;mysql&gt; quit;#为Zabbix server配置数据库#编辑配置文件 /etc/zabbix/zabbix_server.confDBPassword=12456# 为 Zabbix前端配置PHP# 编辑配置文件 /etc/opt/rh/rh-nginx116/nginx/conf.d/zabbix.conf uncomment and set &#x27;listen&#x27; and &#x27;server_name&#x27; directives.# listen 80;# server_name example.com;# 编辑配置文件 /etc/opt/rh/rh-php72/php-fpm.d/zabbix.conf add nginx to listen.acl_users directive.listen.acl_users = apache,nginx# Then uncomment and set the right timezone for you.(取消注释，设置时区)php_value[date.timezone] = Asia/Shanghai# 启动Zabbix server和agent进程# 启动Zabbix server和agent进程，并为它们设置开机自启：# systemctl restart zabbix-server zabbix-agent rh-nginx116-nginx rh-php72-php-fpm# systemctl enable zabbix-server zabbix-agent rh-nginx116-nginx rh-php72-php-fpm 开始使用 1http://ip:port apt安装 Zabbix 5.0 LTS for Ubuntu 20.04 (Focal), MySQL, Apache 1234567891011121314151617181920212223242526272829303132333435363738394041424344# Install and configure Zabbix for your platform# a. Install Zabbix repositorywget https://repo.zabbix.com/zabbix/5.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_5.0-1%2Bfocal_all.debdpkg -i zabbix-release_5.0-1+focal_all.debapt update# 安装Zabbix server，Web前端，agentapt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf zabbix-agent# 安装数据库apt install mysql-server -y# 创建初始数据库# Make sure you have database server up and running.# 在数据库主机上运行以下代码。# mysql -uroot -ppasswordmysql&gt; create database zabbix character set utf8 collate utf8_bin;mysql&gt; create user zabbix@localhost identified by &#x27;123456&#x27;;mysql&gt; grant all privileges on zabbix.* to zabbix@localhost;mysql&gt; set global log_bin_trust_function_creators = 1;mysql&gt; quit;# 导入初始架构和数据，系统将提示您输入新创建的密码。zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p123456 zabbix# Disable log_bin_trust_function_creators option after importing database schema.# mysql -uroot -ppasswordmysql&gt; set global log_bin_trust_function_creators = 0;mysql&gt; quit;# 为Zabbix server配置数据库# 编辑配置文件 /etc/zabbix/zabbix_server.confDBPassword=123456# 为Zabbix前端配置PHP# 编辑配置文件 /etc/zabbix/apache.conf uncomment and set the right timezone for you.php_value date.timezone Asia/Shanghai# 动Zabbix server和agent进程# 启动Zabbix server和agent进程，并为它们设置开机自启：systemctl restart zabbix-server zabbix-agent apache2systemctl enable zabbix-server zabbix-agent apache2","categories":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://snippet.itshare.work/categories/Zabbix/"}],"tags":[],"keywords":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://snippet.itshare.work/categories/Zabbix/"}]},{"title":"运维自动化工具Ansible(二)","slug":"Ansible2","date":"2023-02-25T04:21:17.000Z","updated":"2023-02-27T13:39:07.329Z","comments":true,"path":"2023/02/25/Ansible2/","link":"","permalink":"http://snippet.itshare.work/2023/02/25/Ansible2/","excerpt":"Ansible 的名称来自科幻小说《安德的游戏》中跨越时空的即时通信工具，使用它可以在相距数光年的距离,远程实时控制前线的舰队战斗","text":"Playbookplaybook介绍官方链接 1https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html Playbook 组成 一个 playbook(剧本)文件是一个YAML语言编写的文本文件 通常一个playbook只包括一个play 一个 play的主要包括两部分: 主机和tasks. 即实现在指定一组主机上执行一个tasks定义好的任务列表。 一个tasks中可以有一个或多个task任务 每一个Task本质上就是调用ansible的一个module 在复杂场景中,一个playbook中也可以包括多个play，实现对多组不同的主机执行不同的任务 Playbook 与 Ad-Hoc 对比 Playbook是对多个 AD-Hoc 的一种编排组合的实现方式 Playbook能控制任务执行的先后顺序 Playbook可以持久保存到文件中从而方便多次调用运行，而Ad-Hoc只能临时运行。 Playbook适合复杂的重复性的任务，而Ad-Hoc适合做快速简单的一次性任务 YAML 语言YAML 语言介绍YAML：YAML Ain’t Markup Language，即YAML不是标记语言。不过，在开发的这种语言时，YAML的意思其实是：”Yet Another Markup Language”（仍是一种标记语言）YAML是一个可读性高的用来表达资料序列的格式。YAML参考了其他多种语言，包括：XML、C语言、Python、Perl以及电子邮件格式RFC2822等。Clark Evans在2001年在首次发表了这种语言，另外Ingy döt Net与Oren Ben-Kiki也是这语言的共同设计者目前很多最新的软件比较流行采用此格式的文件存放配置信息，如:ubuntu，anisble，docker，kubernetes等YAML 官方网站： 1http://www.yaml.org ansible 官网: 1https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html YAML 语言特性 YAML的可读性好 YAML和脚本语言的交互性好 YAML使用实现语言的数据类型 YAML有一个一致的信息模型 YAML易于实现 YAML可以基于流来处理 YAML表达能力强，扩展性好 YAML语法简介 在单一文件第一行，用连续三个连字号”-“ 开始，还有选择性的连续三个点号( … )用来表示文件结尾 次行开始正常写Playbook的内容，一般建议写明该Playbook的功能 使用#号注释代码 缩进的级别也必须是一致的，同样的缩进代表同样的级别，程序判别配置的级别是通过缩进结行来实现的 缩进不支持tab,必须使用空格进行缩进 缩进的空格数不重要，只要相同层级的元素左对齐即可 YAML文件内容是区别大小写的，key&#x2F;value的值均需大小写敏感 多个key&#x2F;value可同行写也可换行写，同行使用，分隔 key后面冒号要加一个空格 比如: key: value value可是个字符串，也可是另一个列表 YAML文件扩展名通常为yml或yaml 支持的数据类型YAML 支持以下常用几种数据类型： 标量：单个的、不可再分的值 对象：键值对的集合，又称为: 字典（dictionary）&#x2F; 哈希（hashes） &#x2F; 映射（mapping） 数组：一组按次序排列的值，又称为: 列表（list）&#x2F; 序列（sequence） scalar 标量key对应value 12name: wangage: 18 使用缩进的方式 1234name:wangage:18 标量是最基本的，不可再分的值，包括： 字符串 布尔值 整数 浮点数 Null 时间 日期 Dictionary 字典一个字典是由一个或多个key与value构成key和value之间用冒号 ：分隔冒号 : 后面有一个空格所有 k&#x2F;v 可以放在一行，,每个 k&#x2F;v 之间用逗号分隔所有每个 k&#x2F;v 也可以分别放在不同行,一对k&#x2F;v放在独立的一行格式 1account: &#123; name: wang, age: 30 &#125; 使用缩进方式 123account:name: wangage: 18 范例： 12345678#不同行# An employee recordname: Example Developerjob: Developerskill: Elite(社会精英)#同一行,也可以将key:value放置于&#123;&#125;中进行表示，用,分隔多个key:value# An employee record&#123;name: &quot;Example Developer&quot;, job: &quot;Developer&quot;, skill: &quot;Elite&quot;&#125; List 列表列表由多个元素组成每个元素放在不同行，每个元素一行,且元素前均使用中横线 - 开头，并且中横线 - 和元素之间有一个空格也可以将所有元素用 [ ] 括起来放在同一行,每个元素之间用逗号分隔格式 1course: [ linux , golang , python ] 也可以写成以 - 开头的多行 12345678course: - linux - golang - pythoncourse: - linux: manjaro - golang: gin - python: django 范例： 12345678#不同行,行以-开头,后面有一个空格# A list of tasty fruits- Apple- Orange- Strawberry- Mango#同一行[Apple,Orange,Strawberry,Mango] 范例：YAML 表示一个家庭 12345678910111213name: John Smithage: 41gender: Malespouse: &#123; name: Jane Smith, age: 37, gender: Female &#125; # 写在一行里 name: Jane Smith #也可以写成多行 age: 37 gender: Female children: [ &#123;name: Jimmy Smith,age: 17, gender: Male&#125;, &#123;name: Jenny Smith, age:13, gender: Female&#125;, &#123;name: hao Smith, age: 20, gender: Male &#125; ] #写在一行 - name: Jimmy Smith #写在多行,更为推荐的写法 age: 17 gender: Male - &#123;name: Jenny Smith, age: 13, gender: Female&#125; - &#123;name: hao Smith, age: 20, gender: Male &#125; 三种常见的数据格式 XML：Extensible Markup Language，可扩展标记语言，可用于数据交换和配置 JSON：JavaScript Object Notation, JavaScript 对象表记法，主要用来数据交换或配置，不支持注释 YAML：YAML Ain’t Markup Language YAML 不是一种标记语言， 主要用来配置，大小写敏感，不支持tab 可以用工具互相转换，参考网站：https://www.json2yaml.com/http://www.bejson.com/json/json2yaml/ Playbook 核心组件官方文档 1https://docs.ansible.com/ansible/latest/reference_appendices/playbooks_keywords.html#playbook-keywords 一个playbook 中由多个组件组成,其中所用到的常见组件类型如下: Hosts 执行的远程主机列表 Tasks 任务集,由多个task的元素组成的列表实现,每个task是一个字典,一个完整的代码块功能需少元素需包括 name 和 task,一个name只能包括一个task Variables 内置变量或自定义变量在playbook中调用 Templates 模板，可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers 和 notify 结合使用，由特定条件触发的操作，满足条件方才执行，否则不执行 tags 标签 指定某条任务执行，用于选择运行playbook中的部分代码。ansible具有幂等性，因此 会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会非常地长。此时，如果确信其没有变化，就可以通过tags跳过此些代码片断 hosts 组件Hosts：playbook中的每一个play的目的都是为了让特定主机以某个指定的用户身份执行任务。hosts用于指定要执行指定任务的主机，须事先定义在主机清单中 1234567one.example.comone.example.com:two.example.com192.168.1.50192.168.1.*Websrvs:dbsrvs #或者，两个组的并集Websrvs:&amp;dbsrvs #与，两个组的交集webservers:!dbsrvs #在websrvs组，但不在dbsrvs组 案例： 1- hosts: websrvs:appsrvs remote_user 组件remote_user: 可用于Host和task中。也可以通过指定其通过sudo的方式在远程主机上执行任务，其可用于play全局或某任务；此外，甚至可以在sudo时使用sudo_user指定sudo时切换的用户 12345678- hosts: websrvs remote_user: root tasks: - name: test connection ping: remote_user: magedu sudo: yes #默认sudo为root sudo_user:wang #sudo为wang task列表和action组件play的主体部分是task list，task list中有一个或多个task,各个task 按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个task后，再开始第二个tasktask的目的是使用指定的参数执行模块，而在模块参数中可以使用变量。模块执行是幂等的，这意味着多次执行是安全的，因为其结果均一致每个task都应该有其name，用于playbook的执行结果输出，建议其内容能清晰地描述任务执行步骤。如果未提供name，则action的结果将用于输出task两种格式： 12action: module arguments #示例: action: shell wall hellomodule: arguments #建议使用 #示例: shell: wall hello 注意：shell和command模块后面跟命令，而非key&#x3D;value范例: 1234567891011121314151617181920[root@ansible ansible]#cat hello.yml---#first yaml文件#- hosts: websrvs remote_user: root gather_facts: no tasks: - name: task1 debug: msg=&quot;task1 running&quot; - name: task2 debug: msg=&quot;task2 running&quot;- hosts: appsrvs remote_user: root gather_facts: no tasks: - name: task3 debug: msg=&quot;task3 running&quot; - name: task4 debug: msg=&quot;task4 running&quot; 其它组件说明某任务的状态在运行后为changed时，可通过”notify”通知给相应的handlers任务还可以通过”tags”给task 打标签，可在ansible-playbook命令上使用-t指定进行调用 ShellScripts VS Playbook 案例1234567891011121314151617181920212223#SHELL脚本实现#!/bin/bash# 安装Apacheyum install --quiet -y httpd# 复制配置文件cp /tmp/httpd.conf /etc/httpd/conf/httpd.confcp/tmp/vhosts.conf /etc/httpd/conf.d/# 启动Apache，并设置开机启动systemctl enable --now httpd#Playbook实现---- hosts: websrvs remote_user: root gather_facts: no tasks: - name: &quot;安装Apache&quot; yum: name=httpd - name: &quot;复制配置文件&quot; copy: src=/tmp/httpd.conf dest=/etc/httpd/conf/ - name: &quot;复制配置文件&quot; copy: src=/tmp/vhosts.conf dest=/etc/httpd/conf.d/ - name: &quot;启动Apache，并设置开机启动&quot; service: name=httpd state=started enabled=yes playbook 命令格式 1ansible-playbook &lt;filename.yml&gt; ... [options] 选项 123456789--syntax,--syntax-check #语法检查,功能相当于bash -n-C --check #模拟执行dry run ,只检测可能会发生的改变，但不真正执行操作--list-hosts #列出运行任务的主机--list-tags #列出tag--list-tasks #列出task--limit 主机列表 #只针对主机列表中的特定主机执行-i INVENTORY, --inventory INVENTORY #指定主机清单文件,通常一个项对应一个主机清单文件--start-at-task START_AT_TASK #从指定task开始执行,而非从头开始,START_AT_TASK为任务的name-v -vv -vvv #显示过程 范例: 一个简单的 playbook 12345678[root@ansible ansible]#cat hello.yml---- hosts: websrvs tasks: - name: hello command: echo &quot;hello ansible&quot;[root@ansible ansible]#ansible-playbook hello.yml[root@ansible ansible]#ansible-playbook -v hello.yml 范例: 检查和限制主机 123ansible-playbook file.yml --check #只检测ansible-playbook file.ymlansible-playbook file.yml --limit websrvs 范例: 一个playbook 多个play 1234567891011121314cat test_plays.yaml---- hosts: localhost remote_user: root gather_facts: no tasks: - name: play1 command: echo &quot;play1&quot;- hosts: centos7 remote_user: root gather_facts: no tasks: - name: play2 command: echo &quot;play2&quot; 忽略错误 ignore_errors如果一个task出错,默认将不会继续执行后续的其它task利用 ignore_errors: yes 可以忽略此task的错误,继续向下执行playbook其它task 123456789[root@ansible ansible]#cat test_ignore.yml---- hosts: centos7 tasks: - name: error command: /bin/false ignore_errors: yes - name: continue command: wall continue Playbook中使用handlers和notifyhandlers和notifyHandlers本质是task list ，类似于MySQL中的触发器触发的行为，其中的task与前述的task并没有本质上的不同，只有在关注的资源发生变化时，才会采取一定的操作。Notify对应的action 在所有task都执行完才会最后被触发，这样可避免多个task多次改变发生时每次都触发执行指定的操作，Handlers仅在所有的变化发生完成后一次性地执行指定操作。在notify中列出的操作称为handler，也即notify中调用handler中定义的操作注意: 如果多个task通知了相同的handlers， 此handlers仅会在所有task结束后运行一 次。 只有notify对应的task发生改变了才会通知handlers， 没有改变则不会触发handlers handlers 是在所有前面的tasks都成功执行才会执行,如果前面任何一个task失败,会导致handle跳过执行 案例: 案例： 案例： 范例: 部署haproxy force_handlers如果不论前面的task成功与否,都希望handlers能执行, 可以使用force_handlers: yes 强制执行handler范例: 强制调用handlers Playbook中使用tags组件官方文档: 1https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html 默认情况下， Ansible 在执行一个 playbook 时，会执行 playbook 中所有的任务，在playbook文件中，可以利用tags组件，为特定 task 指定标签，当在执行playbook时，可以只执行特定tags的task,而非整个playbook文件可以一个task对应多个tag,也可以多个task对应同一个tag还有另外3个特殊关键字用于标签, tagged, untagged 和 all,它们分别是仅运行已标记，只有未标记和所有任务。tags 主要用于调试环境范例： tag 标签 Playbook中使用变量Playbook中同样也支持变量变量名：仅能由字母、数字和下划线组成，且只能以字母开头变量定义： 12variable=valuevariable: value 范例： 12http_port=80http_port: 80 通过 调用变量，且变量名前后建议加空格，有时用”“才生效变量来源： ansible 的 setup facts 远程主机的所有变量都可直接调用 通过命令行指定变量，优先级最高 1ansible-playbook -e varname=value test.yml 3.在playbook文件中定义 123vars:var1: value1var2: value2 4.在独立的变量YAML文件中定义 123- hosts: allvars_files:- vars.yml 在主机清单文件中定义主机（普通）变量：主机组中主机单独定义，优先级高于公共变量组（公共）变量：针对主机组中所有主机定义统一变量 在项目中针对主机和主机组定义在项目目录中创建 host_vars和group_vars目录 在role中定义 变量的优先级从高到低如下 1-e 选项定义变量 --&gt;playbook中vars_files --&gt; playbook中vars变量定义 --&gt;host_vars/主机名文件 --&gt;主机清单中主机变量--&gt; group_vars/主机组名文件--&gt;group_vars/all文件--&gt; 主机清单组变量 使用 setup 模块中变量使用 facts 变量本模块自动在playbook调用，生成的系统状态信息, 并将之存放在facts变量中facts 包括的信息很多,如: 主机名,IP,CPU,内存,网卡等facts 变量的实际使用场景案例 通过facts变量获取被控端CPU的个数信息,从而生成不同的Nginx配置文件 通过facts变量获取被控端内存大小信息,从而生成不同的memcached的配置文件 通过facts变量获取被控端主机名称信息,从而生成不同的Zabbix配置文件 通过facts变量获取被控端网卡信息,从而生成不同的主机名 案例：使用setup变量 1234567891011121314151617181920[root@ansible ~]# ansible localhost -m setup -a &#x27;filter=&quot;ansible_default_ipv4&quot;&#x27;localhost | SUCCESS =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;ansible_default_ipv4&quot;: &#123; &quot;address&quot;: &quot;192.168.32.133&quot;, &quot;alias&quot;: &quot;ens160&quot;, &quot;broadcast&quot;: &quot;192.168.32.255&quot;, &quot;gateway&quot;: &quot;192.168.32.2&quot;, &quot;interface&quot;: &quot;ens160&quot;, &quot;macaddress&quot;: &quot;00:0c:29:7c:80:cd&quot;, &quot;mtu&quot;: 1500, &quot;netmask&quot;: &quot;255.255.255.0&quot;, &quot;network&quot;: &quot;192.168.32.0&quot;, &quot;prefix&quot;: &quot;24&quot;, &quot;type&quot;: &quot;ether&quot; &#125; &#125;, &quot;changed&quot;: false&#125;[root@ansible ~]# 范例：显示ens33的网卡的IP地址 1234567891011---- hosts: centos7 tasks: - name: show ens33 ip debug: msg: IP address &#123;&#123; ansible_ens33.ipv4.address &#125;&#125; #msg: IP address &#123;&#123; ansible_facts[&quot;ens33&quot;][&quot;ipv4&quot;][&quot;address&quot;] &#125;&#125; #msg: IP address &#123;&#123; ansible_facts.ens33.ipv4.address &#125;&#125; #msg: IP address &#123;&#123; ansible_default_ipv4.address &#125;&#125; #msg: IP address &#123;&#123; ansible_ens33.ipv4.address &#125;&#125; #msg: IP address &#123;&#123; ansible_ens33.ipv4.address.split(&#x27;.&#x27;)[-1] &#125;&#125; #取IP中的最后一个数字 12345678910111213141516171819202122[root@ansible ansible]# ansible-playbook -v show_ip.yml Using /etc/ansible/ansible.cfg as config filePLAY [centos7] *************************************************************************************************************************TASK [Gathering Facts] *****************************************************************************************************************ok: [192.168.32.179]ok: [192.168.32.178]TASK [show ens33 ip] *******************************************************************************************************************ok: [192.168.32.178] =&gt; &#123; &quot;msg&quot;: &quot;IP address 192.168.32.178&quot;&#125;ok: [192.168.32.179] =&gt; &#123; &quot;msg&quot;: &quot;IP address 192.168.32.179&quot;&#125;PLAY RECAP *****************************************************************************************************************************192.168.32.178 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 192.168.32.179 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 [root@ansible ansible]# 范例：修改主机名称为web-IP 12345678- hosts: centos7 tasks: - name: 打印facts变量 debug: msg=&#123;&#123; ansible_ens33.ipv4.address &#125;&#125; - name: 修改主机名 hostname: name=web-&#123;&#123; ansible_ens33.ipv4.address &#125;&#125; #- name: 获取facts变量提取IP地址，以.结尾的最后一列,修改主机名为web-hostid #hostname: name=web-&#123;&#123; ansible_ens33.ipv4.address.split(&#x27;.&#x27;)[-1] &#125;&#125; 12345678910111213141516171819202122232425[root@ansible ansible]# ansible-playbook change_hostname.yml PLAY [centos7] *************************************************************************************************************************TASK [Gathering Facts] *****************************************************************************************************************ok: [192.168.32.178]ok: [192.168.32.179]TASK [打印facts变量] *******************************************************************************************************************ok: [192.168.32.178] =&gt; &#123; &quot;msg&quot;: &quot;192.168.32.178&quot;&#125;ok: [192.168.32.179] =&gt; &#123; &quot;msg&quot;: &quot;192.168.32.179&quot;&#125;TASK [修改主机名] **********************************************************************************************************************changed: [192.168.32.179]changed: [192.168.32.178]PLAY RECAP *****************************************************************************************************************************192.168.32.178 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 192.168.32.179 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 [root@ansible ansible]# 性能优化每次执行playbook,默认会收集每个主机的所有facts变量,将会导致速度很慢,可以采用下面方法加速方法1关闭facts采集加速执行,此方法将导致无法使用facts变量 12- hosts: all gather_facts: no 方法2当使用 gather_facts: no 关闭 facts，确实能加速 Ansible 执行，但是有时候又需要使用 facts 中的内容，还希望执行的速度快，这时候可以设置facts 的缓存,将facts变量信息存在redis服务器中 1234567891011[root@ansible ~]# cat /etc/ansible/ansible.cfg[defaults]# smart 表示默认收集 facts，但 facts 已有的情况下不会收集，即使用缓存 facts# implicit 表示默认收集 facts，要禁止收集，必须使用 gather_facts: False# explicit 则表示默认不收集，要显式收集，必须使用gather_facts: Truegathering = smart #在使用 facts 缓存时设置为smartfact_caching_timeout = 86400 #缓存时长fact_caching = redis #缓存存在redis中fact_caching_connection = 10.0.0.100:6379:0 #0表示redis的0号数据库#若redis设置了密码fact_caching_connection = 10.0.0.100:6379:0:password register 注册变量在playbook中可以使用register将捕获命令的输出保存在临时变量中，方便后续调用此变量,比如可以使用debug模块进行显示输出范例: 利用debug 模块输出变量 12345678910111213141516---- hosts: centos7 tasks: - name: get variable shell: hostname register: name - name: print variable debug: msg: &quot;&#123;&#123; name &#125;&#125;&quot; #输出register注册的name变量的全部信息,注意变量要加&quot; &quot;引起来 #msg: &quot;&#123;&#123; name.cmd &#125;&#125;&quot; #显示命令 #msg: &quot;&#123;&#123; name.rc &#125;&#125;&quot; #显示命令成功与否 #msg: &quot;&#123;&#123; name.stdout &#125;&#125;&quot; #显示命令的输出结果为字符串形式,所有结果都放在一行里显示,适合于结果是单行输出 #msg: &quot;&#123;&#123; name.stdout_lines &#125;&#125;&quot; #显示命令的输出结果为列表形式,逐行标准输出,适用于多行显示 #msg: &quot;&#123;&#123; name[&#x27;stdout_lines&#x27;] &#125;&#125;&quot; #显示命令的执行结果为列表形式,和效果上面相同 #msg: &quot;&#123;&#123; name.stdout_lines[0] &#125;&#125;&quot; #显示命令的输出结果的列表中的第一个元素#说明 第一个 task 中，使用了 register 注册变量名为 name ；当 shell 模块执行完毕后，会将数据放到该变量中。第二给 task 中，使用了 debug 模块，并从变量name中获取数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253[root@ansible ansible]# ansible-playbook -C register.yml PLAY [centos7] *************************************************************************************************************************TASK [Gathering Facts] *****************************************************************************************************************ok: [192.168.32.179]ok: [192.168.32.178]TASK [get variable] ********************************************************************************************************************skipping: [192.168.32.179]skipping: [192.168.32.178]TASK [print variable] ******************************************************************************************************************ok: [192.168.32.178] =&gt; &#123; &quot;msg&quot;: &#123; &quot;changed&quot;: false, &quot;cmd&quot;: &quot;hostname&quot;, &quot;delta&quot;: null, &quot;end&quot;: null, &quot;failed&quot;: false, &quot;msg&quot;: &quot;Command would have run if not in check mode&quot;, &quot;rc&quot;: 0, &quot;skipped&quot;: true, &quot;start&quot;: null, &quot;stderr&quot;: &quot;&quot;, &quot;stderr_lines&quot;: [], &quot;stdout&quot;: &quot;&quot;, &quot;stdout_lines&quot;: [] &#125;&#125;ok: [192.168.32.179] =&gt; &#123; &quot;msg&quot;: &#123; &quot;changed&quot;: false, &quot;cmd&quot;: &quot;hostname&quot;, &quot;delta&quot;: null, &quot;end&quot;: null, &quot;failed&quot;: false, &quot;msg&quot;: &quot;Command would have run if not in check mode&quot;, &quot;rc&quot;: 0, &quot;skipped&quot;: true, &quot;start&quot;: null, &quot;stderr&quot;: &quot;&quot;, &quot;stderr_lines&quot;: [], &quot;stdout&quot;: &quot;&quot;, &quot;stdout_lines&quot;: [] &#125;&#125;PLAY RECAP *****************************************************************************************************************************192.168.32.178 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 192.168.32.179 : ok=2 changed=0 unreachable=0 failed=0 skipped=1 rescued=0 ignored=0 [root@ansible ansible]# 范例: 安装启动服务并检查 12345678910111213141516---- hosts: centos7 vars: package_name: nginx service_name: nginx tasks: - name: install &#123;&#123; package_name &#125;&#125; yum: name=&#123;&#123; package_name &#125;&#125; - name: start &#123;&#123; service_name &#125;&#125; service: name=&#123;&#123; service_name &#125;&#125; state=started enabled=yes - name: check shell: ps axu|grep &#123;&#123; service_name &#125;&#125; register: check_service - name: debug debug: msg: &quot;&#123;&#123; check_service.stdout_lines &#125;&#125;&quot; 范例: 修改主机名形式为 web_&lt;随机字符&gt; 12345678910111213- hosts: centos7 tasks: - name: genarate random shell: cmd: openssl rand -base64 12 |tr -dc &#x27;[:alnum:]&#x27; register: num - name: show random debug: msg: &quot;&#123;&#123; num &#125;&#125;&quot; - name: change hostname hostname: name: web-&#123;&#123; num.stdout &#125;&#125; 范例: 修改主机名形式为 web_随机数 123456789- hosts: centos7 tasks: - name: 定义一个随机数，设定为变量，然后后续调用 shell: echo $((RANDOM%255)) register: web_number - name: 使用debug输出变量结果 debug: msg=&#123;&#123; web_number &#125;&#125; - name: 使用hostname模块将主机名修改为web_随机数 hostname: name=web_&#123;&#123; web_number.stdout &#125;&#125; 范例: 批量修改主机名为随机字符 12345678910111213- hosts: centos7 vars: host: web domain: wang.org tasks: - name: get variable shell: echo $RANDOM | md5sum | cut -c 1-8 register: get_random - name: print variable debug: msg: &quot;&#123;&#123; get_random.stdout &#125;&#125;&quot; - name: set hostname hostname: name=&#123;&#123; host &#125;&#125;-&#123;&#123; get_random.stdout &#125;&#125;.&#123;&#123; domain &#125;&#125; 范例: 批量修改主机名为IP最后1位数字 12345678910111213- hosts: centos7 vars: host: web domain: wang.org tasks: - name: get variable shell: hostname -I | awk &#x27;&#123;print $1&#125;&#x27; register: get_ip - name: print variable debug: msg: &quot;&#123;&#123; get_ip.stdout.split(&#x27;.&#x27;)[3] &#125;&#125;&quot; - name: set hostname hostname: name=&#123;&#123; host &#125;&#125;-&#123;&#123; get_ip.stdout.split(&#x27;.&#x27;)[3] &#125;&#125;.&#123;&#123; domain &#125;&#125; 在 Playbook 命令行中定义变量范例： 123456789---- hosts: centos7 remote_user: root tasks: - name: install nginx yum: name=&#123;&#123; pkname &#125;&#125; state=present [root@ansible ~]#ansible-playbook -e pkname=nginx var2.yml 范例： 123456789101112131415#也可以将多个变量放在一个文件中[root@ansible ~]#cat varspkname1: memcachedpkname2: vsftpd[root@ansible ~]#vim var2.yml---- hosts: centos7 remote_user: root tasks: - name: install package &#123;&#123; pkname1 &#125; yum: name=&#123;&#123; pkname1 &#125;&#125; state=present - name: install package &#123;&#123; pkname2 &#125; yum: name=&#123;&#123; pkname2 &#125;&#125; state=present[root@ansible ~]#ansible-playbook -e pkname1=memcached -e pkname2=httpd var2.yml[root@ansible ~]#ansible-playbook -e &#x27;@vars&#x27; var2.yml 在playbook文件中定义变量此方式定义的是私有变量,即只能在当前playbook中使用,不能被其它Playbook共用范例： 123456789101112- hosts: webservers remote_user: root vars: username: user1 groupname: group1 tasks: - name: create group &#123;&#123; groupname &#125;&#125; group: name=&#123;&#123; groupname &#125;&#125; state=present - name: create user &#123;&#123; username &#125;&#125; user: name=&#123;&#123; username &#125;&#125; group=&#123;&#123; groupname &#125;&#125; state=present [root@ansible ~]#ansible-playbook -e &quot;username=user2 groupname=group2&quot; var3.yml 范例：变量的相互调用 12345678---- hosts: centos7 remote_user: root vars: collect_info: &quot;/data/test/&#123;&#123;ansible_default_ipv4[&#x27;address&#x27;]&#125;&#125;/&quot; tasks: - name: create IP directory file: name=&quot;&#123;&#123;collect_info&#125;&#125;&quot; state=directory 使用专用的公共的变量文件可以在一个独立的playbook文件中定义公共变量，在其它的playbook文件中可以引用变量文件中的变量此方式比playbook中定义的变量优化级高 1234567891011121314151617181920vim vars.yml---# variables filepackage_name: mariadb-serverservice_name: mariadbvim var5.yml---#install package and start service- hosts: dbsrvs remote_user: root vars_files: # 指定变量文件名 - vars.yml tasks: - name: install package yum: name=&#123;&#123; package_name &#125;&#125; tags: install - name: start service service: name=&#123;&#123; service_name &#125;&#125; state=started enabled=yes 在主机清单中定义主机和主机组的变量所有项目的主机变量在inventory 主机清单文件中为指定的主机定义变量以便于在playbook中使用范例： 123[webservers]www1.wang.org http_port=80 maxRequestsPerChild=808www2.wang.org http_port=8080 maxRequestsPerChild=909 所有项目的组（公共）变量在inventory 主机清单文件中赋予给指定组内所有主机上的在playbook中可用的变量，如果和主机变是同名，优先级低于主机变量 案例： 1234567891011121314151617181920[webservers:vars]http_port=80ntp_server=ntp.wang.orgnfs_server=nfs.wang.org[all:vars]# --------- Main Variables ---------------# Cluster container-runtime supported: docker, containerdCONTAINER_RUNTIME=&quot;docker&quot;# Network plugins supported: calico, flannel, kube-router, cilium, kube-ovnCLUSTER_NETWORK=&quot;calico&quot;# Service proxy mode of kube-proxy: &#x27;iptables&#x27; or &#x27;ipvs&#x27;PROXY_MODE=&quot;ipvs&quot;# K8S Service CIDR, not overlap with node(host) networkingSERVICE_CIDR=&quot;192.168.0.0/16&quot;# Cluster CIDR (Pod CIDR), not overlap with node(host) networkingCLUSTER_CIDR=&quot;172.16.0.0/16&quot;# NodePort RangeNODE_PORT_RANGE=&quot;20000-60000&quot;# Cluster DNS DomainCLUSTER_DNS_DOMAIN=&quot;magedu.local.&quot; 范例： 12345678910111213[root@ansible ~]#vim /etc/ansible/hosts[webservers]10.0.0.8 hname=www1 domain=magedu.io10.0.0.7 hname=www2[webservers:vars]mark=&quot;-&quot;[all:vars]domain=wang.org[root@ansible ~]#ansible webservers -m hostname -a &#x27;name=&#123;&#123; hname &#125;&#125;&#123;&#123; mark &#125;&#125;&#123;&#123; domain &#125;&#125;&#x27;#命令行指定变量：[root@ansible ~]#ansible webservers -e domain=magedu.cn -m hostname -a &#x27;name=&#123;&#123; hname &#125;&#125;&#123;&#123; mark &#125;&#125;&#123;&#123; domain &#125;&#125;&#x27; 针对当前项目的主机和主机组的变量上面的方式是针对所有项目都有效,而官方更建议的方式是使用ansible特定项目的主机变量和组变量.生产建议在每个项目对应的目录中创建额外的两个变量目录,分别是host_vars和group_vars host_vars下面的文件名和主机清单主机名一致,针对单个主机进行变量定义格式:host_vars&#x2F;hostname group_vars下面的文件名和主机清单中组名一致, 针对单个组进行变量定义格式: group_vars&#x2F;groupname group_vars&#x2F;all文件内定义的变量对所有组都有效 范例: 特定项目的主机和组变量 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@ansible ansible]#pwd/data/ansible[root@ansible ansible]#mkdir host_vars[root@ansible ansible]#mkdir group_vars[root@ansible ansible]#cat host_vars/10.0.0.8id: 2[root@ansible ansible]#cat host_vars/10.0.0.7id: 1[root@ansible ansible]#cat group_vars/webserversname: web[root@ansible ansible]#cat group_vars/alldomain: wang.org[root@ansible ansible]#tree host_vars/ group_vars/host_vars/├── 10.0.0.7└── 10.0.0.8group_vars/├── all└── webservers0 directories, 4 files[root@ansible ansible]#cat test.yml- hosts: webserverstasks:- name: get variablecommand: echo &quot;&#123;&#123;name&#125;&#125;&#123;&#123;id&#125;&#125;.&#123;&#123;domain&#125;&#125;&quot;register: result- name: print variabledebug:msg: &quot;&#123;&#123;result.stdout&#125;&#125;&quot;[root@ansible ansible]#ansible-playbook test.ymlPLAY [webservers]***********************************************************************************************************************TASK [Gathering Facts]***************************************************************************************************************ok: [10.0.0.7]ok: [10.0.0.8]TASK [get variable]******************************************************************************************************************changed: [10.0.0.7]changed: [10.0.0.8]TASK [print variable]****************************************************************************************************************ok: [10.0.0.7] =&gt; &#123;&quot;msg&quot;: &quot;web1.wang.org&quot;&#125;ok: [10.0.0.8] =&gt; &#123;&quot;msg&quot;: &quot;web2.wang.org&quot;&#125;PLAY RECAP***************************************************************************************************************************10.0.0.7 : ok=3 changed=1 unreachable=0 failed=0skipped=0 rescued=0 ignored=010.0.0.8 : ok=3 changed=1 unreachable=0 failed=0skipped=0 rescued=0 ignored=0","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://snippet.itshare.work/categories/Ansible/"}],"tags":[],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://snippet.itshare.work/categories/Ansible/"}]},{"title":"运维自动化工具Ansible(一)","slug":"Ansible","date":"2023-02-21T11:12:21.000Z","updated":"2023-02-27T10:14:06.890Z","comments":true,"path":"2023/02/21/Ansible/","link":"","permalink":"http://snippet.itshare.work/2023/02/21/Ansible/","excerpt":"Ansible 的名称来自科幻小说《安德的游戏》中跨越时空的即时通信工具，使用它可以在相距数光年的距离,远程实时控制前线的舰队战斗","text":"Ansible介绍和架构Ansible发展史Ansible 的名称来自科幻小说《安德的游戏》中跨越时空的即时通信工具，使用它可以在相距数光年的距离，远程实时控制前线的舰队战斗2012-03-09，发布0.0.1版，2015-10-17，Red Hat宣布1.5亿美元收购官网：https://www.ansible.com/官方文档：https://docs.ansible.com/ Ansible 功能 批量执行远程命令,可以对远程的多台主机同时进行命令的执行 批量安装和配置软件服务，可以对远程的多台主机进行自动化的方式配置和管理各种服务 编排高级的企业级复杂的IT架构任务, Ansible的Playbook和role可以轻松实现大型的IT复杂架构 提供自动化运维工具的开发API, 有很多运维工具,如jumpserver就是基于 ansible 实现自动化管工功能 Ansible 特点优点 功能丰富的模块：提供了多达数千个的各种功能的模块,完成特定任务只需调用特定模块即可，还 支持自定义模块，可使用任何编程语言写模块 使用和部署简单: 无需安装专用代理软件,基于python和SSH(默认已安装)实现 安全: 基于OpenSSH实现安全通讯无需专用协议 幂等性：一个任务执行1遍和执行n遍效果一样，不因重复执行带来意外情况,此特性和模块有关 支持playbook编排任务，YAML格式，编排任务，支持丰富的数据结构 较强大的多层解决方案 Role Python语言实现, 基于Paramiko（python对ssh的实现），PyYAML，Jinja2（模板语言）三个关键模块 属于红帽(IBM)公司产品,背景强大,未来发展前景光明 缺点 如果管理的主机较多时,执行效率不如saltstack高 当前还不支持像MySQL数据库一样的事务回滚 Ansible 架构Ansible 组成组合INVENTORY、API、MODULES、PLUGINS的绿框，为ansible命令工具，其为核心执行工具 INVENTORY：Ansible管理主机的清单文件,默认为 &#x2F;etc&#x2F;ansible&#x2F;hosts MODULES：Ansible执行命令的功能模块，多数为内置核心模块，也可自定义 PLUGINS：模块功能的补充，如连接类型插件、循环插件、变量插件、过滤插件等，该功能不常用 API：供第三方程序调用的应用程序编程接口 Ansible 命令执行来源 USER 普通用户，即SYSTEM ADMINISTRATOR PLAYBOOKS：任务剧本（任务集），编排定义Ansible任务集的配置文件，由Ansible顺序依次执行，通常是JSON格式的YML文件 CMDB（配置管理数据库） API 调用 PUBLIC&#x2F;PRIVATE CLOUD API调用 USER-&gt; Ansible Playbook -&gt; Ansibile 注意事项 执行ansible的主机一般称为管理端, 主控端，中控，master或堡垒机 主控端Python版本需要2.6或以上 被控端Python版本小于2.4，需要安装python-simplejson 被控端如开启SELinux需要安装libselinux-python windows 不能做为主控端,只能做为被控制端 Ansible 安装和常见模块Ansible 安装ansible的安装方法有多种官方文档 12https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.htmlhttps://docs.ansible.com/ansible/latest/installation_guide/index.html 下载 1https://releases.ansible.com/ansible/ pip 下载 1https://pypi.org/project/ansible/ 包安装方式1234#CentOS 的EPEL源的rpm包安装[root@centos ~]#yum install ansible#ubuntu 安装[root@ubuntu ~]#apt -y install ansible pip安装pip 是安装Python包的管理器，类似 yum范例: 在rocky8上通过pip3安装ansible 1234567891011121314151617[root@rocky8 ~]#yum -y install python39 rust[root@rocky8 ~]#pip3 install ansible[root@rocky8 ~]#ansible --versionansible [core 2.12.6]config file = Noneconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python3.9/site-packages/ansibleansible collection location =/root/.ansible/collections:/usr/share/ansible/collectionsexecutable location = /usr/bin/ansiblepython version = 3.9.6 (default, Nov 9 2021, 13:31:27) [GCC 8.5.0 20210514(Red Hat 8.5.0-3)]jinja version = 3.1.2libyaml = True[root@rocky8 ~]#ansible-doc -l 2&gt; /dev/null|wc -l6763 范例: 安装python3.8 支持ansible2.12以上版本 1234567891011121314151617[root@rocky8 ~]#yum -y install python38 python38-pip[root@rocky8 ~]#pip3 install --upgrade pip -i https://pypi.douban.com/simple[root@rocky8 ~]#pip3 install ansible -i https://pypi.douban.com/simple/[root@rocky8 ~]#ansible --versionansible [core 2.12.6]config file = Noneconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/local/lib/python3.8/site-packages/ansibleansible collection location =/root/.ansible/collections:/usr/share/ansible/collectionsexecutable location = /usr/local/bin/ansiblepython version = 3.8.8 (default, Nov 9 2021, 13:31:34) [GCC 8.5.0 20210514(Red Hat 8.5.0-3)]jinja version = 3.1.2libyaml = True 范例: 安装默认的python3.6版本会有警报提示 1234567891011121314151617181920212223242526272829[root@rocky8 ~]#yum -y install python3[root@rocky8 ~]#pip3 install --upgrade pip -i https://pypi.douban.com/simple[root@rocky8 ~]#pip3 install ansible -i https://pypi.douban.com/simple/[root@rocky8 ~]#ansible --version[DEPRECATION WARNING]: Ansible will require Python 3.8 or newer on thecontroller starting with Ansible 2.12. Current version: 3.6.8 (default, Nov9 2021, 14:44:26) [GCC 8.5.0 20210514 (Red Hat 8.5.0-3)]. This feature will beremoved from ansible-core in version 2.12. Deprecation warningscan be disabled by setting deprecation_warnings=False in ansible.cfg./usr/local/lib/python3.6/site-packages/ansible/parsing/vault/__init__.py:44:CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Pythoncore team. Therefore, support for it is deprecated in cryptography and will beremoved in a future release.from cryptography.exceptions import InvalidSignatureansible [core 2.11.12]config file = Noneconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/local/lib/python3.6/site-packages/ansibleansible collection location =/root/.ansible/collections:/usr/share/ansible/collectionsexecutable location = /usr/local/bin/ansiblepython version = 3.6.8 (default, Nov 9 2021, 14:44:26) [GCC 8.5.0 20210514(Red Hat 8.5.0-3)]jinja version = 3.0.3libyaml = True[root@rocky8 ~]#ansible-doc -l 2&gt; /dev/null|wc -l6141 范例 12345678910111213141516171819[root@centos7 ~]#yum -y install python-pip[root@centos7 ~]#pip install --upgrade pip[root@centos7 ~]#pip install ansible --upgrade[root@centos7 ~]#ansible --version/usr/lib64/python2.7/site-packages/cryptography/__init__.py:39:CryptographyDeprecationWarning: Python 2 is no longer supported by the Pythoncore team. Support for it is now deprecated in cryptography, and will be removedin a future release.CryptographyDeprecationWarning,ansible 2.9.12config file = Noneconfigured module search path = [u&#x27;/root/.ansible/plugins/modules&#x27;,u&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python2.7/site-packages/ansibleexecutable location = /usr/bin/ansiblepython version = 2.7.5 (default, Apr 2 2020, 13:16:51) [GCC 4.8.5 20150623(Red Hat 4.8.5-39)][root@centos7 ~]#ll /opt/etc/ansible/ansible.cfg-rw-r--r-- 1 wang bin 19980 Aug 11 21:34 /opt/etc/ansible/ansible.cfg 确认安装123456789[root@ansible ~]#ansible --versionansible 2.9.5config file = /etc/ansible/ansible.cfgconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python3.6/site-packages/ansibleexecutable location = /usr/bin/ansiblepython version = 3.6.8 (default, Nov 21 2019, 19:31:34) [GCC 8.3.1 20190507(Red Hat 8.3.1-4)] Ansible 相关文件Ansible 配置文件列表 &#x2F;etc&#x2F;ansible&#x2F;ansible.cfg 主配置文件，配置ansible工作特性,也可以在项目的目录中创建此文件,当前目录下如果也有ansible.cfg,则此文件优先生效,建议每个项目目录下,创建独有的ansible.cfg文件 &#x2F;etc&#x2F;ansible&#x2F;hosts 主机清单 &#x2F;etc&#x2F;ansible&#x2F;roles&#x2F; 存放角色的目录 Ansible 主配置文件Ansible 的配置文件可以放在多个不同地方,优先级从高到低顺序如下 1234ANSIBLE_CONFIG #环境变量,目录下的文件必须存在才能生效./ansible.cfg #当前目录下的ansible.cfg,一般一个项目对应一个专用配置文件,推荐使用~/.ansible.cfg #当前用户家目录下的.ansible.cfg/etc/ansible/ansible.cfg #系统默认配置文件 Ansible 的默认配置文件 &#x2F;etc&#x2F;ansible&#x2F;ansible.cfg ,其中大部分的配置内容无需进行修改 12345678910111213141516171819[defaults]#inventory = /etc/ansible/hosts #主机列表配置文件#library = /usr/share/my_modules/ #库文件存放目录#remote_tmp = $HOME/.ansible/tmp #临时py命令文件存放在远程主机目录#local_tmp = $HOME/.ansible/tmp #本机的临时命令执行目录#forks = 5 #默认并发数#sudo_user = root #默认sudo 用户#ask_sudo_pass = True #每次执行ansible命令是否询问ssh密码#ask_pass = True#remote_port = 22#host_key_checking = False #检查对应服务器的host_key，建议取消此行注释,实现第一次连接自动信任目标主机#log_path=/var/log/ansible.log #日志文件，建议启用#module_name = command #默认模块，可以修改为shell模块[privilege_escalation] #普通用户提权配置#become=True#become_method=sudo#become_user=root#become_ask_pass=False 范例: 通过环境变量ANSIBLE_CONFIG指定ansible配置文件路径 12345678910111213141516171819202122232425262728293031[root@rocky8 ~]#cd /data/ansible/[root@rocky8 ansible]#cat ansbile.cfg[defaults]inventory = ./hosts[root@rocky8 ansible]#cat hosts[ubuntu]10.0.0.100[centos]10.0.0.710.0.0.8#定义变量[root@rocky8 ansible]#export ANSIBLE_CONFIG=./ansbile.cfg[root@rocky8 ansible]#ansible --versionansible [core 2.12.6]config file = /data/ansible/ansbile.cfgconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python3.9/site-packages/ansibleansible collection location =/root/.ansible/collections:/usr/share/ansible/collectionsexecutable location = /usr/bin/ansiblepython version = 3.9.6 (default, Nov 9 2021, 13:31:27) [GCC 8.5.0 20210514(Red Hat 8.5.0-3)]jinja version = 3.1.2libyaml = True[root@rocky8 ansible]#ansible --list-hosts allhosts (3):10.0.0.10010.0.0.710.0.0.8 范例: 创建ansible 指定项目专用的配置文件 12345678910111213141516171819202122232425262728[root@ubuntu2004 ~]#ansible --versionansible 2.9.6config file = /etc/ansible/ansible.cfgconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python3/dist-packages/ansibleexecutable location = /usr/bin/ansiblepython version = 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0][root@ubuntu2004 ~]#mkdir /data/ansible -p[root@ubuntu2004 ~]#cd /data/ansible/[root@ubuntu2004 ansible]#touch ansible.cfg[root@ubuntu2004 ansible]#ansible --versionansible 2.9.6config file = /data/ansible/ansible.cfgconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python3/dist-packages/ansibleexecutable location = /usr/bin/ansiblepython version = 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0][root@ubuntu2004 ansible]#cd[root@ubuntu2004 ~]#ansible --versionansible 2.9.6config file = /etc/ansible/ansible.cfgconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python3/dist-packages/ansibleexecutable location = /usr/bin/ansiblepython version = 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0] 范例: 当前目录下的ansible的配置文件优先生效 123456789101112131415161718192021[root@ansible ~]#ansible --versionansible 2.9.17config file = /etc/ansible/ansible.cfgconfigured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python3.6/site-packages/ansibleexecutable location = /usr/bin/ansiblepython version = 3.6.8 (default, Apr 16 2020, 01:36:27) [GCC 8.3.1 20191121(Red Hat 8.3.1-5)][root@ansible ~]#cp /etc/ansible/ansible.cfg .[root@ansible ~]#ansible --versionansible 2.9.17config file = /root/ansible.cfg #注意配置文件路径configured module search path = [&#x27;/root/.ansible/plugins/modules&#x27;,&#x27;/usr/share/ansible/plugins/modules&#x27;]ansible python module location = /usr/lib/python3.6/site-packages/ansibleexecutable location = /usr/bin/ansiblepython version = 3.6.8 (default, Apr 16 2020, 01:36:27) [GCC 8.3.1 20191121(Red Hat 8.3.1-5)][root@ansible ~]# Inventory 主机清单文件ansible的主要功用在于批量主机操作，为了便捷地使用其中的部分主机，可以在inventory 主机清单文件中将其分组组织默认的inventory file为 &#x2F;etc&#x2F;ansible&#x2F;hostsinventory file可以有多个，且也可以通过Dynamic Inventory来动态生成注意: 生产建议在每个项目目录下创建项目独立的hosts文件 通过项目目录下的ansible.cfg文件中的 inventory &#x3D; .&#x2F;hosts实现 官方文档: 1https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html 主机清单文件格式inventory文件遵循INI文件风格，中括号中的字符为组名。可以将同一个主机同时归并到多个不同的组中,此外，当如若目标主机使用了非默认的SSH端口，还可以在主机名称之后使用冒号加端口号来标明,如果主机名称遵循相似的命名模式，还可以使用列表的方式标识各主机Inventory 参数说明 1234567891011ansible_ssh_host #将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置.ansible_ssh_port #ssh端口号.如果不是默认的端口号,通过此变量设置.这种可以使用 ip:端口192.168.1.100:2222ansible_ssh_user #默认的 ssh 用户名ansible_ssh_pass #ssh 密码(这种方式并不安全,我们强烈建议使用 --ask-pass 或 SSH 密钥)ansible_sudo_pass #sudo 密码(这种方式并不安全,我们强烈建议使用 --ask-sudo-pass)ansible_sudo_exe (new in version 1.8) #sudo 命令路径(适用于1.8及以上版本)ansible_connection #与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko.1.2 以后默认使用 &#x27;smart&#x27;,&#x27;smart&#x27; 方式会根据是否支持 ControlPersist,来判断&#x27;ssh&#x27; 方式是否可行.ansible_ssh_private_key_file #ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况.ansible_shell_type #目标系统的shell类型.默认情况下,命令的执行使用 &#x27;sh&#x27; 语法,可设置为&#x27;csh&#x27; 或 &#x27;fish&#x27;.ansible_python_interpreter #目标主机的 python 路径.适用于的情况: 系统中有多个 Python,或者命令路径不是&quot;/usr/bin/python&quot;,比如 \\*BSD, 或者 /usr/bin/python 不是 2.X 版本的Python.之所以不使用 &quot;/usr/bin/env&quot; 机制,因为这要求远程用户的路径设置正确,且要求 &quot;python&quot;可执行程序名不可为 python以外的名字(实际有可能名为python26).与ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径.... 范例： 12345678910ntp.wang.org[webservers]www1.wang.org:2222www2.wang.org[dbservers]db1.wang.orgdb2.wang.orgdb3.wang.org#或者db[1:3].wang.org 范例: 组嵌套 12345678910[webservers]www[1:100].example.com[dbservers]db-[a:f].example.com[appservers]10.0.0.[1:100]#定义testsrvs组中包括两个其它分组,实现组嵌套[testsrvs:children]webserversdbservers 范例: 基于用户名和密码的ssh连接主机清单 12345678910111213141516[test]10.0.0.8 ansible_connection=local #指定本地连接,无需ssh配置#每个主机分别指定用户和密码,ansible_connection=ssh 需要StrictHostKeyChecking no 或者host_key_checking = False10.0.0.7 ansible_connection=ssh ansible_ssh_port=2222 ansible_ssh_user=wangansible_ssh_password=12345610.0.0.6 ansible_ssh_user=root ansible_ssh_password=123456#对每个分组的所有主机统一定义用户和密码,执行ansible命令时显示别名,如web01[websrvs]web01 ansible_ssh_host=10.0.0.101web02 ansible_ssh_host=10.0.0.102[websrvs:vars]ansible_ssh_password=magedusome_host ansible_ssh_port=2222 ansible_ssh_user=manageraws_host ansible_ssh_private_key_file=/home/example/.ssh/aws.pemfreebsd_host ansible_python_interpreter=/usr/local/bin/pythonruby_module_host ansible_ruby_interpreter=/usr/bin/ruby.1.9.3 Ansible相关工具 &#x2F;usr&#x2F;bin&#x2F;ansible 主程序，临时命令执行工具 &#x2F;usr&#x2F;bin&#x2F;ansible-doc 查看配置文档，模块功能查看工具,相当于man &#x2F;usr&#x2F;bin&#x2F;ansible-playbook 定制自动化任务，编排剧本工具,相当于脚本 &#x2F;usr&#x2F;bin&#x2F;ansible-pull 远程执行命令的工具 &#x2F;usr&#x2F;bin&#x2F;ansible-vault 文件加密工具 &#x2F;usr&#x2F;bin&#x2F;ansible-console 基于Console界面与用户交互的执行工具 &#x2F;usr&#x2F;bin&#x2F;ansible-galaxy 下载&#x2F;上传优秀代码或Roles模块的官网平台 利用ansible实现管理的主要方式： Ansible Ad-Hoc 即利用ansible命令，主要用于临时命令使用场景 Ansible playbook 主要用于长期规划好的，大型项目的场景，需要有前期的规划过程 ansible 使用前准备ansible 相关工具大多数是通过ssh协议，实现对远程主机的配置管理、应用部署、任务执行等功能建议：使用此工具前，先配置ansible主控端能基于密钥认证的方式联系各个被管理节点范例：利用sshpass批量实现基于key验证脚本1 12345678910111213141516[root@centos8 ~]#vim /etc/ssh/ssh_config#修改下面一行StrictHostKeyChecking no[root@centos8 ~]#cat hosts.list192.168.32.178192.168.32.179[root@centos8 ~]#vim push_ssh_key.sh#!/bin/bashrpm -ql shpass &amp;&gt; /dev/null || yum -y install sshpass[ -f /root/.ssh/id_rsa ] || ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;export SSHPASS=123456while read IP;do sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $IPdone &lt; hosts.list 范例: 实现基于key验证的脚本2 1234567891011121314[root@centos8 ~]#cat ssh_key.sh#!/bin/bashPLIST=&quot;192.168.32.178192.168.32.179&quot;rpm -q sshpass &amp;&gt; /dev/null || yum -y install sshpass[ -f /root/.ssh/id_rsa ] || ssh-keygen -f /root/.ssh/id_rsa -P &#x27;&#x27;export SSHPASS=123456for IP in $IPLIST;do &#123; sshpass -e ssh-copy-id -o StrictHostKeyChecking=no $IP; &#125; &amp;donewait ansible-doc此工具用来显示模块帮助,相当于man格式 123ansible-doc [options] [module...]-l, --list #列出可用模块-s, --snippet #显示指定模块的playbook片段 范例: 查看帮助 1234567891011[root@rocky ~]# ansible-doc --helpusage: ansible-doc [-h] [--version] [-v] [-M MODULE_PATH] [--playbook-dir BASEDIR] [-t &#123;become,cache,callback,cliconf,connection,httpapi,inventory,lookup,netconf,shell,vars,module,strategy,role,keyword&#125;] [-j] [-r ROLES_PATH] [-e ENTRY_POINT | -s | -F | -l | --metadata-dump] [--no-fail-on-errors] [plugin ...]plugin documentation toolpositional arguments: plugin Plugin 范例： 123456#列出所有模块ansible-doc -l#查看指定模块帮助用法ansible-doc ping#查看指定模块帮助用法ansible-doc -s ping 范例: 查看指定的插件 1234567891011121314151617181920212223242526272829303132333435[root@rocky ~]# ansible-doc -t connection -llocal execute on controller paramiko_ssh Run tasks via python ssh (paramiko) psrp Run tasks over Microsoft PowerShell Remoting Protocol ssh connect via SSH client binary winrm Run tasks over Microsoft&#x27;s WinRM [root@rocky ~]# [root@rocky ~]# ansible-doc -t lookup -lconfig Lookup current Ansible configuration values csvfile read data from a TSV or CSV file dict returns key/value pair items from dictionaries env Read the value of environment variables file read file contents fileglob list files matching a pattern first_found return first file found from list indexed_items rewrites lists to return &#x27;indexed items&#x27; ini read data from an ini file inventory_hostnames list of inventory hosts matching a host pattern items list of items lines read lines from command list simply returns what it is given nested composes a list with nested elements of other lists password retrieve or generate a random password, stored in a file pipe read output from a command random_choice return random element from list sequence generate a list based on a number sequence subelements traverse nested key from a list of dictionaries template retrieve contents of file after templating with Jinja2 together merges lists into synchronized list unvault read vaulted file(s) contents url return contents from URL varnames Lookup matching variable names vars Lookup templated value of variables [root@rocky ~]# ansibleAnsible Ad-Hoc 介绍Ansible Ad-Hoc 的执行方式的主要工具就是 ansible特点: 一次性的执行,不会保存执行命令信息,只适合临时性或测试性的任务 ansible 命令用法格式： 1ansible &lt;host-pattern&gt; [-m module_name] [-a args] 选项说明： 12345678910111213--version #显示版本-m module #指定模块，默认为command-v #详细过程 -vv -vvv更详细--list-hosts #显示主机列表，可简写 --list-C, --check #检查，并不执行-T, --timeout=TIMEOUT #执行命令的超时时间，默认10s-k, --ask-pass #提示输入ssh连接密码，默认Key验证-u, --user=REMOTE_USER #执行远程执行的用户,默认root-b, --become #代替旧版的sudo实现通过sudo机制实现提升权限--become-user=USERNAME #指定sudo的runas用户，默认为root-K, --ask-become-pass #提示输入sudo时的口令-f FORKS, --forks FORKS #指定并发同时执行ansible任务的主机数-i INVENTORY, --inventory INVENTORY #指定主机清单文件 范例: 12345678#以wang用户执行ping存活检测ansible all -m ping -u wang -k#以wang sudo至root执行ping存活检测ansible all -m ping -u wang -k -b#以wang sudo至mage用户执行ping存活检测ansible all -m ping -u wang -k -b --become-user=mage#以wang sudo至root用户执行lsansible all -m command -u wang -a &#x27;ls /root&#x27; -b --become-user=root -k -K 范例: 并发执行控制 123#分别执行下面两条命令观察结果[root@ansible ~]#ansible all -a &#x27;sleep 5&#x27; -f1[root@ansible ~]#ansible all -a &#x27;sleep 5&#x27; -f10 范例: 使用普能用户进行远程管理 123456789101112131415161718192021222324252627282930313233#在所有控制端和被控制端创建用户和密码[root@rocky8 ~]#useradd wang[root@rocky8 ~]#echo wang:123456 | chpasswd#在所有被控制端对用户sudo授权[root@rocky8 ~]#visudowang ALL=(ALL) NOPASSWD: ALL[root@rocky8 ~]#visudo -c/etc/sudoers: parsed OK#实现从控制端到被控制端的基于key验证[root@ansible ~]#su - wangwang@ansible:~$ssh-keygen -f ~/.ssh/id_rsa -P &#x27;&#x27;wang@ansible:~$$ssh-copy-id wang@&#x27;10.0.0.8&#x27;#使用普通用户测试连接,默认连接权限不足失败wang@ansible:~$ ansible 10.0.0.8 -m shell -a &#x27;ls /root&#x27;10.0.0.8 | FAILED | rc=2 &gt;&gt;ls: cannot open directory &#x27;/root&#x27;: Permission deniednon-zero return code#使用普通用户通过-b选项连接实现sudo提权后连接成功wang@ansible:~$ ansible 10.0.0.8 -m shell -a &#x27;ls /root&#x27; -b --become-user root10.0.0.8 | CHANGED | rc=0 &gt;&gt;anaconda-ks.cfg#修改配置文件指定sudo机制[root@ansible ~]#vim /etc/ansible/ansible.cfg#取消下面行前面的注释[privilege_escalation]become=Truebecome_method=sudobecome_user=rootbecome_ask_pass=False#再次测试[root@ansible ~]#su - wangwang@ansible:~$ ansible 10.0.0.8 -m shell -a &#x27;ls /root&#x27;10.0.0.8 | CHANGED | rc=0 &gt;&gt;anaconda-ks.cfg 范例: 使用普通用户连接远程主机执行代替另一个用户身份执行操作 1234567891011[root@centos8 ~]#useradd wang[root@centos8 ~]#echo wang:123456 | chpasswd#先在被控制端能过sudo对普通用户授权[root@centos8 ~]#grep wang /etc/sudoerswang ALL=(ALL) NOPASSWD: ALL#以wang的用户连接用户,并利用sudo代表mage执行whoami命令[root@ansible ~]#ansible 10.0.0.8 -m shell -a &#x27;whoami&#x27; -u wang -k -b --become-user=mageSSH password: #输入远程主机wang用户ssh连接密码10.0.0.8 | CHANGED | rc=0 &gt;&gt;mage ansible的Host-pattern用于匹配被控制的主机的列表All ：表示所有Inventory中的所有主机范例 1ansible all -m ping *:通配符 1234ansible &quot;*&quot; -m pingansible 192.168.1.* -m pingansible &quot;srvs&quot; -m pingansible &quot;10.0.0.6 10.0.0.7&quot; -m ping 或关系 12ansible &quot;websrvs:appsrvs&quot; -m pingansible &quot;192.168.1.10:192.168.1.20&quot; -m ping 逻辑与 12#在websrvs组并且在dbsrvs组中的主机ansible &quot;websrvs:&amp;dbsrvs&quot; -m ping 逻辑非 123#在所有主机,但不在websrvs组和dbsrvs组中的主机#注意：此处为单引号ansible &#x27;all:!dbsrvs:!websrvs&#x27; -m ping 综合逻辑 1ansible &#x27;websrvs:dbsrvs:&amp;appsrvs:!ftpsrvs&#x27; -m ping 正则表达式 12ansible &quot;websrvs:dbsrvs&quot; -m pingansible &quot;~(web|db).*\\.magedu\\.com&quot; -m ping ansible 命令的执行过程 加载自己的配置文件,默认&#x2F;etc&#x2F;ansible&#x2F;ansible.cfg 查找主机清单中对应的主机或主机组 加载自己对应的模块文件，如：command 通过ansible将模块或命令生成对应的临时py文件，并将该文件传输至远程服务器的对应执行用户$HOME&#x2F;.ansible&#x2F;tmp&#x2F;ansible-tmp-数字&#x2F;XXX.PY文件 给文件+x执行 执行并返回结果 删除临时py文件，退出 ansible 命令的执行状态123456789101112131415[root@centos8 ~]#grep -A 14 &#x27;\\[colors\\]&#x27; /etc/ansible/ansible.cfg[colors]#highlight = white#verbose = blue#warn = bright purple#error = red#debug = dark gray#deprecate = purple#skip = cyan#unreachable = red#ok = green#changed = yellow#diff_add = green#diff_remove = red#diff_lines = cyan 绿色：执行成功并且对目标主机不需要做改变的操作 黄色：执行成功并且对目标主机做变更 红色：执行失败 ansible-console此工具可交互执行命令，支持tab，ansible 2.0+新增提示符格式： 1执行用户@当前操作的主机组 (当前组的主机数量)[f:并发数]$ 常用子命令： 设置并发数： forks n 例如： forks 10 切换组： cd 主机组 例如： cd web 列出当前组主机列表： list 列出所有的内置命令： ?或help 范例 12345678910111213141516171819202122232425262728293031323334353637[root@ansible ~]#ansible-consoleWelcome to the ansible console.Type help or ? to list commands.root@all (3)[f:5]$ ping10.0.0.7 | SUCCESS =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;&#125;,&quot;changed&quot;: false,&quot;ping&quot;: &quot;pong&quot;&#125;10.0.0.6 | SUCCESS =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;&#125;,&quot;changed&quot;: false,&quot;ping&quot;: &quot;pong&quot;&#125;10.0.0.8 | SUCCESS =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;&#125;,&quot;changed&quot;: false,&quot;ping&quot;: &quot;pong&quot;&#125;root@all (3)[f:5]$ list10.0.0.810.0.0.710.0.0.6root@all (3)[f:5]$ cd websrvsroot@websrvs (2)[f:5]$ list10.0.0.710.0.0.8root@websrvs (2)[f:5]$ forks 10root@websrvs (2)[f:10]$ cd appsrvsroot@appsrvs (2)[f:5]$ yum name=httpd state=presentroot@appsrvs (2)[f:5]$ service name=httpd state=started ansible-playbook此工具用于执行编写好的 playbook 任务范例： 12345678910ansible-playbook hello.ymlcat hello.yml---#hello world yml file- hosts: websrvs remote_user: root gather_facts: no tasks: - name: hello world command: /usr/bin/wall hello world ansible-vault此工具可以用于加密解密yml文件格式： 1ansible-vault [create|decrypt|edit|encrypt|rekey|view] 范例 1234567891011121314151617ansible-vault encrypt hello.yml #加密ansible-vault decrypt hello.yml #解密ansible-vault view hello.yml #查看ansible-vault edit hello.yml #编辑加密文件ansible-vault rekey hello.yml #修改口令ansible-vault create new.yml #创建新文件#执行加密的playbook,交互式输入密码chmod 600 hello.ymlansible-playbook --ask-vault-pass hello.yml#从pass.txt文件中读取密码ansible-playbook --vault-password-file pass.txt hello.yml#从配置文件中取得密码#vi /etc/ansible/ansible.cfg[defaults]ault-password-file=pass.txt#可以直接执行加密文件ansible-playbook hello.yml ansible-galaxyGalaxy 是一个免费网站, 类似于github网站, 网站上发布了很多的共享的roles角色。Ansible 提供了ansible-galaxy命令行工具连接 https://galaxy.ansible.com 网站下载相应的roles, 进行init(初始化、search( 查拘、install(安装、 remove(移除)等操作。 范例： 123456789#搜索项目[root@ansible ~]#ansible-galaxy search lamp#列出所有已安装的galaxyansible-galaxy list#安装galaxy,默认下载到~/.ansible/roles下ansible-galaxy install geerlingguy.mysqlansible-galaxy install geerlingguy.redis#删除galaxyansible-galaxy remove geerlingguy.redis Ansible常用模块2015年12月只270多个模块2016年12年26日ansible 1.9.2 有540个模块2018年01月12日ansible 2.3.8 有1378个模块2018年05月28日ansible 2.5.3 有1562个模块2018年07月15日ansible 2.6.3 有1852个模块2018年11月19日ansible 2.7.2 有2080个模块2020年03月02日ansible 2.9.5 有3387个模块2021年12月22日ansible 2.11.8 有6141个模块2022年06月04日ansible 2.12.6 有6763个模块虽然模块众多，但最常用的模块也就2，30个而已，针对特定业务只需要熟悉10几个模块即可常用模块帮助文档参考： 1234https://docs.ansible.com/ansible/2.9/modules/modules_by_category.htmlhttps://docs.ansible.com/ansible/2.9/modules/list_of_all_modules.htmlhttps://docs.ansible.com/ansible/latest/modules/list_of_all_modules.htmlhttps://docs.ansible.com/ansible/latest/modules/modules_by_category.html Command 模块功能：在远程主机执行命令，此为默认模块，可忽略 -m 选项注意：此命令不支持 $VARNAME &lt; &gt; | ; &amp; 等，可用shell模块实现注意：此模块不具有幂等性常见选项 123chdir=dir #执行命令前,先切换至目录dircreates=file #当file不存在时才会执行removes=file #当file存在时才会执行 范例： 123456789101112131415161718192021[root@ansible ~]#ansible websrvs -m command -a &#x27;chdir=/etc cat centos-release&#x27;10.0.0.7 | CHANGED | rc=0 &gt;&gt;CentOS Linux release 7.7.1908 (Core)10.0.0.8 | CHANGED | rc=0 &gt;&gt;CentOS Linux release 8.1.1911 (Core)[root@ansible ~]#ansible websrvs -m command -a &#x27;chdir=/etc creates=/data/f1.txt cat centos-release&#x27;10.0.0.7 | CHANGED | rc=0 &gt;&gt;CentOS Linux release 7.7.1908 (Core)10.0.0.8 | SUCCESS | rc=0 &gt;&gt;skipped, since /data/f1.txt exists[root@ansible ~]#ansible websrvs -m command -a &#x27;chdir=/etc removes=/data/f1.txt cat centos-release&#x27;10.0.0.7 | SUCCESS | rc=0 &gt;&gt;skipped, since /data/f1.txt does not exist10.0.0.8 | CHANGED | rc=0 &gt;&gt;CentOS Linux release 8.1.1911 (Core)ansible websrvs -m command -a &#x27;service vsftpd start&#x27;ansible websrvs -m command -a &#x27;echo magedu |passwd --stdin wang&#x27;ansible websrvs -m command -a &#x27;rm -rf /data/&#x27;ansible websrvs -m command -a &#x27;echo hello &gt; /data/hello.log&#x27;ansible websrvs -m command -a &quot;echo $HOSTNAME&quot; Shell 模块功能：和command相似，用shell执行命令,支持各种符号,比如:*,$, &gt; , 相当于增强版的command模块注意：此模块不具有幂等性,建议能不能就用此模块,最好使用专用模块常见选项 123chdir=dir #执行命令前,先切换至目录dircreates=file #当file不存在时才会执行removes=file #当file存在时才会执行 范例： 123456789101112131415161718192021222324252627282930[root@ansible ~]#ansible websrvs -m shell -a &quot;echo $HOSTNAME&quot;10.0.0.7 | CHANGED | rc=0 &gt;&gt;ansible10.0.0.8 | CHANGED | rc=0 &gt;&gt;ansible[root@ansible ~]#ansible websrvs -m shell -a &#x27;echo $HOSTNAME&#x27;10.0.0.7 | CHANGED | rc=0 &gt;&gt;centos7.wangxiaochun.com10.0.0.8 | CHANGED | rc=0 &gt;&gt;centos8.localdomain[root@ansible ~]#ansible websrvs -m shell -a &#x27;echo centos | passwd --stdin wang&#x27;10.0.0.7 | CHANGED | rc=0 &gt;&gt;Changing password for user wang.passwd: all authentication tokens updated successfully.10.0.0.8 | CHANGED | rc=0 &gt;&gt;Changing password for user wang.passwd: all authentication tokens updated successfully.[root@ansible ~]#ansible websrvs -m shell -a &#x27;ls -l /etc/shadow&#x27;10.0.0.7 | CHANGED | rc=0 &gt;&gt;---------- 1 root root 889 Mar 2 14:34 /etc/shadow10.0.0.8 | CHANGED | rc=0 &gt;&gt;---------- 1 root root 944 Mar 2 14:34 /etc/shadow[root@ansible ~]#ansible websrvs -m shell -a &#x27;echo hello &gt; /data/hello.log&#x27;10.0.0.7 | CHANGED | rc=0 &gt;&gt;10.0.0.8 | CHANGED | rc=0 &gt;&gt;[root@ansible ~]#ansible websrvs -m shell -a &#x27;cat /data/hello.log&#x27;10.0.0.7 | CHANGED | rc=0 &gt;&gt;hello10.0.0.8 | CHANGED | rc=0 &gt;&gt;hello 注意：调用bash执行命令 类似 cat &#x2F;tmp&#x2F;test.md | awk -F’|’ ‘{print $1,$2}’ &amp;&gt; &#x2F;tmp&#x2F;example.txt 这些复杂命令，即使使用shell也可能会失败，解决办法：写到脚本时，copy到远程，执行，再把需要的结果拉回执行命令的机器范例：将shell模块代替command，设为模块 123[root@ansible ~]#vim /etc/ansible/ansible.cfg#修改下面一行module_name = shell Script 模块功能：在远程主机上运行ansible服务器上的脚本(无需执行权限)注意：此模块不具有幂等性常见选项 1234chdir=dir #执行命令前,先切换至目录dircmd #指定ansible主机的命令creates=file #当file不存在时才会执行removes=file #当file存在时才会执行 范例： 1ansible websrvs -m script -a /data/test.sh Copy 模块功能：复制ansible服务器主控端或远程的本机的文件到远程主机注意: src&#x3D;file 如果是没指明路径,则为当前目录或当前目录下的files目录下的file文件常见选项 12345678src #控制端的源文件路径dest #被控端的文件路径owner #属主group #属组mode #权限backup #是否备份validate #验证成功才会执行copyremote_src #no是默认值,表示src文件在ansible主机,yes表示src文件在远程主机 范例: 12345678910#如目标存在，默认覆盖，此处指定先备ansible websrvs -m copy -a &quot;src=/root/test1.sh dest=/tmp/test2.sh owner=wang mode=600 backup=yes&quot;#指定内容，直接生成目标文件ansible websrvs -m copy -a &quot;content=&#x27;wang 123456\\nxiao 654321\\n&#x27; dest=/etc/rsync.pas owner=root group=root mode=0600&quot;#复制/etc目录自身,注意/etc/后面没有/ansible websrvs -m copy -a &quot;src=/etc dest=/backup&quot;#复制/etc/下的文件，不包括/etc/目录自身,注意/etc/后面有/ansible websrvs -m copy -a &quot;src=/etc/ dest=/backup&quot;#复制/etc/suders,并校验语法ansible websrvs -m copy -a &quot;src=/etc/suders dest=/etc/sudoers.edit remote_src=yes validate=/usr/sbin/visudo -csf %s&quot; Get_url 模块功能: 用于将文件从http、https或ftp下载到被管理机节点上常用参数如下： 123456789101112131415url #下载文件的URL,支持HTTP，HTTPS或FTP协议dest #下载到目标路径（绝对路径），如果目标是一个目录，就用原文件名，如果目标设置了名称就用目标设置的名称owner #指定属主group #指定属组mode #指定权限force #如果yes，dest不是目录，将每次下载文件，如果内容改变替换文件。如果no，则只有在目标不存在时才会下载checksum #对目标文件在下载后计算摘要，以确保其完整性#示例: checksum=&quot;sha256:D98291AC[...]B6DC7B97&quot;,checksum=&quot;sha256:http://example.com/path/sha256sum.txt&quot;url_username #用于HTTP基本认证的用户名。 对于允许空密码的站点，此参数可以不使用`url_password&#x27;url_password #用于HTTP基本认证的密码。 如果未指定`url_username&#x27;参数，则不会使用`url_password&#x27;参数validate_certs #如果“no”，SSL证书将不会被验证。 适用于自签名证书在私有网站上使用timeout #URL请求的超时时间,秒为单位 范例: 下载并MD5验证 1[root@ansible ~]#ansible websrvs -m get_url -a &#x27;url=http://nginx.org/download/nginx-1.18.0.tar.gz dest=/usr/local/src/nginx.tar.gz checksum=&quot;md5:b2d33d24d89b8b1f87ff5d251aa27eb8&quot;&#x27; Fetch 模块功能：从远程主机提取文件至ansible的主控端，copy相反，目前不支持目录常见选项 12src #被控制端的源文件路径,只支持文件dest #ansible控制端的目录路径 范例： 1ansible websrvs -m fetch -a &#x27;src=/root/test.sh dest=/data/scripts&#x27; 范例： 1234567891011121314[root@ansible ~]#ansible all -m fetch -a &#x27;src=/etc/redhat-releasedest=/data/os&#x27;[root@ansible ~]#tree /data/os//data/os/├── 10.0.0.6│ └── etc│ └── redhat-release├── 10.0.0.7│ └── etc│ └── redhat-release└── 10.0.0.8└── etc└── redhat-release6 directories, 3 files File 模块功能：设置文件属性,创建文件,目录和软链接等常见选项 12345678910path #在被控端创建的路径owner #属主group #属组mode #权限state #状态=touch #创建文件=directory #创建目录=link #软链接=hard #硬链接recurse #yes表示递归授权 范例： 1234567891011121314#创建空文件ansible all -m file -a &#x27;path=/data/test.txt state=touch&#x27;ansible all -m file -a &#x27;path=/data/test.txt state=absent&#x27;ansible all -m file -a &quot;path=/root/test.sh owner=wang mode=755&quot;#创建目录ansible all -m file -a &quot;path=/data/mysql state=directory owner=mysql group=mysql&quot;#创建软链接ansible all -m file -a &#x27;src=/data/testfile path|dest|name=/data/testfile-link state=link&#x27;#创建目录ansible all -m file -a &#x27;path=/data/testdir state=directory&#x27;#递归修改目录属性,但不递归至子目录ansible all -m file -a &quot;path=/data/mysql state=directory owner=mysql group=mysql&quot;#递归修改目录及子目录的属性ansible all -m file -a &quot;path=/data/mysql state=directory owner=mysql group=mysql recurse=yes&quot; stat 模块功能：检查文件或文件系统的状态注意：对于Windows目标，请改用win_stat模块 常见选项 1path #文件/对象的完整路径（必须） 常用的返回值判断： 12exists： 判断是否存在isuid： 调用用户的ID与所有者ID是否匹配 范例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@ansible ~]#ansible 127.0.0.1 -m stat -a &#x27;path=/etc/passwd&#x27;127.0.0.1 | SUCCESS =&gt; &#123;&quot;changed&quot;: false,&quot;stat&quot;: &#123;&quot;atime&quot;: 1614601466.7493012,&quot;attr_flags&quot;: &quot;&quot;,&quot;attributes&quot;: [],&quot;block_size&quot;: 4096,&quot;blocks&quot;: 8,&quot;charset&quot;: &quot;us-ascii&quot;,&quot;checksum&quot;: &quot;8f7a9a996d24de98bf1eab4a047f8e89e9c708cf&quot;,&quot;ctime&quot;: 1614334259.4498665,&quot;dev&quot;: 2050,&quot;device_type&quot;: 0,&quot;executable&quot;: false,&quot;exists&quot;: true,&quot;gid&quot;: 0,&quot;gr_name&quot;: &quot;root&quot;,&quot;inode&quot;: 134691833,&quot;isblk&quot;: false,&quot;ischr&quot;: false,&quot;isdir&quot;: false,&quot;isfifo&quot;: false,&quot;isgid&quot;: false,&quot;islnk&quot;: false,&quot;isreg&quot;: true,&quot;issock&quot;: false,&quot;isuid&quot;: false,&quot;mimetype&quot;: &quot;text/plain&quot;,&quot;mode&quot;: &quot;0000&quot;,&quot;mtime&quot;: 1614334259.4498665,&quot;nlink&quot;: 1,&quot;path&quot;: &quot;/etc/passwd&quot;,&quot;pw_name&quot;: &quot;root&quot;,&quot;readable&quot;: true,&quot;rgrp&quot;: false,&quot;roth&quot;: false,&quot;rusr&quot;: false,&quot;size&quot;: 1030,&quot;uid&quot;: 0,&quot;version&quot;: &quot;671641160&quot;,&quot;wgrp&quot;: false,&quot;woth&quot;: false,&quot;writeable&quot;: true,&quot;wusr&quot;: false,&quot;xgrp&quot;: false,&quot;xoth&quot;: false,&quot;xusr&quot;: false&#125;&#125; 案例： 123456789- name: install | Check if file is already configured. stat: path=&#123;&#123; nginx_file_path &#125;&#125; connection: local register: nginx_file_result- name: install | Download nginx file get_url: url=&#123;&#123; nginx_file_url &#125;&#125; dest=&#123;&#123; software_files_path &#125;&#125; validate_certs=no connection: local when:，not. nginx_file_result.stat.exists 范例: 1234567891011121314151617181920212223242526272829303132333435363738394041[root@ansible ansible]#cat stat.yml---- hosts: websrvs tasks: - name: check file stat: path=/data/mysql register: st - name: debug debug: msg: &quot;/data/mysql is not exist&quot; when: not st.stat.exists[root@ansible ansible]#ansible-playbook stat.ymlPLAY [websrvs]***********************************************************************************************************************TASK [Gathering Facts]***************************************************************************************************************ok: [10.0.0.7]ok: [10.0.0.8]TASK [check file]********************************************************************************************************************ok: [10.0.0.7]ok: [10.0.0.8]TASK [debug]*************************************************************************************************************************ok: [10.0.0.7] =&gt; &#123;&quot;msg&quot;: &quot;/data/mysql is not exist&quot;&#125;ok: [10.0.0.8] =&gt; &#123;&quot;msg&quot;: &quot;/data/mysql is not exist&quot;&#125;PLAY RECAP***************************************************************************************************************************10.0.0.7 : ok=3 changed=0 unreachable=0 failed=0skipped=0 rescued=0 ignored=010.0.0.8 : ok=3 changed=0 unreachable=0 failed=0skipped=0 rescued=0 ignored=0 unarchive 模块功能：解包解压缩实现有两种用法： 将ansible主机上的压缩包传到远程主机后解压缩至特定目录，设置remote_src&#x3D;no,此为默认值,可省略 将远程本主机上或非ansible的其它主机的某个压缩包解压缩到远程主机本机的指定路径下，需要设置remote_src&#x3D;yes 常见参数： 123456remote_src #和copy功能一样且选项互斥，yes表示源文件在远程被控主机或其它非ansible的其它主机上，no表示文件在ansible主机上,默认值为no, 此选项代替copy选项copy #默认为yes，当copy=yes，拷贝的文件是从ansible主机复制到远程主机上，如果设置为copy=no，会在远程主机上寻找src源文件,此选项已废弃src #源路径，可以是ansible主机上的路径，也可以是远程主机(被管理端或者第三方主机)上的路径，如果是远程主机上的路径，则需要设置remote_src=yesdest #远程主机上的目标路径mode #设置解压缩后的文件权限creates=/path/file #当绝对路径/path/file不存在时才会执行 范例： 123456789ansible all -m unarchive -a &#x27;src=/data/foo.tgz dest=/var/lib/foo owner=wang group=bin&#x27;ansible all -m unarchive -a &#x27;src=/tmp/foo.zip dest=/data mode=0777&#x27;ansible all -m unarchive -a &#x27;src=https://example.com/example.zip dest=/data &#x27;ansible websrvs -m unarchive -a &#x27;src=https://releases.ansible.com/ansible/ansible-2.1.6.0-0.1.rc1.tar.gz dest=/data/ owner=root remote_src=yes&#x27;ansible websrvs -m unarchive -a &#x27;src=http://nginx.org/download/nginx- 1.18.0.tar.gz dest=/usr/local/src/ remote_src=yes&#x27;&#x27; Archive 模块功能：打包压缩保存在被管理节点 常见选项 123path #压缩的文件或目录dest #压缩后的文件format #压缩格式,支持gz,bz2,xz,tar,zip 范例： 1ansible websrvs -m archive -a &#x27;path=/var/log/ dest=/data/log.tar.bz2 format=bz2 owner=wang mode=0600&#x27; Hostname 模块功能：管理主机名常见选项 1name #修改后的主机名称 范例： 12ansible node1 -m hostname -a &quot;name=websrv&quot;ansible 10.0.0.18 -m hostname -a &#x27;name=node18.wang.org&#x27; Cron 模块功能：计划任务支持时间：minute，hour，day，month，weekday常见选项 123456name #描述脚本的作用minute #分钟hour #小时weekday #周user #任务由哪个用户运行；默认rootjob #任务 范例： 123456789101112131415161718#备份数据库脚本[root@centos8 ~]#cat /root/mysql_backup.sh#!/bin/bashmysqldump -A -F --single-transaction --master-data=2 -q -uroot |gzip &gt; /data/mysql_`date +%F_%T`.sql.gz#创建任务ansible 10.0.0.8 -m cron -a &#x27;hour=2 minute=30 weekday=1-5 name=&quot;backup mysql&quot; job=/root/mysql_backup.sh&#x27;ansible websrvs -m cron -a &quot;minute=*/5 job=&#x27;/usr/sbin/ntpdate ntp.aliyun.com &amp;&gt;/dev/null&#x27; name=Synctime&quot;#禁用计划任务ansible websrvs -m cron -a &quot;minute=*/5 job=&#x27;/usr/sbin/ntpdate 172.20.0.1 &amp;&gt;/dev/null&#x27; name=Synctime disabled=yes&quot;#启用计划任务ansible websrvs -m cron -a &quot;minute=*/5 job=&#x27;/usr/sbin/ntpdate 172.20.0.1 &amp;&gt; /dev/null&#x27; name=Synctime disabled=no&quot;#删除任务ansible websrvs -m cron -a &quot;name=&#x27;backup mysql&#x27; state=absent&quot;ansible websrvs -m cron -a &#x27;state=absent name=Synctime&#x27; Yum 和 Apt 模块功能：管理软件包yum 管理软件包，只支持RHEL，CentOS，fedora，不支持Ubuntu其它版本apt 模块管理 Debian 相关版本的软件包yum常见选项 12345678910name #软件包名称state #状态=present #安装,此为默认值=absent #删除=latest #最新版list #列出指定包enablerepo #启用哪个仓库安装disablerepo #不使用哪些仓库的包exclude #排除指定的包validate #是否检验,默认为yes 范例： 1234567891011121314[root@ansible ~]#ansible websrvs -m yum -a &#x27;name=httpd state=present&#x27;#安装zabbix agent rpm包[root@ansible ~]#ansible websrvs -m yum -a &#x27;name=https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/5.0/rhel/8/x86_64/zabbix-agent2-5.0.24-1.el8.x86_64.rpm state=present validate_certs=no&#x27;#启用epel源进行安装[root@ansible ~]#ansible websrvs -m yum -a &#x27;name=nginx state=present enablerepo=epel&#x27;#升级除kernel和foo开头以外的所有包[root@ansible ~]#ansible websrvs -m yum -a &#x27;name=* state=lastest exclude=kernel*,foo*&#x27;#删除[root@ansible ~]#ansible websrvs -m yum -a &#x27;name=httpd state=absent&#x27;[root@ansible ~]#ansible websrvs -m yum -a &#x27;name=sl,cowsay&#x27; yum_repository 模块功能: 此模块实现yum的仓库配置管理常见选项 123456name #仓库iddescription #仓库描述名称,对应配置文件中的name=baseurl #仓库的地址gpgcheck #验证开启gpgkey #仓库公钥路径state=absen #删除 范例： 12345678ansible websrvs -m yum_repository -a &#x27;name=ansible_nginx description=&quot;nginx repo&quot; baseurl=&quot;http://nginx.org/packages/centos/$releasever/$basearch/&quot; gpgcheck=yes gpgkey=&quot;https://nginx.org/keys/nginx_signing.key&quot;&#x27;[root@rocky8 ~]#cat /etc/yum.repos.d/ansible_nginx.repo[ansible_nginx]baseurl = http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck = 1gpgkey = https://nginx.org/keys/nginx_signing.keyname = nginx repo Service 模块此模块和sytemd功能相似,选项很多相同功能：管理服务常见选项 12345678name #服务名称state #服务状态=started #启动=stopped #停止=restarted #重启=reloaded #重载enabled #开启自启动daemon_reload #加载新的配置文件,适用于systemd模块 范例： 12345678ansible all -m service -a &#x27;name=httpd state=started enabled=yes&#x27;ansible all -m service -a &#x27;name=httpd state=stopped&#x27;ansible all -m service -a &#x27;name=httpd state=reloaded&#x27;ansible all -m shell -a &quot;sed -i &#x27;s/^Listen 80/Listen 8080/&#x27;/etc/httpd/conf/httpd.conf&quot;ansible all -m service -a &#x27;name=httpd state=restarted&#x27;#重启动指定网卡服务ansible all -m service -a &#x27;name=network state=absent args=eth0&#x27; User 模块功能：管理用户常见选项 1234567891011121314name #创建的名称uid #指定uidgroup #指定基本组shell #登录shell类型默认/bin/bashcreate_home #是否创建家目录password #设定对应的密码，必须是加密后的字符串才行，否则不生效system #yes表示系统用户groups #附加组append #追加附加组使用,yes表示增加新的附加组state #absen删除remove #yes表示删除用户时将家目录一起删除generate_ssh_key #创建私钥ssh_keyu_bits #私钥位数ssh_key_file #私钥文件路径 范例： 123456789101112#创建用户ansible all -m user -a &#x27;name=user1 comment=&quot;test user&quot; uid=2048 home=/app/user1group=root&#x27;ansible all -m user -a &#x27;name=nginx comment=nginx uid=88 group=nginxgroups=&quot;root,daemon&quot; shell=/sbin/nologin system=yes create_home=nohome=/data/nginx non_unique=yes&#x27;#remove=yes表示删除用户及家目录等数据,默认remove=noansible all -m user -a &#x27;name=nginx state=absent remove=yes&#x27;#生成123456加密的密码ansible localhost -m debug -a &quot;msg=&#123;&#123; &#x27;123456&#x27;| password_hash(&#x27;sha512&#x27;,&#x27;salt&#x27;)&#125;&#125;&quot; localhost | SUCCESS =&gt; &#123; &quot;msg&quot;: &quot;$6$salt$MktMKPZJ6t59GfxcJU20DwcwQzfMvOlHFVZiOVD71w.&quot;&#125;#用上面创建的密码创建用户ansible websrvs -m user -a &#x27;name=www group=www system=yes shell=/sbin/nlogin password=&quot;$6$salt$MktMKPZJ6t59GfxcJU20DwcwQzfMvOlHFVZiOVD71w.&quot;&#x27;#创建用户test,并生成4096bit的私钥ansible websrvs -m user -a &#x27;name=test generate_ssh_key=yes ssh_key_bits=4096 ssh_key_file=.ssh/id_rsa&#x27; Group 模块功能：管理组常见选项 12345name #指定组名称gid #指定gidstate=present #创建,默认=absent #删除 范例： 1234#创建组ansible websrvs -m group -a &#x27;name=nginx gid=88 system=yes&#x27;#删除组ansible websrvs -m group -a &#x27;name=nginx state=absent&#x27; Lineinfile 模块ansible在使用sed进行替换时，经常会遇到需要转义的问题，而且ansible在遇到特殊符号进行替换时，会存在问题，无法正常进行替换 。 ansible自身提供了两个模块：lineinfile模块和replace模块，可以方便的进行替换一般在ansible当中去修改某个文件的单行进行替换的时候需要使用lineinfile模块功能：相当于sed，主要用于修改一行的文件内容常见选项 1234567891011121314151617path #被控端文件的路径regexp #正则匹配语法格式,表示被替换的内容line #替换为的内容state #absent表示删除insertafter #插入到替换内容前面,如和regexp同时存在,只在没找到与regexp匹配时才使用insertafterinsertbefore #插入到替换内容后面,如和regexp同时存在,只在没找到与regexp匹配时才使用insertafterbackrefs #支持后面引用,yes和nobackup #修改前先备份create #如果文件不存在,则创建,默认不存在会出错mode #指定权限owner #指定用户group #指定组#注意regexp参数 ：使用正则表达式匹配对应的行，当替换文本时，如果有多行文本都能被匹配，则只有最后面被匹配到的那行文本才会被替换，当删除文本时，如果有多行文本都能被匹配，这么这些行都会被删除。 注意: 如果想进行多行匹配进行替换需要使用replace模块范例： 12345678910111213141516171819202122232425262728#修改监听端口ansible websrvs -m lineinfile -a &quot;path=/etc/httpd/conf/httpd.conf regexp=&#x27;^Listen&#x27; line=&#x27;Listen 8080&#x27;&quot;#修改SELinuxansible all -m lineinfile -a &quot;path=/etc/selinux/config regexp=&#x27;^SELINUX=&#x27;line=&#x27;SELINUX=disabled&#x27;&quot;#添加网关ansible webservers -m lineinfile -a &#x27;path=/etc/sysconfig/network-scripts/ifcfg-eth0 line=&quot;GATEWAY=10.0.0.254&quot;&#x27;#给主机增加一个网关，但需要增加到NAME=下面ansible webservers -m lineinfile -a &#x27;path=/etc/sysconfig/network-scripts/ifcfg-eth0 insertafter=&quot;^NAME=&quot; line=&quot;GATEWAY=10.0.0.254&quot;&#x27;#效果如下cat /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0NAME=eth0GATEWAY=10.0.0.254#给主机增加一个网关，但需要增加到NAME=上面ansible webservers -m lineinfile -a &#x27;path=/etc/sysconfig/network-scripts/ifcfg-eth0 insertbefore=&quot;^NAME=&quot; line=&quot;GATEWAY=10.0.0.254&quot;&#x27;#效果如下cat /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0GATEWAY=10.0.0.254NAME=eth0#删除网关ansible webservers -m lineinfile -a &#x27;path=/etc/sysconfig/network-scripts/ifcfg-eth0 regexp=&quot;^GATEWAY&quot; state=absent&#x27;#删除#开头的行ansible all -m lineinfile -a &#x27;dest=/etc/fstab state=absent regexp=&quot;^#&quot;&#x27; Replace 模块该模块有点类似于sed命令，主要也是基于正则进行匹配和替换，建议使用功能: 多行修改替换常见选项 123456789path #被控端文件的路径regexp #正则匹配语法格式,表示被替换的内容replace #替换为的内容after #插入到替换内容前面,before #插入到替换内容后面backup #修改前先备份mode #指定权限owner #指定用户group #指定组 范例 12ansible all -m replace -a &quot;path=/etc/fstab regexp=&#x27;^(UUID.*)&#x27; replace=&#x27;#\\1&#x27;&quot;ansible all -m replace -a &quot;path=/etc/fstab regexp=&#x27;^#(UUID.*)&#x27; replace=&#x27;\\1&#x27;&quot; SELinux 模块功能: 该模块管理 SELInux 策略常见选项 12policy #指定SELINUXTYPE=targetedstate #指定SELINUX=disabled 范例 123456789101112131415161718192021222324252627[root@rocky ansible-apps]# ansible 192.168.32.132 -m selinux -a &#x27;state=disabled&#x27;192.168.32.132 | FAILED! =&gt; &#123; &quot;msg&quot;: &quot;The module selinux was redirected to ansible.posix.selinux, which could not be loaded.&quot;&#125;# ansible版本2.13.3出现如下错误 &quot;msg&quot;: &quot;The module selinux was redirected to ansible.posix.selinux, which could not be loaded.&quot; # 解决方法 [root@rocky ansible-apps]# ansible-galaxy collection install ansible.posix# 再次执行，显示成功[root@rocky ansible-apps]# ansible 192.168.32.132 -m selinux -a &#x27;state=disabled&#x27;[WARNING]: SELinux state temporarily changed from &#x27;enforcing&#x27; to &#x27;permissive&#x27;. State change will take effect next reboot.192.168.32.132 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot; &#125;, &quot;changed&quot;: true, &quot;configfile&quot;: &quot;/etc/selinux/config&quot;, &quot;msg&quot;: &quot;Config SELinux state changed from &#x27;enforcing&#x27; to &#x27;disabled&#x27;&quot;, &quot;policy&quot;: &quot;targeted&quot;, &quot;reboot_required&quot;: true, &quot;state&quot;: &quot;disabled&quot;&#125; reboot 模块功能: 重启常见选项 12345msg #重启提示pre_reboot_delay #重启前延迟时间的秒数post_reboot_delay #重启后延迟时间的秒数后,再验证系统正常启动reboot_timeout #重启后延迟时间再执行测试成功与否的命令test_command #执行测试成功与否的命令 范例: 1[root@ansible ~]#ansible websrvs -m reboot -a &#x27;msg=&quot;host will be reboot&quot;&#x27; mount 模块功能: 挂载和卸载文件系统常见选项 123456789src #源设备路径，或网络地址path #挂载至本地哪个路径下fstype #设备类型； nfsopts #挂载的选项state #挂载还是卸载=present #永久挂载，但没有立即生效=absent #卸载临时挂载,并删除永久挂载=mounted #临时挂载=unmounted #临时卸载 范例: 12345678#修改fstab文件永久挂载,但不立即生效mount websrvs -m mount -a &#x27;src=&quot;UUID=b3e48f45-f933-4c8e-a700-22a159ec9077&quot; path=/home fstype=xfs opts=noatime state=present&#x27;#临时取消挂载mount websrvs -m mount -a &#x27;path=/home fstype=xfs opts=noatime state=unmounted&#x27;#永久挂载,并立即生效ansible websrvs -m mount -a &#x27;src=10.0.0.8:/data/wordpress path=/var/www/html/wp- content/uploads opts=&quot;_netdev&quot; state=mounted&#x27;#永久卸载,并立即生效ansible websrvs -m mount -a &#x27;src=10.0.0.8:/data/wordpress path=/var/www/html/wp- content/uploads state=absent&#x27; Setup 模块功能： setup 模块来收集主机的系统信息，这些 facts 信息可以直接以变量的形式使用，但是如果主机较多，会影响执行速度可以使用 gather_facts: no 来禁止 Ansible 收集 facts 信息常见选项 1filter #指定过滤条件 范例: 1234567891011121314151617ansible all -m setupansible all -m setup -a &quot;filter=ansible_nodename&quot;ansible all -m setup -a &quot;filter=ansible_hostname&quot; # 主机名称ansible all -m setup -a &quot;filter=ansible_domain&quot;ansible all -m setup -a &quot;filter=ansible_memtotal_mb&quot;ansible all -m setup -a &quot;filter=ansible_memory_mb&quot;ansible all -m setup -a &quot;filter=ansible_memfree_mb&quot;ansible all -m setup -a &quot;filter=ansible_os_family&quot;ansible all -m setup -a &quot;filter=ansible_distribution&quot;ansible all -m setup -a &quot;filter=ansible_distribution_major_version&quot;ansible all -m setup -a &quot;filter=ansible_distribution_version&quot;ansible all -m setup -a &quot;filter=ansible_processor_vcpus&quot;ansible all -m setup -a &quot;filter=ansible_all_ipv4_addresses&quot;ansible all -m setup -a &quot;filter=ansible_architecture&quot;ansible all -m setup -a &quot;filter=ansible_uptime_seconds&quot;ansible all -m setup -a &quot;filter=ansible_processor*&quot;ansible all -m setup -a &#x27;filter=ansible_env&#x27; 范例： 1234567891011121314151617181920212223[root@ansible ~]#ansible all -m setup -a &#x27;filter=ansible_python_version&#x27;10.0.0.7 | SUCCESS =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;ansible_python_version&quot;: &quot;2.7.5&quot;,&quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;&#125;,&quot;changed&quot;: false&#125;10.0.0.6 | SUCCESS =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;ansible_python_version&quot;: &quot;2.6.6&quot;,&quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot;&#125;,&quot;changed&quot;: false&#125;10.0.0.8 | SUCCESS =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;ansible_python_version&quot;: &quot;3.6.8&quot;,&quot;discovered_interpreter_python&quot;: &quot;/usr/libexec/platform-python&quot;&#125;,&quot;changed&quot;: false&#125;[root@ansible ~]# 范例：取IP地址 1234567891011121314151617181920212223242526272829303132333435#取所有IPansible 10.0.0.101 -m setup -a &#x27;filter=ansible_all_ipv4_addresses&#x27;10.0.0.101 | SUCCESS =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;ansible_all_ipv4_addresses&quot;: [&quot;192.168.0.1&quot;,&quot;192.168.0.2&quot;,&quot;192.168.64.238&quot;,&quot;192.168.13.36&quot;,&quot;10.0.0.101&quot;,&quot;172.16.1.0&quot;,&quot;172.17.0.1&quot;]&#125;,&quot;changed&quot;: false&#125;#取默认IPansible all -m setup -a &#x27;filter=&quot;ansible_default_ipv4&quot;&#x27;10.0.0.101 | SUCCESS =&gt; &#123;&quot;ansible_facts&quot;: &#123;&quot;ansible_default_ipv4&quot;: &#123;&quot;address&quot;: &quot;10.0.0.101&quot;,&quot;alias&quot;: &quot;eth0&quot;,&quot;broadcast&quot;: &quot;10.0.0.255&quot;,&quot;gateway&quot;: &quot;10.0.0.2&quot;,&quot;interface&quot;: &quot;eth0&quot;,&quot;macaddress&quot;: &quot;00:0c:29:e8:c7:9b&quot;,&quot;mtu&quot;: 1500,&quot;netmask&quot;: &quot;255.255.255.0&quot;,&quot;network&quot;: &quot;10.0.0.0&quot;,&quot;type&quot;: &quot;ether&quot;&#125;&#125;,&quot;changed&quot;: false&#125; debug 模块功能: 此模块可以用于输出信息,并且通过 msg 定制输出的信息内容,功能类似于echo命令注意: msg后面的变量有时需要加 “ “ 引起来常见选项 123msg #指定命令输出的信息var #指定变量名,和msg互斥verbosity #详细度 范例: debug 模块默认输出Hello world 1234567891011121314151617181920212223242526272829[root@ansible ~]#ansible 10.0.0.18 -m debug10.0.0.18 | SUCCESS =&gt; &#123;&quot;msg&quot;: &quot;Hello world!&quot;&#125;[root@ansible ansible]#cat debug.yml---- hosts: websrvstasks:- name: output Hello worlddebug:#默认没有指定msg,默认输出&quot;Hello world!&quot;[root@ansible ansible]#ansible-playbook debug.yml.....TASK [output variables]**************************************************************************************************************ok: [10.0.0.7] =&gt; &#123;&quot;msg&quot;: &quot;Hello world!&quot;&#125;ok: [10.0.0.8] =&gt; &#123;&quot;msg&quot;: &quot;Hello world!&quot;&#125;PLAY RECAP***************************************************************************************************************************10.0.0.7 : ok=2 changed=0 unreachable=0 failed=0skipped=0 rescued=0 ignored=010.0.0.8 : ok=2 changed=0 unreachable=0 failed=0skipped=0 rescued=0 ignored=0 范例: 利用debug 模块输出变量 123456789101112131415161718192021222324252627282930313233[root@centos8 ~]#cat debug.yaml---- hosts: websrvstasks:- name: output variablesdebug:msg: Host &quot;&#123;&#123; ansible_nodename &#125;&#125;&quot; Ip &quot;&#123;&#123; ansible_default_ipv4.address&#125;&#125;&quot;[root@centos8 ~]#ansible-playbook debug.yamlPLAY [websrvs]***********************************************************************************************************************TASK [Gathering Facts]***************************************************************************************************************ok: [10.0.0.7]ok: [10.0.0.8]TASK [output variables]**************************************************************************************************************ok: [10.0.0.7] =&gt; &#123;&quot;msg&quot;: &quot;Host \\&quot;centos7.wangxiaochun.com\\&quot; Ip \\&quot;10.0.0.7\\&quot;&quot;&#125;ok: [10.0.0.8] =&gt; &#123;&quot;msg&quot;: &quot;Host \\&quot;centos8.wangxiaochun.com\\&quot; Ip \\&quot;10.0.0.8\\&quot;&quot;&#125;PLAY RECAP***************************************************************************************************************************10.0.0.7 : ok=2 changed=0 unreachable=0 failed=0skipped=0 rescued=0 ignored=010.0.0.8 : ok=2 changed=0 unreachable=0 failed=0skipped=0 rescued=0 ignored=0 范例: 显示字符串特定字符 123456789101112131415161718# cat debug.yml- hosts: all gather_facts: no vars: a: &quot;12345&quot; tasks: - debug: msg: - &quot;&#123;&#123;a[0]&#125;&#125;&quot; - &quot;&#123;&#123;a[1]&#125;&#125;&quot; - &quot;&#123;&#123;a[2]&#125;&#125;&quot;#定义了一个字符串变量a，如果想要获取a字符串的第3个字符，则可以使用”a[2]”获取，索引从0开始，执行上例playbook，debug的输出信息如下：TASK [debug] *************************ok: [test1] =&gt; &#123;&quot;msg&quot;: &quot;1&quot;&quot;msg&quot;: &quot;2&quot;&quot;msg&quot;: &quot;3&quot;&#125; sysctl 模块功能: 修改内核参数常见选项 1234name #内核参数value #指定值state #是否保存在sysctl.conf文件中,默认presentsysctl_set #使用sysctl -w 验证值生效 范例: 1ansible websrvs -m sysctl -a &#x27;name=net.ipv4.ip_forward value=1 state=present&#x27; 范例: 内核参数优化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748- name: Change Port Range sysctl: name: net.ipv4.ip_local_port_range value: &#x27;1024 65000&#x27; sysctl_set: yes- name: Enabled Forward sysctl: name: net.ipv4.ip_forward value: &#x27;1&#x27; sysctl_set: yes- name: Enabled tcp_reuse sysctl: name: net.ipv4.tcp_tw_reuse value: &#x27;1&#x27; sysctl_set: yes- name: Chanage tcp tw_buckets sysctl: name: net.ipv4.tcp_max_tw_buckets value: &#x27;5000&#x27; sysctl_set: yes- name: Chanage tcp_syncookies sysctl: name: net.ipv4.tcp_syncookies value: &#x27;1&#x27; sysctl_set: yes- name: Chanage tcp max_syn_backlog sysctl: name: net.ipv4.tcp_max_syn_backlog value: &#x27;8192&#x27; sysctl_set: yes- name: Chanage tcp Established Maxconn sysctl: name: net.core.somaxconn value: &#x27;32768&#x27; sysctl_set: yes state: present- name: Chanage tcp_syn_retries sysctl: name: net.ipv4.tcp_syn_retries value: &#x27;2&#x27; sysctl_set: yes state: present- name: Chanage net.ipv4.tcp_synack_retries sysctl: name: net.ipv4.tcp_synack_retries value: &#x27;2&#x27; sysctl_set: yes state: presen pam_limits功能: 管理资源限制范例 123456789- name: Change Limit /etc/security/limit.conf pam_limits: domain: &quot;*&quot; limit_type: &quot;&#123;&#123; item.limit_type &#125;&#125;&quot; limit_item: &quot;&#123;&#123; item.limit_item &#125;&#125;&quot; value: &quot;&#123;&#123; item.value &#125;&#125;&quot; loop: - &#123; limit_type: &#x27;soft&#x27;, limit_item: &#x27;nofile&#x27;,value: &#x27;100000&#x27; &#125; - &#123; limit_type: &#x27;hard&#x27;, limit_item: &#x27;nofile&#x27;,value: &#x27;10000&#x27; &#125; apt_repository 模块功能: 此模块实现apt的仓库配置管理常见选项 1234repo #仓库信息state #添加或删除update_cache #是否apt update,默认yesfilename #仓库文件,默认放在/etc/apt/sources.list.d/file.list 范例: 1234ansible ubuntu-servers -m apt_repository -a &#x27;repo=&quot;debhttp://archive.canonical.com/ubuntu focal partner&quot; filename=google-chrome&#x27;[root@ubuntu2004 ~]#cat /etc/apt/sources.list.d/google-chrome.listdeb http://archive.canonical.com/ubuntu focal partner apt_key 模块功能: 添加和删除apt key常见选项 12url #key路径state #添加或删除 范例: 生成ceph仓库配置 12345678910#先导入key,注意先后顺序ansible ubuntu-servers -m apt_key -a&#x27;url=https://download.ceph.com/keys/release.asc state=present&#x27;#再生成apt配置,如果不导入key此步会出错ansible ubuntu-servers -m apt_repository -a &#x27;repo=&quot;debhttp://mirror.tuna.tsinghua.edu.cn/ceph/debian-pacific focal main&quot;filename=ansible_ceph&#x27;#验证结果[root@ubuntu2004 ~]#cat /etc/apt/sources.list.d/ansible_ceph.listdeb http://mirror.tuna.tsinghua.edu.cn/ceph/debian-pacific focal main 其它模块ansible 还提供了很多针对各种应用的模块,比如 123456789nginx_status_infonginx_status_factsmysql_db #需要安装MySQL-python包mysql_user #需要安装MySQL-python包redismongodb*postgresql*haproxygit","categories":[{"name":"Ansible","slug":"Ansible","permalink":"http://snippet.itshare.work/categories/Ansible/"}],"tags":[],"keywords":[{"name":"Ansible","slug":"Ansible","permalink":"http://snippet.itshare.work/categories/Ansible/"}]},{"title":"常用shell脚本","slug":"常用shell脚本","date":"2023-01-11T13:04:04.000Z","updated":"2023-02-25T10:17:47.465Z","comments":true,"path":"2023/01/11/常用shell脚本/","link":"","permalink":"http://snippet.itshare.work/2023/01/11/%E5%B8%B8%E7%94%A8shell%E8%84%9A%E6%9C%AC/","excerpt":"运维常用shell脚本","text":"显示系统信息123456789101112131415161718192021#!/bin/bash#HOSTNAME=`hostname`IP=`ip a show ens33 | grep &quot;inet&quot; | grep -v &quot;inet6&quot; | awk &#x27;&#123;print $2&#125;&#x27; | cut -d&#x27;/&#x27; -f1`SYSTEM=`cat /etc/centos-release`CORE=`uname -r`CPU=`cat /proc/cpuinfo | grep &#x27;model name&#x27; |uniq | cut -d: -f2`MEMORY=`free -mh | grep -i &quot;mem&quot; | awk &#x27;&#123;print$2&#125;&#x27;`DISKNUM=`fdisk -l | grep -i &quot;/dev&quot; | grep -i &quot;disk&quot; | wc -l`systemname=(&quot;HOSTNAME&quot; &quot;IP&quot; &quot;SYSTEM VERSION&quot; &quot;CORE VERSION&quot; &quot;CPU&quot; &quot;MEMORY SIZE&quot;)systeminfo=(&quot;$HOSTNAME&quot; &quot;$IP&quot; &quot;$SYSTEM&quot; &quot;$CORE&quot; &quot;$CPU&quot; &quot;$MEMORY&quot;)for s in `seq 1 $DISKNUM`;do eval DISK$s=`fdisk -l | grep -i &quot;/dev&quot; | grep -i &quot;disk&quot; | head -$s | tail -1| awk &#x27;&#123;print $2$3$4&#125;&#x27; | cut -d&#x27;,&#x27; -f1` eval systeminfo[$(($s+5))]=&#x27;$&#x27;DISK$s systemname[$(($s+5))]=&quot;DISK$s SIZE&quot;donefor i in $&#123;!systeminfo[*]&#125;;do echo &quot;--------------------------------------------------------------&quot; printf &quot;|%-15s| %-43s|\\n&quot; &quot;$&#123;systemname[$i]&#125;&quot; &quot;$&#123;systeminfo[$i]&#125;&quot;doneecho &quot;--------------------------------------------------------------&quot;","categories":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}]},{"title":"Nginx核心配置文件","slug":"Nginx核心配置文件","date":"2023-01-10T01:58:09.000Z","updated":"2023-01-10T08:34:53.877Z","comments":true,"path":"2023/01/10/Nginx核心配置文件/","link":"","permalink":"http://snippet.itshare.work/2023/01/10/Nginx%E6%A0%B8%E5%BF%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","excerpt":"nginx 官方帮助文档，http://nginx.org/en/docs/","text":"Nginx核心配置文件配置文件说明nginx官网文档说明 1http://nginx.org/en/docs/ tengine帮助文档 1http://tengine.taobao.org/nginx_docs/cn/docs Nginx的配置文件的组成部分： 主配置文件：nginx.conf 子配置文件: include conf.d&#x2F;*.conf fastcgi， uwsgi，scgi 等协议相关的配置文件 mime.types：支持的mime类型，MIME(Multipurpose Internet Mail Extensions)多用途互联网邮 件扩展类型，MIME消息能包含文本、图像、音频、视频以及其他应用程序专用的数据，是设定某 种扩展名的文件用一种应用程序来打开的方式类型，当该扩展名文件被访问的时候，浏览器会自动 使用指定应用程序来打开。多用于指定一些客户端自定义的文件名，以及一些媒体文件打开方式。 MIME参考文档：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_ Types nginx 配置文件格式说明 12345678配置文件由指令与指令块构成每条指令以;分号结尾，指令与值之间以空格符号分隔可以将多条指令放在同一行,用分号分隔即可,但可读性差,不推荐指令块以&#123; &#125;大括号将多条指令组织在一起,且可以嵌套指令块include语句允许组合多个配置文件以提升可维护性使用#符号添加注释，提高可读性使用$符号使用变量部分指令的参数支持正则表达式 Nginx主配置文件的配置指令方式 1234567directive value [value2 ...];注意(1) 指令必须以分号结尾(2) 支持使用配置变量 内建变量：由Nginx模块引入，可直接引用 自定义变量：由用户使用set命令定义,格式: set variable_name value; 引用变量：$variable_name 主配置文件结构：四部分 12345678910111213141516171819main block：主配置段，即全局配置段，对http,mail都有效#事件驱动相关的配置event &#123; ...&#125; #http/https 协议相关配置段http &#123; ...&#125; #默认配置文件不包括下面两个块#mail 协议相关配置段mail &#123; ...&#125; #stream 服务器相关配置段stream &#123; ...&#125; 默认的nginx.conf配置文件格式说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#全局配置端，对全局生效，主要设置nginx的启动用户/组，启动的工作进程数量，工作模式，Nginx的PID路径，日志路径等。user nginx nginx;worker_processes 1; #启动工作进程数数量events &#123; #events设置快，主要影响nginx服务器与用户的网络连接，比如是否允许同时接受多个网络连接，使用哪种事件驱动模型处理请求，每个工作进程可以同时支持的最大连接数，是否开启对多工作进程下的网络连接进行序列化等。 worker_connections 1024; #设置单个nginx工作进程可以接受的最大并发，作为web服务器的时候最大并发数为worker_connections * worker_processes，作为反向代理的时候为(worker_connections * worker_processes)/2&#125;http &#123; #http块是Nginx服务器配置中的重要部分，缓存、代理和日志格式定义等绝大多数功能和第三方模块都可以在这设置，http块可以包含多个server块，而一个server块中又可以包含多个location块，server块可以配置文件引入、MIME-Type定义、日志自定义、是否启用sendfile、连接超时时间和单个链接的请求上限等。 include mime.types; default_type application/octet-stream; sendfile on; #作为web服务器的时候打开sendfile加快静态文件传输，指定是否使用sendfile系统调用来传输文件,sendfile系统调用在两个文件描述符之间直接传递数据(完全在内核中操作)，从而避免了数据在内核缓冲区和用户缓冲区之间的拷贝，操作效率很高，被称之为零拷贝，硬盘 &gt;&gt;kernel buffer (快速拷贝到kernelsocket buffer) &gt;&gt;协议栈。 keepalive_timeout 65; #长连接超时时间，单位是秒 server &#123; #设置一个虚拟机主机，可以包含自己的全局快，同时也可以包含多个location模块。比如本虚拟机监听的端口、本虚拟机的名称和IP配置，多个server 可以使用一个端口，比如都使用80端口提供web服务、 listen 80; #配置server监听的端口 server_name localhost; #本server的名称，当访问此名称的时候nginx会调用当前serevr内部的配置进程匹配。 location / &#123; #location其实是server的一个指令，为nginx服务器提供比较多而且灵活的指令，都是在location中体现的，主要是基于nginx接受到的请求字符串，对用户请求的UIL进行匹配，并对特定的指令进行处理，包括地址重定向、数据缓存和应答控制等功能都是在这部分实现，另外很多第三方模块的配置也是在location模块中配置。 root html; #相当于默认页面的目录名称，默认是安装目录的相对路径，可以使用绝对路径配置。 index index.html index.htm; #默认的页面文件名称 &#125; error_page 500 502 503 504 /50x.html; #错误页面的文件名称 location = /50x.html &#123; #location处理对应的不同错误码的页面定义到/50x.html，这个跟对应其server中定义的目录下。 root html; #定义默认页面所在的目录 &#125; &#125; #和邮件相关的配置#mail &#123;# ...# &#125; mail 协议相关配置段#tcp代理配置，1.9版本以上支持#stream &#123;# ...# &#125; stream 服务器相关配置段#导入其他路径的配置文件#include /apps/nginx/conf.d/*.conf&#125; 全局配置 Main 全局配置段常见的配置指令分类 正常运行必备的配置 优化性能相关的配置 用于调试及定位问题相关的配置 事件驱动相关的配置 全局配置说明: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455user nginx nginx; #启动Nginx工作进程的用户和组worker_processes [number | auto]; #启动Nginx工作进程的数量,一般设为和CPU核心数相同worker_cpu_affinity 00000001 00000010 00000100 00001000 | auto ; #将Nginx工作进程绑定到指定的CPU核心，默认Nginx是不进行进程绑定的，绑定并不是意味着当前nginx进程独占以一核心CPU，但是可以保证此进程不会运行在其他核心上，这就极大减少了nginx的工作进程在不同的cpu核心上的来回跳转，减少了CPU对进程的资源分配与回收以及内存管理等，因此可以有效的提升nginx服务器的性能。CPU MASK: 00000001：0号CPU 00000010：1号CPU 10000000：7号CPU#示例:worker_cpu_affinity 0001 0010 0100 1000;第0号---第3号CPUworker_cpu_affinity 0101 1010;#示例worker_processes 4;worker_cpu_affinity 00000010 00001000 00100000 10000000;[root@centos8 ~]# ps axo pid,cmd,psr | grep nginx31093 nginx: master process /apps 134474 nginx: worker process 134475 nginx: worker process 334476 nginx: worker process 534477 nginx: worker process 735751 grep nginx#auto 绑定CPU#The special value auto (1.9.10) allows binding worker processes automatically toavailable CPUs:worker_processes auto;worker_cpu_affinity auto;#The optional mask parameter can be used to limit the CPUs available forautomatic binding:worker_cpu_affinity auto 01010101;#错误日志记录配置，语法：error_log file [debug | info | notice | warn | error | crit| alert | emerg]#error_log logs/error.log;#error_log logs/error.log notice;error_log /usr/local/src/nginx/logs/error.log error;#pid文件保存路径pid /usr/local/src/nginx/logs/nginx.pid;worker_priority 0; #工作进程优先级，-20~20(19)worker_rlimit_nofile 65536; #所有worker进程能打开的文件数量上限,包括:Nginx的所有连接（例如与代理服务器的连接等），而不仅仅是与客户端的连接,另一个考虑因素是实际的并发连接数不能超过系统级别的最大打开文件数的限制.最好与ulimit -n 或者limits.conf的值保持一致,daemon off; #前台运行Nginx服务用于测试、或者以容器运行时，需要设为offmaster_process off|on; #是否开启Nginx的master-worker工作模式，仅用于开发调试场景,默认为onevents &#123; worker_connections 65536; #设置单个工作进程的最大并发连接数 use epoll; #使用epoll事件驱动，Nginx支持众多的事件驱动，比如:select、poll、epoll，只能设置在events模块中设置。 accept_mutex on; #on为同一时刻一个请求轮流由worker进程处理,而防止被同时唤醒所有worker,避免多个睡眠进程被唤醒的设置，默认为off，新请求会唤醒所有worker进程,此过程也称为&quot;惊群&quot;，因此nginx刚安装完以后要进行适当的优化。建议设置为on multi_accept on; #on时Nginx服务器的每个工作进程可以同时接受多个新的网络连接，此指令默认为off，即默认为一个工作进程只能一次接受一个新的网络连接，打开后几个同时接受多个。建议设置为on&#125; 范例：实现nginx高并发配置 123456789101112131415161718192021[root@centos7 ~]#ulimit -n 102400[root@centos7 ~]#while true;do ab -c 5000 -n 10000 http://10.0.0.8/;sleep0.5;done#默认配置不支持高并发,会出现以下错误日志[root@centos8 conf]#tail /usr/local/src/nginx/logs/error.log2020/09/24 21:19:33 [crit] 41006#0: *1105860 open() &quot;/apps/nginx/html/50x.html&quot;failed (24: Too many open files), client: 10.0.0.7, server: localhost, request:&quot;GET / HTTP/1.0&quot;, host: &quot;10.0.0.8&quot;2020/09/24 21:19:33 [crit] 41006#0: accept4() failed (24: Too many open files)2020/09/24 21:19:33 [crit] 41006#0: *1114177 open()&quot;/apps/nginx/html/index.html&quot; failed (24: Too many open files), client: 10.0.0.7,server: localhost, request: &quot;GET / HTTP/1.0&quot;, host: &quot;10.0.0.8&quot;#如果systemd启动,则需要修改nginx.service文件中加LimitNOFILE=100000,才能有效#如果非systemd启动,可以修改下面pam限制[root@centos8 ~]#vim /etc/security/limits.conf* soft nofile 1000000* hard nofile 1000000[root@centos8 ~]#vim /apps/nginx/conf/nginx.confworker_rlimit_nofile 100000;[root@centos8 ~]#systemctl restart nginx[root@centos8 ~]# watch -n1 &#x27;ps -axo pid,cmd,nice | grep nginx #验证进程优先级 http配置块12345678910111213141516171819http &#123; ... ... #各server的公共配置 server &#123; #每个server用于定义一个虚拟主机,第一个server为默认虚拟服务器 ... &#125; server &#123; ... server_name #虚拟主机名 root #主目录 alias #路径别名 location [OPERATOR] URL &#123; #指定URL的特性 ... if CONDITION &#123; ... &#125; &#125; &#125;&#125; http配置协议说明 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788http &#123; include mime.types; #导入支持的文件类型,是相对于/usr/local/src/nginx/conf的目录 default_type application/octet-stream; #除mime.types中文件类型外,设置其它文件默认类型，访问其它类型时会提示下载不匹配的类型文件#日志配置部分 #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main;#自定义优化参数 sendfile on; #tcp_nopush on; #在开启了sendfile的情况下，合并请求后统一发送给客户端,必须开启sendfile #tcp_nodelay off; #在开启了keepalived模式下的连接是否启用TCP_NODELAY选项，当为off时，延迟0.2s发送，默认On时，不延迟发送，立即发送用户响应报文。 #keepalive_timeout 0; keepalive_timeout 65 65; #设置会话保持时间,第二个值为响应首部:keepAlived:timeout=65,可以和第一个值不同 #gzip on; #开启文件压缩 server &#123; listen 80; #设置监听地址和端口 server_name localhost; #设置server name，可以以空格隔开写多个并支持正则表达式，如:*.magedu.com www.magedu.* ~^www\\d+\\.magedu\\.com$ default_server #charset koi8-r; #设置编码格式，默认是俄语格式，建议改为utf-8 #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; #定义错误页面 location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; #以http的方式转发php请求到指定web服务器 # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; #以fastcgi的方式转发php请求到php处理 # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; #拒绝web形式访问指定文件，如很多的网站都是通过.htaccess文件来改变自己的重定向等功能。 # deny all; #&#125; location ~ /passwd.html &#123; deny all; &#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; #自定义虚拟server # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; #指定默认网页文件，此指令由ngx_http_index_module模块提供 # &#125; #&#125; # HTTPS server # #server &#123; #https服务器配置 # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; MIME1234567891011#在响应报文中将指定的文件扩展名映射至MIME对应的类型include /etc/nginx/mime.types;default_type application/octet-stream;#除mime.types中的类型外，指定其它文件的默认MIME类型，浏览器一般会提示下载types &#123; text/html html; image/gif gif; image/jpeg jpg;&#125;#MIME参考文档：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_Types 范例：识别PHP为text 1234567891011121314151617[root@centos7 conf]# vim /usr/local/src/nginx/html/test.php&lt;?phpphpinfo();?&gt;# 修改配置文件[root@centos7 conf]# vim /usr/local/src/nginx/conf/nginx.confhttp &#123; include mime.types; default_type text/html; # 加入次行......#或者修改为下面 include mime.types; default_type application/octet-stream; types&#123; text/plain php; #加此行 &#125; 指定响应报文server首部123456#是否在响应报文中的Content-Type显示指定的字符集，默认off不显示charset charset | off;#示例charset utf-8;#是否在响应报文的Server首部显示nginx版本server_tokens on | off | build | string; 修改server字段 12345678如果想自定义响应报文的nginx版本信息，需要修改源码文件，重新编译如果server_tokens on，修改 src/core/nginx.h 修改第13-14行，如下示例#define NGINX_VERSION &quot;1.68.9&quot;#define NGINX_VER &quot;test/&quot; NGINX_VERSION如果server_tokens off，修改 src/http/ngx_http_header_filter_module.c第49行，如下示例：static char ngx_http_server_string[] = &quot;Server: nginx&quot; CRLF;把其中的nginx改为自己想要的文字即可,如：test root 与 aliasroot：指定web的家目录，在定义location的时候，文件的绝对路径等于 root+location alias：定义路径别名，会把访问的路径重新定义到其指定的路径,文档映射的另一种机制;仅能用于 location上下文,此指令使用较少 注意：location中使用root指令和alias指令的意义不同 12root 给定的路径对应于location中的/uri 左侧的/alias 给定的路径对应于location中的/uri 的完整路径 location 的详细使用在一个server中location配置段可存在多个，用于实现从uri到文件系统的路径映射；ngnix会根据用户请 求的URI来检查定义的所有location，按一定的优先级找出一个最佳匹配，而后应用其配置 在没有使用正则表达式的时候，nginx会先在server中的多个location选取匹配度最高的一个uri，uri是 用户请求的字符串，即域名后面的web文件路径，然后使用该location模块中的正则url和字符串，如果 匹配成功就结束搜索，并使用此location处理此请求。 location 官方帮助: 1https://nginx.org/en/docs/http/ngx_http_core_module.html#location 语法规则 123456789101112#语法规则：location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;= #用于标准uri前，需要请求字串与uri精确匹配，大小敏感,如果匹配成功就停止向下匹配并立即处理请求^~ #用于标准uri前，表示包含正则表达式,并且匹配以指定的正则表达式开头,对uri的最左边部分做匹配检查，不区分字符大小写~ #用于标准uri前，表示包含正则表达式,并且区分大小写~* #用于标准uri前，表示包含正则表达式,并且不区分大写不带符号 #匹配起始于此uri的所有的uri\\ #用于标准uri前，表示包含正则表达式并且转义字符。可以将 . * ?等转义为普通符号#匹配优先级从高到低：=, ^~, ~/~*, 不带符号 官网案例 1234567891011121314151617181920location = / &#123; [ configuration A ]&#125;location / &#123; [ configuration B ]&#125;location /documents/ &#123; [ configuration C ]&#125;location ^~ /images/ &#123; [ configuration D ]&#125;location ~* \\.(gif|jpg|jpeg)$ &#123; [ configuration E ]&#125;The “/” request will match configuration A(?), the “/index.html” request willmatch configuration B,the “/documents/document.html” request will match configuration C, the“/images/1.gif” request will match configuration D, and the “/documents/1.jpg”request will match configuration E. 精确匹配图片 123456789server&#123; listen 80; server_name localhost; root /data/web; index index.html *.html; location = /test.jpg &#123; root /data/image;&#125;&#125; 匹配案例-文件名后缀 123456789server&#123; listen 80; server_name localhost; root /data/web; index index.html *.html; location ~* \\.(gif|jpg|jpeg|bmp|png|tiff|tif|ico|wmf|js|css)$ &#123; root /data/web1;&#125;&#125; 匹配案例-优先级 1234567891011121314151617server&#123; listen 80; server_name localhost; root /data/web; index index.html *.html; location = /test2.jpg &#123; root /data/web2; index index.html;&#125; location ~* \\.(gif|jpg|jpeg|bmp|png|tiff|tif|ico|wmf|js|css)$ &#123; root /data/web1; index index.html;&#125;&#125;#匹配优先级：=, ^~, ～/～*，/location优先级：(location =) &gt; (location ^~ 路径) &gt; (location ~,~* 正则顺序) &gt;(location 完整路径) &gt; (location 部分起始路径) &gt; (/) Nginx 四层访问控制 访问控制基于模块ngx_http_access_module实现，可以通过匹配客户端源IP地址进行限制 注意: 如果能在防火墙设备控制,最好就不要在nginx上配置,可以更好的节约资源 官方帮助: 1http://nginx.org/en/docs/http/ngx_http_access_module.html 范例： 1234567891011121314location = /login/ &#123; root /data/nginx/html/pc; allow 10.0.0.0/24; deny all; &#125;location /about &#123; alias /data/nginx/html/pc; index index.html; deny 192.168.1.1; # 禁止该IP访问 allow 192.168.1.0/24; # 允许该网段访问 allow 10.1.1.0/16; allow 2001:0db8::/32; deny all; #按先小范围到大范围排序 &#125; Nginx 账户认证功能 由 ngx_http_auth_basic_module 模块提供此功能 官方帮助: 1https://nginx.org/en/docs/http/ngx_http_auth_basic_module.html#auth_basic 范例： 12345678910111213141516171819202122232425262728293031#CentOS安装包[root@centos7 ~]#yum -y install httpd-tools#Ubuntu安装包[root@Ubuntu ~]#apt -y install apache2-utils#创建用户#-b 非交互式方式提交密码[root@centos7 ~]# htpasswd -cb /usr/local/src/nginx/conf.d/passwd admin 123456Adding password for user admin[root@centos7 conf.d]# cat passwd admin:$apr1$/MugqAsJ$MbWcOmC5U9WTZlgK5MJeU.[root@centos7 conf.d]# #安全加固[root@centos7 ~]# chown nginx.nginx /usr/local/src/nginx/conf.d/passwd[root@centos7 ~]# chmod 600 /usr/local/src/nginx/conf.d/passwd# 修改配置文件server&#123; listen 80; server_name localhost; root /data/web; index index.html *.html; location /about &#123; alias /data/web1; index index.html *.html; auth_basic &quot;login password&quot;; auth_basic_user_file /usr/local/src/nginx/conf.d/passwd;&#125;&#125; 检测文件是否存在 try_files 会按顺序检查文件是否存在，返回第一个找到的文件或文件夹（结尾加斜线表示为文件夹）， 如果所有文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。只有最后一个参数可以引起 一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现 内部500错误。 语法格式 1234Syntax: try_files file ... uri;try_files file ... =code;Default: —Context: server, location 范例： 如果不存在页面, 就转到default.html页面 1234567891011121314server&#123; listen 80; server_name localhost; root /data/web; index index.html *.html; location / &#123; #如果不存在页面, 就转到default.html页面 # try_files $uri $uri.html $uri/index.html /about/default.html; # 返回自定义状态码 489 try_files $uri $uri/index.html $uri.html =489; index index.html *.html;&#125;&#125; 长连接配置1234keepalive_timeout timeout [header_timeout]; #设定保持连接超时时长，0表示禁止长连接，默认为75s，通常配置在http字段作为站点全局配置keepalive_requests number; #在一次长连接上所允许请求的资源的最大数量，默认为1000次,建议适当调大,比如:500 范例： 12345678keepalive_requests 3;keepalive_timeout 65 60;#开启长连接后，返回客户端的会话保持时间为60s，单次长连接累计请求达到指定次数请求或65秒就会被断开，第二个数字60为发送给客户端应答报文头部中显示的超时时间设置为60s：如不设置客户端将不显示超时时间。Keep-Alive:timeout=60 #浏览器收到的服务器返回的报文#如果设置为0表示关闭会话保持功能，将如下显示：Connection:close #浏览器收到的服务器返回的报文 作为下载服务器配置 nginx_http_autoindex_module 模块处理以斜杠字符 “&#x2F;“ 结尾的请求，并生成目录列表,可以做为下载服务 配置使用 官方文档: 1https://nginx.org/en/docs/http/ngx_http_autoindex_module.html#autoindex 1234Syntax: autoindex on | off;Default: autoindex off;Context: http, server, location 相关指令 12345678910autoindex on | off;#自动文件索引功能，默为offautoindex_exact_size on | off; #计算文件确切大小（单位bytes），off 显示大概大小（单位K、M)，默认onautoindex_localtime on | off ; #显示本机时间而非GMT(格林威治)时间，默认offautoindex_format html | xml | json | jsonp; #显示索引的页面文件风格，默认htmllimit_rate rate; #限制响应客户端传输速率(除GET和HEAD以外的所有方法)，单位B/s,即bytes/second，默认值0,表示无限制,此指令由ngx_http_core_module提供set $limit_rate 4k; #也可以通变量限速,单位B/s,同时设置,此项优级高.Rate limit can alsobe set in the $limit_rate variable, however, since version 1.17.0, this method isnot recommended: 范例： 12345678910# 配置文件location /download &#123; autoindex on; #自动索引功能 autoindex_exact_size on; #计算文件确切大小（单位bytes），此为默认值,off只显示大概大小（单位kb、mb、gb） autoindex_localtime on; #on表示显示本机时间而非GMT(格林威治)时间,默为为off显示GMT时间 limit_rate 1024k; #限速,默认不限速 root /data/web/download; &#125; 其他配置12keepalive_disable none | browser ...; #对哪种浏览器禁用长连接 123456789101112131415161718192021limit_except method ... &#123; ... &#125;，仅用于location#禁止客户端使用除了指定的请求方法之外的其它方法,如果使用会出现403错误method:GET, HEAD, POST, PUT, DELETE，MKCOL, COPY, MOVE, OPTIONS, PROPFIND,PROPPATCH, LOCK, UNLOCK, PATCHlimit_except GET &#123; allow 192.168.0.0/24; allow 10.0.0.1; deny all;&#125;#除了GET和HEAD 之外其它方法仅允许192.168.1.0/24网段主机使用location /upload &#123; root /data/nginx/html/pc; index index.html; limit_except GET &#123; allow 10.0.0.6; deny all; &#125;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://snippet.itshare.work/categories/Nginx/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Nginx","slug":"Nginx","permalink":"http://snippet.itshare.work/categories/Nginx/"}]},{"title":"Nginx平滑升级","slug":"Nginx平滑升级","date":"2023-01-07T05:34:33.000Z","updated":"2023-01-08T12:25:50.362Z","comments":true,"path":"2023/01/07/Nginx平滑升级/","link":"","permalink":"http://snippet.itshare.work/2023/01/07/Nginx%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7/","excerpt":"有时候我们需要对Nginx版本进行升级以满足对其功能的需求，例如添加新模块，需要新功能，而此时Nginx又在跑着业务无法停掉，这时我们就可能选择平滑升级","text":"平滑升级流程 将旧Nginx二进制文件换成新Nginx程序文件（注意先备份) 向master进程发送USR2信号启动新nginx进程 master进程修改pid文件名加上后缀.oldbin,成为nginx.pid.oldbin master进程用新Nginx文件启动新master进程及worker子进程成为旧master的子进程,系统中将有新旧两个Nginx主进程和对应的worker子进程并存当前新的请求仍然由旧Nginx的worker进程进行处理,将新生成的master进程的PID存放至新生成的pid文件nginx.pid 向旧的Nginx服务进程发送WINCH信号，使旧的Nginx worker进程平滑停止 向旧master进程发送QUIT信号，关闭旧master，并删除Nginx.pid.oldbin文件 如果发现升级有问题,可以回滚∶向旧master发送HUP，向新master发送QUIT 范例：Nginx1.18.0版本升级到1.20.2Nginx1.18.0编译安装官方源码包下载地址： 1https://nginx.org/en/download.html 范例：编译安装 系统centos8.5 Nginx版本：1.18.0 安装扩展依赖 1[root@centos8 ~]# yum -y install gcc pcre-devel openssl-devel zlib-devel 创建用户和组 12groupadd nginxuseradd -s /sbin/nologin -g nginx nginx 下载安装包并解压 1234[root@centos8 ~]# cd /usr/local/src/[root@centos8 ~]# wget https://nginx.org/download/nginx-1.18.0.tar.gz[root@centos8 src]# tar xf nginx-1.18.0.tar.gz [root@centos8 src]# cd nginx-1.18.0 安装 12345678910111213[root@centos8 nginx-1.18.0]# ./configure --prefix=/usr/local/src/nginx/ \\ # 安装位置--user=nginx \\ # 运行的用户--group=nginx \\--with-http_ssl_module \\--with-http_v2_module \\--with-http_realip_module \\--with-http_stub_status_module \\--with-http_gzip_static_module \\--with-pcre \\--with-stream \\--with-stream_ssl_module[root@centos8 nginx-1.18.0]#make &amp;&amp; make install 修改权限 1[root@centos8 /]# chown -R nginx.nginx /usr/local/src/nginx/ nginx安装完成后有四个主要的目录 1234567891011121314[root@centos8 /]# ll /usr/local/src/nginx/total 4drwxr-xr-x. 2 nginx nginx 4096 Jan 4 15:17 confdrwxr-xr-x. 2 nginx nginx 40 Jan 4 15:17 htmldrwxr-xr-x. 2 nginx nginx 6 Jan 4 15:17 logsdrwxr-xr-x. 2 nginx nginx 19 Jan 4 15:17 sbin[root@centos8 /]# conf：保存nginx所有的配置文件，其中nginx.conf是nginx服务器的最核心最主要的配置文件，其他的.conf则是用来配置nginx相关的功能的，例如fastcgi功能使用的是fastcgi.conf和fastcgi_params两个文件，配置文件一般都有一个样板配置文件，是以.default为后缀，使用时可将其复制并将default后缀去掉即可。html目录中保存了nginx服务器的web文件，但是可以更改为其他目录保存web文件,另外还有一个50x的web文件是默认的错误页面提示页面。logs：用来保存nginx服务器的访问日志错误日志等日志，logs目录可以放在其他 验证版本及编译参数 12345678[root@centos8 /]# ln -s /usr/local/src/nginx/sbin/nginx /usr/bin/[root@centos8 /]# nginx -Vnginx version: nginx/1.18.0built by gcc 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC) built with OpenSSL 1.1.1k FIPS 25 Mar 2021TLS SNI support enabledconfigure arguments: --prefix=/usr/local/src/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module[root@centos8 /]# 创建Nginx启动文件 1234567891011121314151617181920#复制同一版本的nginx的yum安装生成的service文件[root@centos8 ~]# vim /lib/systemd/system/nginx.service [Unit]Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/After=network.target[Service] Type=forkingPIDFile=/usr/local/src/nginx/logs/nginx.pidExecStartPre=/usr/local/src//nginx/sbin/nginx -t -c /usr/local/src/nginx/conf/nginx.confExecStart=/usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.confExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install] WantedBy=multi-user.target 验证启动文件 1234[root@centos8 ~]#systemctl daemon-reload[root@centos8 ~]#systemctl enable --now nginxCreated symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service.[root@centos8 ~]# 查看Nginx运行状态 123456789101112131415161718[root@centos8 ~]# systemctl status nginx● nginx.service - nginx - high performance web server Loaded: loaded (/usr/lib/systemd/system/nginx.service; enabled; vendor preset: disabled) Active: active (running) since Wed 2023-01-04 17:53:00 CST; 2 days ago Docs: http://nginx.org/en/docs/ Main PID: 1595 (nginx) Tasks: 2 (limit: 11218) Memory: 9.1M CGroup: /system.slice/nginx.service ├─1595 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.conf └─1596 nginx: worker processJan 04 17:53:00 centos8 systemd[1]: Starting nginx - high performance web server...Jan 04 17:53:00 centos8 nginx[1592]: nginx: the configuration file /usr/local/src/nginx/conf/nginx.conf syntax is okJan 04 17:53:00 centos8 nginx[1592]: nginx: configuration file /usr/local/src/nginx/conf/nginx.conf test is successfulJan 04 17:53:00 centos8 systemd[1]: nginx.service: Failed to parse PID from file /usr/local/src/nginx/logs/nginx.pid: Invalid argumentJan 04 17:53:00 centos8 systemd[1]: Started nginx - high performance web server.[root@centos8 ~]# 编译Nginx1.20.2 下载Nginx1.20.2 123[root@centos8 ~]# cd /usr/local/src/[root@centos8 src]# wget https://nginx.org/download/nginx-1.20.2.tar.gz[root@centos8 src]# tar xf nginx-1.20.2.tar.gz 查看旧版本Nginx编译选项 1234567[root@centos8 src]# nginx -Vnginx version: nginx/1.18.0built by gcc 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC) built with OpenSSL 1.1.1k FIPS 25 Mar 2021TLS SNI support enabledconfigure arguments: --prefix=/usr/local/src/nginx/ --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module[root@centos8 src]# 编译新版本，使用旧版本相同的编译参数选项 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788[root@centos8 src]# cd nginx-1.20.2[root@centos8 nginx-1.20.2]# ./configure --prefix=/usr/local/src/nginx/ --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module# 只需要make无需make install[root@centos8 nginx-1.20.2]# make# 编译完的软件存在objs/nginx[root@centos8 nginx-1.20.2]# ll objs/total 7684-rw-r--r--. 1 root root 18498 Jan 7 15:29 autoconf.err-rw-r--r--. 1 root root 53217 Jan 7 15:29 Makefile-rwxr-xr-x. 1 root root 7697296 Jan 7 15:31 nginx-rw-r--r--. 1 root root 5557 Jan 7 15:31 nginx.8-rw-r--r--. 1 root root 7906 Jan 7 15:29 ngx_auto_config.h-rw-r--r--. 1 root root 657 Jan 7 15:29 ngx_auto_headers.h-rw-r--r--. 1 root root 8758 Jan 7 15:29 ngx_modules.c-rw-r--r--. 1 root root 60056 Jan 7 15:31 ngx_modules.odrwxr-xr-x. 9 root root 91 Jan 7 15:29 src[root@centos8 nginx-1.20.2]# # 查看两个Nginx版本[root@centos8 nginx-1.20.2]# ./objs/nginx -vnginx version: nginx/1.20.2[root@centos8 nginx-1.20.2]# /usr/local/src/nginx/sbin/nginx -vnginx version: nginx/1.18.0[root@centos8 nginx-1.20.2]## 备份旧版本Nginx[root@centos8 nginx-1.20.2]# cp /usr/local/src/nginx/sbin/nginx /usr/local/src/nginx/sbin/nginx.old[root@centos8 nginx-1.20.2]# ll /usr/local/src/nginx/sbin/total 14776-rwxr-xr-x. 1 root root 7562368 Jan 4 17:39 nginx-rwxr-xr-x. 1 root root 7562368 Jan 7 15:36 nginx.old[root@centos8 nginx-1.20.2]# #把新版本的nginx命令复制过去覆盖旧版本程序文件,注意:需要加 -f 选项强制覆盖,否则会提示Text file busy[root@centos8 nginx-1.20.2]# cp -f objs/nginx /usr/local/src/nginx/sbin/cp: overwrite &#x27;/usr/local/src/nginx/sbin/nginx&#x27;? y[root@centos8 nginx-1.20.2]## 检测是否存在问题，必须做的[root@centos8 nginx-1.20.2]# /usr/local/src/nginx/sbin/nginx -tnginx: the configuration file /usr/local/src/nginx//conf/nginx.conf syntax is oknginx: configuration file /usr/local/src/nginx//conf/nginx.conf test is successful[root@centos8 nginx-1.20.2]# #发送信号USR2 平滑升级可执行程序,将存储有旧版本主进程PID的文件重命名为nginx.pid.oldbin，并启动新的nginx#此时两个master的进程都在运行,只是旧的master不在监听,由新的master监听80#此时Nginx开启一个新的master进程，这个master进程会生成新的worker进程，这就是升级后的Nginx进程，此时老的进程不会自动退出，但是当接收到新的请求不作处理而是交给新的进程处理。[root@centos8 nginx-1.20.2]# kill -USR2 `cat /usr/local/src/nginx/logs/nginx.pid `[root@centos8 nginx-1.20.2]# #可以看到两个master,新的master是旧版master的子进程,并生成新版的worker进程[root@centos8 nginx-1.20.2]# ps aux | grep nginxroot 1595 0.0 0.1 42452 2724 ? Ss Jan05 0:00 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.confnginx 1596 0.0 0.2 77120 4612 ? S Jan05 0:00 nginx: worker processroot 8328 0.0 0.3 42484 5860 ? S 15:44 0:00 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.confnginx 8329 0.0 0.2 77240 4652 ? S 15:44 0:00 nginx: worker processroot 8333 0.0 0.0 12136 1120 pts/0 S+ 15:45 0:00 grep --color=auto nginx[root@centos8 nginx-1.20.2]# #先关闭旧nginx的worker进程,而不关闭nginx主进程方便回滚#向原Nginx主进程发送WINCH信号，它会逐步关闭旗下的工作进程（主进程不退出），这时所有请求都会由新版Nginx处理[root@centos8 nginx-1.20.2]# kill -WINCH `cat /usr/local/src/nginx/logs/nginx.pid.oldbin` #如果旧版worker进程有用户的请求,会一直等待处理完后才会关闭[root@centos8 nginx-1.20.2]# ps aux | grep nginxroot 1595 0.0 0.1 42452 2724 ? Ss Jan05 0:00 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.confroot 8328 0.0 0.3 42484 5860 ? S 15:44 0:00 nginx: master process /usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.confnginx 8329 0.0 0.2 77240 5032 ? S 15:44 0:00 nginx: worker processroot 8346 0.0 0.0 12136 1144 pts/0 S+ 15:48 0:00 grep --color=auto nginx[root@centos8 nginx-1.20.2]# #经过一段时间测试，新版本服务没问题，最后发送QUIT信号,退出老的master[root@centos8 nginx-1.20.2]# kill -QUIT `cat /usr/local/src/nginx/logs/nginx.pid.oldbin`[root@centos8 nginx-1.20.2]# # 查看版本是否升级成功[root@centos8 nginx-1.20.2]# nginx -vnginx version: nginx/1.20.2[root@centos8 nginx-1.20.2]# #回滚#如果升级的版本发现问题需要回滚,可以发送HUP信号,重新拉起旧版本的worker[root@centos8 nginx-1.20.2]# kill -HUB `cat /usr/local/src/nginx/logs/nginx.pid.oldbin`#最后关闭新版的master[root@centos8 nginx-1.20.2]# kill -QUIT `cat /usr/local/src/nginx/logs/nginx.pid`","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://snippet.itshare.work/categories/Nginx/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Nginx","slug":"Nginx","permalink":"http://snippet.itshare.work/categories/Nginx/"}]},{"title":"docker-compose部署MySql","slug":"docker-compose部署MySQL","date":"2023-01-06T06:00:26.000Z","updated":"2023-01-13T15:22:41.294Z","comments":true,"path":"2023/01/06/docker-compose部署MySQL/","link":"","permalink":"http://snippet.itshare.work/2023/01/06/docker-compose%E9%83%A8%E7%BD%B2MySQL/","excerpt":"docker-compose部署MySql","text":"CentOS Docker 安装Docker 支持以下的 64 位 CentOS 版本： CentOS 7 CentOS 8 更高版本… 官方安装脚本自动安装安装命令如下： 1curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun 也可以使用国内 daocloud 一键安装命令： 1curl -sSL https://get.daocloud.io/docker | sh 安装docker-composeCompose 简介Compose 是用于定义和运行多容器 Docker 应用程序的工具。通过 Compose，您可以使用 YML 文件来配置应用程序需要的所有服务。然后，使用一个命令，就可以从 YML 文件配置中创建并启动所有服务。Compose 安装Linux 上我们可以从 Github 上下载它的二进制包来使用，最新发行的版本地址：https://github.com/docker/compose/releases。 运行以下命令以下载 Docker Compose 的当前稳定版本： 1curl -L &quot;https://github.com/docker/compose/releases/download/v2.2.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose 要安装其他版本的 Compose，请替换 v2.2.2。 Docker Compose 存放在 GitHub，不太稳定。 你可以也通过执行下面的命令，高速安装 Docker Compose。 1curl -L https://get.daocloud.io/docker/compose/releases/download/v2.4.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose 将可执行权限应用于二进制文件： 1chmod +x /usr/local/bin/docker-compose 创建软链： 1ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose 测试是否安装成功： 12[root@centos7 ~]# docker-compose versionDocker Compose version v2.4.1 docker-compose一键部署mysql 创建安装目录,根据实际情况修改1234mkdr mysqlcd mysqlmkdir -p data/dbmkdir etc 编写docker-compose.yml12cd mysqlvim docker-compose.yml docker-compose.yml内容如下1234567891011121314version: &#x27;3.1&#x27;services: mysql: image: mysql:5.7 #mysql版本 container_name: $&#123;MYSQL_NAME&#125; volumes: - ./data/db:/var/lib/mysql - ./etc/my.cnf:/etc/mysql/mysql.conf.d/mysqld.cnf restart: always ports: - $&#123;MYSQL_PORT&#125;:3306 environment: MYSQL_ROOT_PASSWORD: $&#123;MYSQL_ROOT_PASSWD&#125; #访问密码 secure_file_priv: 创建MySQL配置文件12cd mysql/etcvim my.cnf my.cnf文件内容如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[mysqld]character-set-server=utf8log-bin=mysql-binserver-id=1pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysqlsql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTIONsymbolic-links=0secure_file_priv =wait_timeout=120interactive_timeout=120default-time_zone = &#x27;+8:00&#x27;skip-external-lockingskip-name-resolveopen_files_limit = 10240max_connections = 1000max_connect_errors = 6000table_open_cache = 800max_allowed_packet = 40msort_buffer_size = 2Mjoin_buffer_size = 1Mthread_cache_size = 32query_cache_size = 64Mtransaction_isolation = READ-COMMITTEDtmp_table_size = 128Mmax_heap_table_size = 128Mlog-bin = mysql-binsync-binlog = 1binlog_format = ROWbinlog_cache_size = 1Mkey_buffer_size = 128Mread_buffer_size = 2Mread_rnd_buffer_size = 4Mbulk_insert_buffer_size = 64Mlower_case_table_names = 1explicit_defaults_for_timestamp=trueskip_name_resolve = ONevent_scheduler = ONlog_bin_trust_function_creators = 1innodb_buffer_pool_size = 512Minnodb_flush_log_at_trx_commit = 1innodb_file_per_table = 1innodb_log_buffer_size = 4Minnodb_log_file_size = 256Minnodb_max_dirty_pages_pct = 90innodb_read_io_threads = 4innodb_write_io_threads = 4 编写重启脚本12cd mysqlvim restart.sh restart.sh文件内容 1234#!/bin/bashdocker-compose stopdocker-compose rm -fdocker-compose up -d 编写.env文件 12345678vim .env# 容器名称MYSQL_NAME=docker-mysql# 启用端口MYSQL_PORT=3306# root密码MYSQL_ROOT_PASSWD=123456 验证 1234567# 执行启动脚本bash restart.sh# 查看运行的容器docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES36d09017f331 mysql:5.7 &quot;docker-entrypoint.s…&quot; 2 minutes ago Up 2 minutes 0.0.0.0:3306-&gt;3306/tcp, :::3306-&gt;3306/tcp, 33060/tcp docker-mysql","categories":[{"name":"Docker","slug":"Docker","permalink":"http://snippet.itshare.work/categories/Docker/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Docker","slug":"Docker","permalink":"http://snippet.itshare.work/categories/Docker/"}]},{"title":"在线一键安装Nginx脚本","slug":"在线一键安装Nginx脚本","date":"2023-01-04T14:46:26.000Z","updated":"2023-01-04T14:51:33.926Z","comments":true,"path":"2023/01/04/在线一键安装Nginx脚本/","link":"","permalink":"http://snippet.itshare.work/2023/01/04/%E5%9C%A8%E7%BA%BF%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85Nginx%E8%84%9A%E6%9C%AC/","excerpt":"一键安装Nginx 脚本","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132#!/bin/bash##********************************************************************#Author: yuankun#Date: 2023-01-04#FileName： install_nginx.sh#Description： The test script#********************************************************************# 安装资源下载路径SRC_DIR=/usr/local/src/# 下载地址NGINX_URL=http://nginx.org/download/# 安装版本NGINX_FILE=nginx-1.20.2TAR=.tar.gz# 安装路径NGINX_INSTALL_DIR=/usr/local/src/nginx# 查看CPU核心数CPUS=`lscpu |awk &#x27;/^CPU\\(s\\)/&#123;print $2&#125;&#x27;`. /etc/os-release# 颜色color () &#123; RES_COL=60 MOVE_TO_COL=&quot;echo -en \\\\033[$&#123;RES_COL&#125;G&quot; SETCOLOR_SUCCESS=&quot;echo -en \\\\033[1;32m&quot; SETCOLOR_FAILURE=&quot;echo -en \\\\033[1;31m&quot; SETCOLOR_WARNING=&quot;echo -en \\\\033[1;33m&quot; SETCOLOR_NORMAL=&quot;echo -en \\E[0m&quot; echo -n &quot;$1&quot; &amp;&amp; $MOVE_TO_COL echo -n &quot;[&quot; if [ $2 = &quot;success&quot; -o $2 = &quot;0&quot; ] ;then $&#123;SETCOLOR_SUCCESS&#125; echo -n $&quot; OK &quot; elif [ $2 = &quot;failure&quot; -o $2 = &quot;1&quot; ] ;then $&#123;SETCOLOR_FAILURE&#125; echo -n $&quot;FAILED&quot; else $&#123;SETCOLOR_WARNING&#125; echo -n $&quot;WARNING&quot; fi $&#123;SETCOLOR_NORMAL&#125; echo -n &quot;]&quot; echo &#125;os_type () &#123; awk -F&#x27;[ &quot;]&#x27; &#x27;/^NAME/&#123;print $2&#125;&#x27; /etc/os-release&#125;os_version () &#123; awk -F&#x27;&quot;&#x27; &#x27;/^VERSION_ID/&#123;print $2&#125;&#x27; /etc/os-release&#125;check () &#123; [ -e $&#123;NGINX_INSTALL_DIR&#125; ] &amp;&amp; &#123; color &quot;nginx 已安装,请卸载后再安装&quot; 1; exit; &#125; cd $&#123;SRC_DIR&#125; if [ -e $&#123;NGINX_FILE&#125;$&#123;TAR&#125; ];then color &quot;相关文件已准备好&quot; 0 else color &#x27;开始下载 nginx 源码包&#x27; 0 wget $&#123;NGINX_URL&#125;$&#123;NGINX_FILE&#125;$&#123;TAR&#125; [ $? -ne 0 ] &amp;&amp; &#123; color &quot;下载 $&#123;NGINX_FILE&#125;$&#123;TAR&#125;文件失败&quot; 1; exit; &#125; fi&#125; install () &#123; color &quot;开始安装 nginx&quot; 0 if id nginx &amp;&gt; /dev/null;then color &quot;nginx 用户已存在&quot; 1 else useradd -s /sbin/nologin -r nginx color &quot;创建 nginx 用户&quot; 0 fi color &quot;开始安装 nginx 依赖包&quot; 0 if [ $ID == &quot;centos&quot; ] ;then if [[ $VERSION_ID =~ ^7 ]];then yum -y -q install make gcc pcre-devel openssl-devel zlib-devel perl-ExtUtils-Embed elif [[ $VERSION_ID =~ ^8 ]];then yum -y -q install make gcc-c++ libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel perl-ExtUtils-Embed else color &#x27;不支持此系统!&#x27; 1 exit fi elif [ $ID == &quot;rocky&quot; ];then yum -y -q install make gcc-c++ libtool pcre pcre-devel zlib zlib-devel openssl openssl-devel perl-ExtUtils-Embed else apt update &amp;&gt; /dev/null apt -y install make gcc libpcre3 libpcre3-dev openssl libssl-dev zlib1g-dev &amp;&gt; /dev/null fi cd $SRC_DIR tar xf $&#123;NGINX_FILE&#125;$&#123;TAR&#125; NGINX_DIR=`echo $&#123;NGINX_FILE&#125;$&#123;TAR&#125;| sed -nr &#x27;s/^(.*[0-9]).*/\\1/p&#x27;` cd $&#123;NGINX_DIR&#125; &amp;&amp; pwd ./configure --prefix=$&#123;NGINX_INSTALL_DIR&#125; --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module make -j $CPUS &amp;&amp; make install [ $? -eq 0 ] &amp;&amp; color &quot;nginx 编译安装成功&quot; 0 || &#123; color &quot;nginx 编译安装失败,退出!&quot; 1 ;exit; &#125; echo &quot;PATH=$&#123;NGINX_INSTALL_DIR&#125;/sbin:$&#123;PATH&#125;&quot; &gt; /etc/profile.d/nginx.sh cat &gt; /lib/systemd/system/nginx.service &lt;&lt;EOF[Unit]Description=The nginx HTTP and reverse proxy serverAfter=network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=$&#123;NGINX_INSTALL_DIR&#125;/logs/nginx.pidExecStartPre=/bin/rm -f $&#123;NGINX_INSTALL_DIR&#125;/logs/nginx.pidExecStartPre=$&#123;NGINX_INSTALL_DIR&#125;/sbin/nginx -tExecStart=$&#123;NGINX_INSTALL_DIR&#125;/sbin/nginxExecReload=/bin/kill -s HUP \\$MAINPIDKillSignal=SIGQUITTimeoutStopSec=5KillMode=processPrivateTmp=trueLimitNOFILE=100000[Install]WantedBy=multi-user.targetEOF systemctl daemon-reload systemctl enable --now nginx &amp;&gt; /dev/null systemctl is-active nginx &amp;&gt; /dev/null || &#123; color &quot;nginx 启动失败,退出!&quot; 1 ; exit; &#125; color &quot;nginx 安装完成&quot; 0&#125;checkinstall","categories":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}]},{"title":"Nginx安装和命令使用","slug":"nginx","date":"2023-01-01T04:08:32.000Z","updated":"2023-02-27T07:30:22.563Z","comments":true,"path":"2023/01/01/nginx/","link":"","permalink":"http://snippet.itshare.work/2023/01/01/nginx/","excerpt":"Nginx是免费的、开源的、高性能的HTTP和反向代理服务器、邮件代理服务器、以及TCP/UDP代理服务器","text":"Nginx安装Nginx版本和安装方式Nginx版本 Mainline version 主要开发版本,一般为奇数版本号,比如1.19 Stable version 当前最新稳定版,一般为偶数版本,如:1.20 Legacy versions 旧的稳定版,一般为偶数版本,如:1.18 Nginx安装可以使用yum或源码安装，但是推荐使用源码编译安装 yum的版本比较旧 编译安装可以更方便自定义相关路径 使用源码编译可以自定义相关功能，更方便业务的上的使用 基于yum安装Nginx查看系统和EPEL的nginx版本 12345678910111213141516171819202122# centos和rocky系统[root@centos8 ~]# yum list nginxRepository extras is listed more than once in the configurationLast metadata expiration check: 0:28:13 ago on Wed 04 Jan 2023 11:51:31 AM CST.Available Packagesnginx.x86_64 1:1.14.1-9.module_el8.0.0+184+e34fea82 AppStreamnginx.x86_64 1:1.14.1-9.module_el8.0.0+184+e34fea82 appstream[root@centos8 ~]# [root@centos8 ~]# dnf list nginxRepository extras is listed more than once in the configurationLast metadata expiration check: 0:28:55 ago on Wed 04 Jan 2023 11:51:31 AM CST.Available Packagesnginx.x86_64 1:1.14.1-9.module_el8.0.0+184+e34fea82 AppStreamnginx.x86_64 1:1.14.1-9.module_el8.0.0+184+e34fea82 appstream[root@centos8 ~]# # ubuntu系统root@ubuntu2004:~# apt list nginxListing... Donenginx/focal-updates,focal-security 1.18.0-0ubuntu1.4 allN: There is 1 additional version. Please use the &#x27;-a&#x27; switch to see itroot@ubuntu2004:~# centos、rocky系统yum安装 123yum install nginx# centos、rocky系统安装nginx后未启动，使用如下命令启动systemctl start nginx ubuntu系统安装 1apt update;apt install nginx 官方包源安装Nginx系统和EPEL源的中 nignx版本较旧,可以安装官方源的最新版本官方包链接: 1http://nginx.org/en/linux_packages.html 官方 yum 源链接: 1http://nginx.org/en/linux_packages.html #RHEL-CentOS 通过官方 yum 源安装nginx 12345678910111213141516171819202122232425262728[root@centos8 ~]# vim /etc/yum.repos.d/nginx.repo[nginx-stable]name=nginx stable repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=1enabled=1gpgkey=https://nginx.org/keys/nginx_signing.keymodule_hotfixes=true[root@centos8 ~]# yum clean all42 files removed[root@centos8 ~]# yum makecache# 查看所有的版本[root@centos8]# yum list nginx --showduplicatesnginx stable repo 462 B/s | 47 kB 01:44 Available Packagesnginx.x86_64 1.16.0-1.el8.ngx nginx-stablenginx.x86_64 1:1.14.1-9.module+el8.4.0+542+81547229 appstream nginx.x86_64 1:1.16.1-1.el8.ngx nginx-stablenginx.x86_64 1:1.18.0-1.el8.ngx nginx-stablenginx.x86_64 1:1.18.0-2.el8.ngx nginx-stablenginx.x86_64 1:1.20.0-1.el8.ngx nginx-stablenginx.x86_64 1:1.20.1-1.el8.ngx nginx-stablenginx.x86_64 1:1.20.2-1.el8.ngx nginx-stablenginx.x86_64 1:1.22.0-1.el8.ngx nginx-stablenginx.x86_64 1:1.22.1-1.el8.ngx nginx-stable #安装指定版本[root@centos8 ~]#yum -y install nginx-1.18.0 检查安装1rpm -ql nginx 查看帮助123456789101112131415[root@centos8 ~]# nginx -h············Options:-?,-h : this help-v : show version and exit-V : show version and configure options then exit #显示版本和编译参数-t : test configuration and exit #测试配置文件是否异常-T : test configuration, dump it and exit #测试并打印-q : suppress non-error messages during configuration testing #静默模式-s signal : send signal to a master process: stop, quit, reopen, reload #发送信号,reload信号 会生成新的worker,但master不会重新生成-p prefix : set prefix path (default: /etc/nginx/)#指定Nginx 目录-c filename : set configuration file (default: /etc/nginx/nginx.conf)#配置文件路径-g directives : set global directives out of configuration file#设置全局指令,注意和配置文件不要同时配置,否则冲突 验证配置文件1234[root@centos8 ~]# nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful[root@centos8 ~]# 启动文件1234567891011121314151617181920212223[root@centos8 ~]# cat /lib/systemd/system/nginx.service[Unit]Description=The nginx HTTP and reverse proxy serverAfter=network.target remote-fs.target nss-lookup.target[Service]Type=forkingPIDFile=/run/nginx.pid# Nginx will fail to start if /run/nginx.pid already exists but has the wrong# SELinux context. This might happen when running `nginx -t` from the cmdline.# https://bugzilla.redhat.com/show_bug.cgi?id=1268621ExecStartPre=/usr/bin/rm -f /run/nginx.pidExecStartPre=/usr/sbin/nginx -tExecStart=/usr/sbin/nginxExecReload=/bin/kill -s HUP $MAINPIDKillSignal=SIGQUITTimeoutStopSec=5KillMode=mixedPrivateTmp=true[Install]WantedBy=multi-user.target[root@centos8 ~]# 启动Nginx1systemctl enable --now nginx Nginx编译安装官方源码包下载地址： 1https://nginx.org/en/download.html 范例：编译安装 系统centos8.5 Nginx版本：1.18.0 安装扩展依赖 1[root@centos8 ~]# yum -y install gcc pcre-devel openssl-devel zlib-devel 创建用户和组 12groupadd nginxuseradd -s /sbin/nologin -g nginx nginx 下载安装包并解压 1234[root@centos8 ~]# cd /usr/local/src/[root@centos8 ~]# wget https://nginx.org/download/nginx-1.18.0.tar.gz[root@centos8 src]# tar xf nginx-1.18.0.tar.gz [root@centos8 src]# cd nginx-1.18.0 安装 12345678910111213[root@centos8 nginx-1.18.0]# ./configure --prefix=/usr/local/src/nginx/ \\ # 安装位置--user=nginx \\ # 运行的用户--group=nginx \\--with-http_ssl_module \\--with-http_v2_module \\--with-http_realip_module \\--with-http_stub_status_module \\--with-http_gzip_static_module \\--with-pcre \\--with-stream \\--with-stream_ssl_module[root@centos8 nginx-1.18.0]#make &amp;&amp; make install 修改权限 1[root@centos8 /]# chown -R nginx.nginx /usr/local/src/nginx/ nginx安装完成后有四个主要的目录 1234567891011121314[root@centos8 /]# ll /usr/local/src/nginx/total 4drwxr-xr-x. 2 nginx nginx 4096 Jan 4 15:17 confdrwxr-xr-x. 2 nginx nginx 40 Jan 4 15:17 htmldrwxr-xr-x. 2 nginx nginx 6 Jan 4 15:17 logsdrwxr-xr-x. 2 nginx nginx 19 Jan 4 15:17 sbin[root@centos8 /]# conf：保存nginx所有的配置文件，其中nginx.conf是nginx服务器的最核心最主要的配置文件，其他的.conf则是用来配置nginx相关的功能的，例如fastcgi功能使用的是fastcgi.conf和fastcgi_params两个文件，配置文件一般都有一个样板配置文件，是以.default为后缀，使用时可将其复制并将default后缀去掉即可。html目录中保存了nginx服务器的web文件，但是可以更改为其他目录保存web文件,另外还有一个50x的web文件是默认的错误页面提示页面。logs：用来保存nginx服务器的访问日志错误日志等日志，logs目录可以放在其他 验证版本及编译参数 12345678[root@centos8 /]# ln -s /usr/local/src/nginx/sbin/nginx /usr/bin/[root@centos8 /]# nginx -Vnginx version: nginx/1.18.0built by gcc 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC) built with OpenSSL 1.1.1k FIPS 25 Mar 2021TLS SNI support enabledconfigure arguments: --prefix=/usr/local/src/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-http_stub_status_module --with-http_gzip_static_module --with-pcre --with-stream --with-stream_ssl_module[root@centos8 /]# 创建Nginx启动文件 1234567891011121314151617181920#复制同一版本的nginx的yum安装生成的service文件[root@centos8 ~]# vim /lib/systemd/system/nginx.service [Unit]Description=nginx - high performance web server Documentation=http://nginx.org/en/docs/After=network.target[Service] Type=forkingPIDFile=/usr/local/src/nginx/logs/nginx.pidExecStartPre=/usr/local/src//nginx/sbin/nginx -t -c /usr/local/src/nginx/conf/nginx.confExecStart=/usr/local/src/nginx/sbin/nginx -c /usr/local/src/nginx/conf/nginx.confExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true[Install] WantedBy=multi-user.target 验证启动文件 1234[root@centos8 ~]#systemctl daemon-reload[root@centos8 ~]#systemctl enable --now nginxCreated symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /usr/lib/systemd/system/nginx.service.[root@centos8 ~]# Nginx命令和信号nginx 命令支持向其发送信号,实现不同功能nginx 格式 1nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives] 选项说明 1234567帮助: -? -h使用指定的配置文件: -c指定配置指令:-g指定运行目录:-p测试配置文件是否有语法错误:-t -T打印nginx的版本信息、编译信息等:-v -V发送信号: -s 示例: nginx -s reload 信号说明 123456立刻停止服务:stop,相当于信号SIGTERM,SIGINT 优雅的停止服务:quit,相当于信号SIGQUIT 平滑重启，重新加载配置文件: reload,相当于信号SIGHUP 重新开始记录日志文件:reopen,相当于信号SIGUSR1,在切割日志时用途较大平滑升级可执行程序:发送信号SIGUSR2,在升级版本时使用优雅的停止工作进程:发送信号SIGWINCH,在升级版本时使用","categories":[{"name":"Nginx","slug":"Nginx","permalink":"http://snippet.itshare.work/categories/Nginx/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Nginx","slug":"Nginx","permalink":"http://snippet.itshare.work/categories/Nginx/"}]},{"title":"Redis一键安装脚本","slug":"Redis一键安装脚本","date":"2022-12-17T03:56:02.000Z","updated":"2022-12-29T08:26:35.033Z","comments":true,"path":"2022/12/17/Redis一键安装脚本/","link":"","permalink":"http://snippet.itshare.work/2022/12/17/Redis%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC/","excerpt":"centos、ubuntu、rockylinux系统Redis一键安装脚本","text":"在线安装 系统 Centos7.9 、Rockylinux8.5、Centos8.5、ubuntu20.04实测安装成功 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131#!/bin/bash##********************************************************************#Author: yuankun#Date: 2022-12-17#FileName： install_redis.sh#URL: https://gzyuankun.github.io#Description: The test script#Copyright (C): 2020 All rights reserved#********************************************************************REDIS_VERSION=redis-6.2.5PASSWORD=123456INSTALL_DIR=/usr/local/src/redisCPUS=`lscpu |awk &#x27;/^CPU\\(s\\)/&#123;print $2&#125;&#x27;`. /etc/os-releasecolor () &#123; RES_COL=60 MOVE_TO_COL=&quot;echo -en \\\\033[$&#123;RES_COL&#125;G&quot; SETCOLOR_SUCCESS=&quot;echo -en \\\\033[1;32m&quot; SETCOLOR_FAILURE=&quot;echo -en \\\\033[1;31m&quot; SETCOLOR_WARNING=&quot;echo -en \\\\033[1;33m&quot; SETCOLOR_NORMAL=&quot;echo -en \\E[0m&quot; echo -n &quot;$1&quot; &amp;&amp; $MOVE_TO_COL echo -n &quot;[&quot; if [ $2 = &quot;success&quot; -o $2 = &quot;0&quot; ] ;then $&#123;SETCOLOR_SUCCESS&#125; echo -n $&quot; OK &quot; elif [ $2 = &quot;failure&quot; -o $2 = &quot;1&quot; ] ;then $&#123;SETCOLOR_FAILURE&#125; echo -n $&quot;FAILED&quot; else $&#123;SETCOLOR_WARNING&#125; echo -n $&quot;WARNING&quot; fi $&#123;SETCOLOR_NORMAL&#125; echo -n &quot;]&quot; echo &#125;prepare()&#123; if [ $ID = &quot;centos&quot; -o $ID = &quot;rocky&quot; ];then yum -y install gcc make systemd-devel else apt update apt -y install gcc make libjemalloc-dev libsystemd-dev fi if [ $? -eq 0 ];then color &quot;安装软件包成功&quot; 0 else color &quot;安装软件包失败，请检查网络配置&quot; 1 exit fi&#125;install() &#123; if [ ! -f $&#123;REDIS_VERSION&#125;.tar.gz ];then wget http://download.redis.io/releases/$&#123;REDIS_VERSION&#125;.tar.gz || &#123; color &quot;Redis 源码下载失败&quot; 1 ; exit; &#125; fi tar xf $&#123;REDIS_VERSION&#125;.tar.gz -C /usr/local/src cd /usr/local/src/$&#123;REDIS_VERSION&#125; make -j $CUPS USE_SYSTEMD=yes PREFIX=$&#123;INSTALL_DIR&#125; install &amp;&amp; color &quot;Redis 编译安装完成&quot; 0 || &#123; color &quot;Redis 编译安装失败&quot; 1 ;exit ; &#125; ln -s $&#123;INSTALL_DIR&#125;/bin/redis-* /usr/bin/ mkdir -p $&#123;INSTALL_DIR&#125;/&#123;etc,log,data,run&#125; cp redis.conf $&#123;INSTALL_DIR&#125;/etc/ sed -i -e &#x27;s/bind 127.0.0.1/bind 0.0.0.0/&#x27; -e &quot;/# requirepass/a requirepass $PASSWORD&quot; -e &quot;/^dir .*/c dir $&#123;INSTALL_DIR&#125;/data/&quot; -e &quot;/logfile .*/c logfile $&#123;INSTALL_DIR&#125;/log/redis-6379.log&quot; -e &quot;/^pidfile .*/c pidfile $&#123;INSTALL_DIR&#125;/run/redis_6379.pid&quot; $&#123;INSTALL_DIR&#125;/etc/redis.conf if id redis &amp;&gt; /dev/null ;then color &quot;Redis 用户已存在&quot; 1 else useradd -r -s /sbin/nologin redis color &quot;Redis 用户创建成功&quot; 0 fi chown -R redis.redis $&#123;INSTALL_DIR&#125; cat &gt;&gt; /etc/sysctl.conf &lt;&lt;EOFnet.core.somaxconn = 1024vm.overcommit_memory = 1EOF sysctl -p if [ $ID = &quot;centos&quot; -o $ID = &quot;rocky&quot; ];then echo &#x27;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&#x27; &gt;&gt; /etc/rc.d/rc.local chmod +x /etc/rc.d/rc.local /etc/rc.d/rc.local else echo -e &#x27;#!/bin/bash\\necho never &gt; /sys/kernel/mm/transparent_hugepage/enabled&#x27; &gt;&gt; /etc/rc.local chmod +x /etc/rc.local /etc/rc.local ficat &gt; /lib/systemd/system/redis.service &lt;&lt;EOF[Unit]Description=Redis persistent key-value databaseAfter=network.target[Service]ExecStart=$&#123;INSTALL_DIR&#125;/bin/redis-server $&#123;INSTALL_DIR&#125;/etc/redis.conf --supervised systemdExecStop=/bin/kill -s QUIT \\$MAINPIDType=notifyUser=redisGroup=redisRuntimeDirectory=redisRuntimeDirectoryMode=0755LimitNOFILE=1000000[Install]WantedBy=multi-user.targetEOF systemctl daemon-reload systemctl enable --now redis &amp;&gt; /dev/null if [ $? -eq 0 ];then color &quot;Redis 服务启动成功,Redis信息如下:&quot; 0 else color &quot;Redis 启动失败&quot; 1 exit fi sleep 2 redis-cli -a $PASSWORD INFO Server 2&gt; /dev/null&#125;prepare install","categories":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}]},{"title":"Centos系统yum源配置","slug":"centos系统yum配置","date":"2022-12-17T01:28:09.000Z","updated":"2022-12-17T02:39:43.580Z","comments":true,"path":"2022/12/17/centos系统yum配置/","link":"","permalink":"http://snippet.itshare.work/2022/12/17/centos%E7%B3%BB%E7%BB%9Fyum%E9%85%8D%E7%BD%AE/","excerpt":"yum 的理念是使用一个中心仓库(repository)管理一部分甚至一个distribution 的应用程序相互关系，根据计算出来的软件依赖关系进行相关的升级、安装、删除等等操作，减少了Linux 用户一直头痛的dependencies 的问题","text":"系统Centos7.9 步骤 1.备份 1[root@centos7-master ~]# mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak 2.创建&#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo文件并复制如下内容 12345678910111213141516171819202122232425262728293031323334353637383940414243[base]name=CentOS-$releasever - Basebaseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/ http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/os/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/os/$basearch/ http://mirror.centos.org/centos/$releasever/os/$basearch/ gpgcheck=0#released updates [updates]name=CentOS-$releasever - Updatesbaseurl=http://mirrors.163.com/centos/$releasever/updates/$basearch/ http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/updates/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/updates/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/updates/$basearch/ http://mirror.centos.org/centos/$releasever/updates/$basearch/ gpgcheck=0#additional packages that may be useful[extras]name=CentOS-$releasever - Extrasbaseurl=http://mirrors.163.com/centos/$releasever/extras/$basearch/ http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/extras/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/extras/$basearch/ http://mirror.centos.org/centos/$releasever/extras/$basearch/gpgcheck=0#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plusbaseurl=http://mirrors.163.com/centos/$releasever/centosplus/$basearch/ http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/ http://mirrors.cloud.tencent.com/centos/$releasever/centosplus/$basearch/ http://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/centosplus/$basearch/ http://mirrors.huaweicloud.com/centos/$releasever/centosplus/$basearch/ http://mirror.centos.org/centos/$releasever/centosplus/$basearch/gpgcheck=0enabled=1 3.清除缓存 1yum clean all 4.重新生成缓存 1yum makecache","categories":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"Redis集群和高可用","slug":"Redis集群和高可用","date":"2022-12-13T14:20:06.000Z","updated":"2022-12-18T14:10:14.494Z","comments":true,"path":"2022/12/13/Redis集群和高可用/","link":"","permalink":"http://snippet.itshare.work/2022/12/13/Redis%E9%9B%86%E7%BE%A4%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/","excerpt":"Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题","text":"简介Redis单机服务存在数据和服务的单点问题,而且单机性能也存在着上限,可以利用Redis的集群相关技术来解决这些问题. 主从复制实现主从命令配置 当配置Redis复制功能时，强烈建议打开主服务器的持久化功能。否则的话，由于延迟等问题，部署的主节点Redis服务应该要避免自动启动。 参考案例: 导致主从服务器数据全部丢失 1231.假设节点A为主服务器，并且关闭了持久化。并且节点B和节点C从节点A复制数据2.节点A崩溃，然后由自动拉起服务重启了节点A.由于节点A的持久化被关闭了，所以重启之后没有任何数据3.节点B和节点C将从节点A复制数据，但是A的数据是空的，于是就把自身保存的数据副本删除。 在关闭主服务器上的持久化，并同时开启自动拉起进程的情况下，即便使用Sentinel来实现Redis的高可用性，也是非常危险的。因为主服务器可能拉起得非常快，以至于Sentinel在配置的心跳时间间隔内没有检测到主服务器已被重启，然后还是会执行上面的数据丢失的流程。无论何时，数据安全都是极其重要的，所以应该禁止主服务器关闭持久化的同时自动启动。 启用主从同步Redis Server 默认为 master节点，如果要配置为从节点,需要指定master服务器的IP,端口及连接密码在从节点执行 REPLICAOF MASTER_IP PORT 指令可以启用主从同步复制功能,早期版本使用 SLAVEOF指令 123127.0.0.1:6379&gt; REPLICAOF MASTER_IP PORT #新版推荐使用127.0.0.1:6379&gt; SLAVEOF MasterIP Port #旧版使用，将被淘汰127.0.0.1:6379&gt; CONFIG SET masterauth &lt;masterpass&gt; 在master实现 12345678910111213141516127.0.0.1:6379&gt; AUTH 123456OK127.0.0.1:6379&gt; INFO replication #查看当前角色默认为master# Replicationrole:masterconnected_slaves:0master_failover_state:no-failovermaster_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77master_replid2:0000000000000000000000000000000000000000master_repl_offset:1361second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:1361127.0.0.1:6379&gt; 在slave实现 12345678910111213141516171819202122232425262728293031323334#在slave上设置master的IP和端口，4.0版之前的指令为slaveof127.0.0.1:6380&gt; REPLICAOF 127.0.0.1 6379 #仍可使用SLAVEOF MasterIP PortOK127.0.0.1:6380&gt; #在slave上设置master的密码127.0.0.1:6379&gt; CONFIG SET masterauth 123456# Replication #角色变为slave127.0.0.1:6380&gt; INFO replication# Replicationrole:slavemaster_host:127.0.0.1 #指向mastermaster_port:6379master_link_status:upmaster_last_io_seconds_ago:1master_sync_in_progress:0slave_read_repl_offset:1515slave_repl_offset:1515slave_priority:100slave_read_only:1replica_announced:1connected_slaves:0master_failover_state:no-failovermaster_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77master_replid2:0000000000000000000000000000000000000000master_repl_offset:1515second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1362repl_backlog_histlen:154127.0.0.1:6380&gt; 在master实现 1234# 添加值127.0.0.1:6379&gt; set class m48OK127.0.0.1:6379&gt; 在slave验证是否同步过来 123456# 在slave执行127.0.0.1:6380&gt; get class&quot;m48&quot;127.0.0.1:6380&gt; # 可以看到已经同步成功 master实现 12345678910111213141516#在master上可以看到所有slave信息127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6380,state=online,offset=1907,lag=0master_failover_state:no-failovermaster_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77master_replid2:0000000000000000000000000000000000000000master_repl_offset:1907second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:1907127.0.0.1:6379&gt; 删除主从同步 在slave实现 1234# 在从节点执行 REPLICAOF NO ONE 指令可以取消主从复制#取消复制,在slave上执行REPLICAOF NO ONE,会断开和master的连接不再主从复制, 但不会清除slave上已有的数据127.0.0.1:6380&gt; REPLICAOF no one 验证同步 查看master日志 123456789101112[root@centos7-master ~]# tail -f /usr/local/src/redis/log/redis_6379.log 945:M 13 Dec 2022 22:27:17.550 * Synchronization with replica 127.0.0.1:6380 succeeded945:M 13 Dec 2022 22:42:59.410 # Connection with replica 127.0.0.1:6380 lost.945:M 13 Dec 2022 22:46:34.373 * Replica 127.0.0.1:6380 asks for synchronization945:M 13 Dec 2022 22:46:34.373 * Partial resynchronization not accepted: Replication ID mismatch (Replica asked for &#x27;1200062e6b1065421dec8531ca2d96776029ab3d&#x27;, my replication IDs are &#x27;f945fd1714d8d3b78a149c8b2e0d57567ee6cb77&#x27; and &#x27;0000000000000000000000000000000000000000&#x27;)945:M 13 Dec 2022 22:46:34.373 * Starting BGSAVE for SYNC with target: disk945:M 13 Dec 2022 22:46:34.374 * Background saving started by pid 16901690:C 13 Dec 2022 22:46:34.376 * DB saved on disk1690:C 13 Dec 2022 22:46:34.377 * RDB: 2 MB of memory used by copy-on-write945:M 13 Dec 2022 22:46:34.435 * Background saving terminated with success945:M 13 Dec 2022 22:46:34.435 * Synchronization with replica 127.0.0.1:6380 succeeded 查看slave日志 123456789101112[root@centos7-master ~]# tail -f /usr/local/src/redis/log/redis_6380.log946:S 13 Dec 2022 22:46:34.436 * MASTER &lt;-&gt; REPLICA sync: Finished with success946:S 13 Dec 2022 22:46:34.437 * Background append only file rewriting started by pid 1691946:S 13 Dec 2022 22:46:34.470 * AOF rewrite child asks to stop sending diffs.1691:C 13 Dec 2022 22:46:34.470 * Parent agreed to stop sending diffs. Finalizing AOF...1691:C 13 Dec 2022 22:46:34.470 * Concatenating 0.00 MB of AOF diff received from parent.1691:C 13 Dec 2022 22:46:34.470 * SYNC append only file rewrite performed1691:C 13 Dec 2022 22:46:34.471 * AOF rewrite: 2 MB of memory used by copy-on-write946:S 13 Dec 2022 22:46:34.536 * Background AOF rewrite terminated with success946:S 13 Dec 2022 22:46:34.536 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)946:S 13 Dec 2022 22:46:34.536 * Background AOF rewrite finished successfully 修改slave配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@centos7-master ~]# vim /usr/local/src/redis/etc/redis6380.conf # replicaof &lt;masterip&gt; &lt;masterport&gt;replicaof 127.0.0.1 6379 #指定master的IP和端口号，我这里在同一台机器上安装了多实例# masterauth &lt;master-password&gt;masterauth 123456 #如果密码需要设置systemctl restart redis#在master上查看状态127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=127.0.0.1,port=6380,state=online,offset=3307,lag=1slave1:ip=127.0.0.1,port=6381,state=online,offset=3307,lag=1master_failover_state:no-failovermaster_replid:f945fd1714d8d3b78a149c8b2e0d57567ee6cb77master_replid2:0000000000000000000000000000000000000000master_repl_offset:3307second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:3307127.0.0.1:6379&gt; #停止master的redis服务：systemctl stop redis,在slave上可以观察到以下现象127.0.0.1:6381&gt; info replication# Replicationrole:slavemaster_host:192.168.1.104master_port:6379master_link_status:down #显示down，表示无法连接mastermaster_last_io_seconds_ago:-1master_sync_in_progress:0slave_read_repl_offset:84slave_repl_offset:84master_link_down_since_seconds:14slave_priority:100slave_read_only:1replica_announced:1connected_slaves:0master_failover_state:no-failovermaster_replid:f6eefc841166e73282b4bab58527081653ddb0d1master_replid2:0000000000000000000000000000000000000000master_repl_offset:84second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:15repl_backlog_histlen:70127.0.0.1:6381&gt; slave 只读状态验证Slave节点为只读状态, 不支持写入 123127.0.0.1:6381&gt; set ll aa(error) READONLY You can&#x27;t write against a read only replica.127.0.0.1:6381&gt; Redis实现哨兵架构以下案例实现一主两从的基于哨兵的高可用Redis架构 先实现主从架构 哨兵的前提是已经实现了Redis的主从复制注意: master 的配置文件中masterauth 和slave 都必须相同所有主从节点的 redis.conf 中关健配置范例: 准备主从环境配置 12345678910111213#在所有主从节点执行vim redis.confbind 0.0.0.0masterauth &quot;123456&quot;requirepass &quot;123456&quot;#或者非交互执行[root@centos8 ~]#sed -i -e &#x27;s/bind 127.0.0.1/bind 0.0.0.0/&#x27; -e &#x27;s/^# masterauth.*/masterauth 123456/&#x27; -e &#x27;s/^# requirepass .*/requirepass 123456/&#x27;/etc/redis.conf#在所有从节点执行[root@centos8 ~]#echo &quot;replicaof 192.168.32.133 6379&quot; &gt;&gt; /etc/redis.conf#在所有主从节点执行[root@centos8 ~]#systemctl enable --now redis 配置slave1 1234567[root@redis-slave1 ~]#redis-cli -a 123456Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interfacemay not be safe.127.0.0.1:6379&gt; REPLICAOF 192.168.32.133 6379OK127.0.0.1:6379&gt; CONFIG SET masterauth &quot;123456&quot;OK 配置slave2 1234567[root@redis-slave2 ~]#redis-cli -a 123456Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interfacemay not be safe.127.0.0.1:6379&gt; REPLICAOF 192.168.32.133 6379OK127.0.0.1:6379&gt; CONFIG SET masterauth &quot;123456&quot;OK 编辑哨兵配置sentinel配置Sentinel实际上是一个特殊的redis服务器,有些redis指令支持,但很多指令并不支持.默认监听在26379&#x2F;tcp端口.哨兵服务可以和Redis服务器分开部署在不同主机，但为了节约成本一般会部署在一起所有redis节点使用相同的以下示例的配置文件 1234567891011121314151617181920212223242526272829#如果是编译安装，在源码目录有sentinel.conf，复制到安装目录即可，如:/usr/local/src/redis/etc/sentinel.conf[root@centos8 ~]#cp redis-6.2.5/sentinel.conf /usr/local/src/redis/etc/[root@centos8 ~]#chown redis.redis /usr/local/src/redis/etc/sentinel.conf[root@centos8 ~]#vim /etc/redis-sentinel.confbind 0.0.0.0port 26379daemonize yespidfile &quot;redis-sentinel.pid&quot;logfile &quot;sentinel_26379.log&quot;dir &quot;/tmp&quot; #工作目录sentinel monitor mymaster 10.0.0.8 6379 2#mymaster是集群的名称，此行指定当前mymaster集群中master服务器的地址和端口#2为法定人数限制(quorum)，即有几个sentinel认为master down了就进行故障转移，一般此值是所有sentinel节点(一般总数是&gt;=3的 奇数,如:3,5,7等)的一半以上的整数值，比如，总数是3，即3/2=1.5，取整为2,是master的ODOWN客观下线的依据sentinel auth-pass mymaster 123456#mymaster集群中master的密码，注意此行要在上面行的下面sentinel down-after-milliseconds mymaster 30000#判断mymaster集群中所有节点的主观下线(SDOWN)的时间，单位：毫秒，建议3000sentinel parallel-syncs mymaster 1#发生故障转移后，可以同时向新master同步数据的slave的数量，数字越小总同步时间越长，但可以减轻新master的负载压力sentinel failover-timeout mymaster 180000#所有slaves指向新的master所需的超时时间，单位：毫秒sentinel deny-scripts-reconfig yes #禁止修改脚本logfile /var/log/redis/sentinel.log 三个哨兵服务器的配置都如下 123456789101112131415161718192021port 26379daemonize nopidfile &quot;/var/run/redis-sentinel.pid&quot;logfile &quot;/var/log/redis/sentinel.log&quot;dir &quot;/tmp&quot;sentinel monitor mymaster 192.168.32.133 6379 2 #修改此行sentinel auth-pass mymaster 123456 #增加此行sentinel down-after-milliseconds mymaster 3000 #修改此行sentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster 180000sentinel deny-scripts-reconfig yes#注意此行自动生成必须唯一,一般不需要修改，如果相同则修改此值需重启redis和sentinel服务sentinel myid 50547f34ed71fd48c197924969937e738a39975b.....# Generated by CONFIG REWRITEprotected-mode nosupervised systemdsentinel leader-epoch mymaster 0sentinel known-replica mymaster 10.0.0.28 6379sentinel known-replica mymaster 10.0.0.18 6379sentinel current-epoch 0 启动哨兵服务将所有哨兵服务器都启动起来 1/usr/local/src/redis/bin/redis-sentinel /usr/local/src/redis/etc/sentinel.conf 将服务写成service文件 1234567891011121314151617vim /lib/systemd/system/redis-sentinel.service[Unit]Description=Redis SentinelAfter=network.target[Service]ExecStart=/usr/local/src/redis/bin/redis-sentinel /usr/local/src/redis/etc/sentinel.conf --supervised systemdExecStop=/bin/kill -s QUIT $MAINPIDUser=redisGroup=redisRuntimeDirectory=redisRuntimeDirectoryMode=0755[Install]WantedBy=multi-user.target#注意所有节点的目录权限,否则无法启动服务[root@redis-master ~]#chown -R redis.redis /usr.local/src/redis/ 验证哨兵服务 查看哨兵服务端口状态,端口26379 12345678[root@centos8 log]# ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port Process LISTEN 0 511 0.0.0.0:26379 0.0.0.0:* LISTEN 0 511 0.0.0.0:6379 0.0.0.0:* LISTEN 0 128 0.0.0.0:22 0.0.0.0:* LISTEN 0 511 [::1]:6379 [::]:* LISTEN 0 128 [::]:22 [::]:* [root@centos8 log]# Sentinel 运维 手动让主节点下线 1127.0.0.1:26379&gt; sentinel failover &lt;masterName&gt; 范例：手动故障转移 12345678910111213141516171819vim redis.confreplica-priority 10 #指定优先级,值越小sentinel会优先将之选为新的master,默为值为100systemctl restart redis#或者动态修改[root@centos8 ~]#redis-cli -a 123456Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interfacemay not be safe.127.0.0.1:6379&gt; CONFIG GET replica-priority1) &quot;replica-priority&quot;2) &quot;100&quot;127.0.0.1:6379&gt; CONFIG SET replica-priority 99OK127.0.0.1:6379&gt; CONFIG GET replica-priority1) &quot;replica-priority&quot;2) &quot;99&quot;[root@centos8 ~]#redis-cli -p 26379127.0.0.1:26379&gt; sentinel failover mymasterOK 应用程序连接 SentinelRedis 官方支持多种开发语言的客户端：https://redis.io/clients 客户端连接 Sentinel 工作原理 客户端获取 Sentinel 节点集合,选举出一个 Sentinel 由这个sentinel 通过masterName 获取master节点信息,客户端通过sentinel get-master-addr-by-name master-name这个api来获取对应主节点信息 客户端发送role指令确认master的信息,验证当前获取的“主节点”是真正的主节点，这样的目的是为了防止故障转移期间主节点的变化 客户端保持和Sentinel节点集合的联系，即订阅Sentinel节点相关频道，时刻获取关于主节点的相关信息,获取新的master 信息变化,并自动连接新的master java 连接Sentinel哨兵java 客户端连接Redis：https://github.com/xetorthio/jedis/blob/master/pom.xml python 连接 Sentinel 哨兵123456789101112131415161718192021222324252627282930313233343536[root@centos8 ~]#yum -y install python3 python3-redis[root@centos8 ~]#vim sentinel_test.py#!/usr/bin/python3import redisfrom redis.sentinel import Sentinel#连接哨兵服务器(主机名也可以用域名)sentinel = Sentinel([(&#x27;192.168.32.135&#x27;, 26379), (&#x27;192.168.32.133&#x27;, 26379), (&#x27;192.168.32.132&#x27;, 26379)],socket_timeout=0.5)redis_auth_pass = &#x27;123456&#x27;#mymaster 是配置哨兵模式的redis集群名称，此为默认值,实际名称按照个人部署案例来填写#获取主服务器地址master = sentinel.discover_master(&#x27;mymaster&#x27;)print(&quot;master:&quot;,master)#获取从服务器地址slave = sentinel.discover_slaves(&#x27;mymaster&#x27;)print(&quot;slave:&quot;,slave)#获取主服务器进行写入master = sentinel.master_for(&#x27;mymaster&#x27;, socket_timeout=0.5,password=redis_auth_pass, db=0)w_ret = master.set(&#x27;name&#x27;, &#x27;xy&#x27;)#输出：True#获取从服务器进行读取（默认是round-roubin）slave = sentinel.slave_for(&#x27;mymaster&#x27;, socket_timeout=0.5,password=redis_auth_pass, db=0)r_ret = slave.get(&#x27;name&#x27;)print(r_ret)#输出：xychmod +x sentinel_test.py./sentinel_test.pymaster: (&#x27;192.168.32.135&#x27;, 6379)slave: [(&#x27;192.168.32.133&#x27;, 6379)]b&#x27;xy&#x27; Redis Cluster Redis Cluster 介绍使用哨兵sentinel 只能解决Redis高可用问题，实现Redis的自动故障转移,但仍然无法解决Redis Master单节点的性能瓶颈问题为了解决单机性能的瓶颈，提高Redis 服务整体性能，可以使用分布式集群的解决方案早期 Redis 分布式集群部署方案： 客户端分区：由客户端程序自己实现写入分配、高可用管理和故障转移等,对客户端的开发实现较为复杂 代理服务：客户端不直接连接Redis,而先连接到代理服务，由代理服务实现相应读写分配，当前代理服务都是第三方实现.此方案中客户端实现无需特殊开发,实现容易,但是代理服务节点仍存有单点故障和性能瓶颈问题。比如：豌豆荚开发的 codis Redis 3.0 版本之后推出无中心架构的 Redis Cluster ，支持多个master节点并行写入和故障的自动转移动能 Redis cluster 架构Redis cluster 架构 Redis cluster 需要至少 3个master节点才能实现,slave节点数量不限,当然一般每个master都至少对应的有一个slave节点如果有三个主节点采用哈希槽 hash slot 的方式来分配16384个槽位 slot此三个节点分别承担的slot 区间可以是如以下方式分配 123节点M1 0－5460节点M2 5461－10922节点M3 10923－16383 Redis cluster的工作原理 数据分区如果是单机存储的话，直接将数据存放在单机redis就行了。但是如果是集群存储，就需要考虑到数据分区了。 集群通信但是寻找槽的过程并不是一次就命中的，比如上图key将要存放在14396槽中，但是并不是一下就锁定了node3节点，可能先去询问node1，然后才访问node3。而集群中节点之间的通信，保证了最多两次就能命中对应槽所在的节点。因为在每个节点中，都保存了其他节点的信息，知道哪个槽由哪个节点负责。这样即使第一次访问没有命中槽，但是会通知客户端，该槽在哪个节点，这样访问对应节点就能精准命中。 集群伸缩集群并不是建立之后，节点数就固定不变的，也会有新的节点加入集群或者集群中的节点下线，这就是集群的扩容和缩容。但是由于集群节点和槽息息相关，所以集群的伸缩也对应了槽和数据的迁移 集群扩容当有新的节点准备好加入集群时，这个新的节点还是孤立节点，加入有两种方式。一个是通过集群节点执行命令来和孤立节点握手，另一个则是使用脚本来添加节点。 集群缩容 故障转移 当从节点走马上任变成主节点之后，就要开始进行替换主节点： 让该slave节点执行slaveof no one变为master节点 将故障节点负责的槽分配给该节点 向集群中其他节点广播Pong消息，表明已完成故障转移 故障节点重启后，会成为new_master的slave节点 实战案例基于Redis 5 以上版本的 redis cluster 部署官方文档：https://redis.io/topics/cluster-tutorial 创建 redis cluster集群的环境准备 每个Redis 节点采用相同的相同的Redis版本、相同的密码、硬件配置 所有Redis服务器必须没有任何数据 准备六台主机，地址如下： 123456192.168.32.132192.168.32.137192.168.32.140192.168.32.129192.168.32.136192.168.32.138 启用 redis cluster 配置每个节点安装相同版每个节点修改redis配置，必须开启cluster功能的参数 12345678910vim /etc/redis.confbind 0.0.0.0masterauth 123456 #建议配置，否则后期的master和slave主从复制无法成功，还需再配置requirepass 123456cluster-enabled yes #取消此行注释,必须开启集群，开启后 redis 进程会有cluster标识cluster-config-file nodes-6379.conf #取消此行注释,此为集群状态数据文件,记录主从关系及slot范围信息,由redis cluster 集群自动创建和维护cluster-require-full-coverage no #默认值为yes,设为no可以防止一个节点不可用导致整个cluster不可用 以下方式二选一 执行下面命令,批量修改 12sed -i.bak -e &#x27;s/bind 127.0.0.1/bind 0.0.0.0/&#x27; -e &#x27;/masterauth/a masterauth 123456&#x27; -e &#x27;/# requirepass/a requirepass 123456&#x27; -e &#x27;/# cluster-enabled yes/a cluster-enabled yes&#x27; -e &#x27;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf&#x27; -e &#x27;/cluster-require-full-coverage yes/c cluster-require-full-coverage no&#x27; /etc/redis.conf 如果是编译安装可以执行下面操作 1sed -i.bak -e &#x27;/masterauth/a masterauth 123456&#x27; -e &#x27;/# cluster-enabled yes/a cluster-enabled yes&#x27; -e &#x27;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf&#x27; -e &#x27;/cluster-require-full-coverage yes/c cluster-require-full-coverage no&#x27; /usr/local/src/redis/etc/redis.conf 开机启动redis 123systemctl enable --now redis# 修改完配置文件重启redissystemctl restart redis 验证当前Redis服务状态： 123456789101112#开启了16379的cluster的端口,实际的端口=redis port + 10000[root@centos7 ~]# ss -ntlState Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 *:22 *:* LISTEN 0 100 127.0.0.1:25 *:* LISTEN 0 511 *:16379 *:* LISTEN 0 511 *:6379 *:* LISTEN 0 128 [::]:22 [::]:* LISTEN 0 100 [::1]:25 [::]:* LISTEN 0 511 [::1]:16379 [::]:* LISTEN 0 511 [::1]:6379 [::]:* [root@centos7 ~]# 创建集群1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#命令redis-cli的选项 --cluster-replicas 1 表示每个master对应一个slave节点# 默认前三个为主节点[root@centos8 etc]# redis-cli -a 123456 --cluster create 192.168.32.132:6379 192.168.32.137:6379 192.168.32.140:6379 192.168.32.129:6379 192.168.32.136:6379 192.168.32.138:6379 --cluster-replicas 1Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Master[0] -&gt; Slots 0 - 5460Master[1] -&gt; Slots 5461 - 10922Master[2] -&gt; Slots 10923 - 16383Adding replica 192.168.32.136:6379 to 192.168.32.132:6379Adding replica 192.168.32.138:6379 to 192.168.32.137:6379Adding replica 192.168.32.129:6379 to 192.168.32.140:6379M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) masterM: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) masterM: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) masterS: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731eS: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 replicates 658dd91e4b51bf06b161e6903d4084c77abd195dS: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 replicates 46b54e8298e11e77450e232c9a0ee057b362191aCan I set the above configuration? (type &#x27;yes&#x27; to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s)S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731eM: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s)M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195dS: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.[root@centos8 ~]# 验证集群 查看主从状态 123456789101112131415127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=192.168.32.136,port=6379,state=online,offset=98,lag=1master_failover_state:no-failovermaster_replid:b1bd51213722f38a83c8bb525e8a74e62392a161master_replid2:0000000000000000000000000000000000000000master_repl_offset:98second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:98127.0.0.1:6379&gt; 验证集群状态 1234567891011121314151617181920212223242526272829127.0.0.1:6379&gt; CLUSTER INFOcluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6 # 节点数cluster_size:3 # 三个集群cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:210cluster_stats_messages_pong_sent:210cluster_stats_messages_sent:420cluster_stats_messages_ping_received:205cluster_stats_messages_pong_received:210cluster_stats_messages_meet_received:5cluster_stats_messages_received:420127.0.0.1:6379&gt; #查看任意节点的集群状态[root@centos8 ~]# redis-cli -a 123456 --cluster info 192.168.32.137:6379Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 5462 slots | 1 slaves.192.168.32.140:6379 (f49ca2e5...) -&gt; 0 keys | 5461 slots | 1 slaves.192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 5461 slots | 1 slaves.[OK] 0 keys in 3 masters.0.00 keys per slot on average.[root@centos8 ~]# 查看对应关系 123456789[root@centos8 ~]# redis-cli -a 123456 CLUSTER NODESWarning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379@16379 slave f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 0 1671364792207 3 connected658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379@16379 myself,master - 0 1671364792000 1 connected 0-5460f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379@16379 master - 0 1671364792000 3 connected 10923-1638346b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379@16379 master - 0 1671364793216 2 connected 5461-10922f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379@16379 slave 658dd91e4b51bf06b161e6903d4084c77abd195d 0 1671364793000 1 connectedeec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379@16379 slave 46b54e8298e11e77450e232c9a0ee057b362191a 0 1671364792000 2 connected[root@centos8 ~]# 测试集群写入数据 redis cluster 写入key 12345678910111213141516171819202122#经过算法计算，当前key的槽位需要写入指定的node[root@centos8 ~]# redis-cli -a 123456 set k1 v1Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.(error) MOVED 12706 192.168.32.140:6379 #槽位不在当前node所以无法写入[root@centos8 ~]# #指定槽位对应node可写入[root@centos8 ~]# redis-cli -h 192.168.32.140 -a 123456 set k1 v1Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.OK[root@centos8 ~]# #对应的slave节点可以KEYS *,但GET k1失败,可以到master上执行GET k1[root@centos8 ~]# redis-cli -h 192.168.32.129 -a 123456 get k1Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.(error) MOVED 12706 192.168.32.140:6379[root@centos8 ~]# redis-cli -h 192.168.32.129 -a 123456 keys &quot;*&quot;Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.1) &quot;k1&quot;[root@centos8 ~]# Redis cluster 管理集群扩容扩容适用场景：当前客户量激增，现有的Redis cluster架构已经无法满足越来越高的并发访问请求，为解决此问题,新购置两台服务器，要求将其动态添加到现有集群，但不能影响业务的正常访问。注意: 生产环境一般建议master节点为奇数个,比如:3,5,7,以防止脑裂现象 添加节点准备 增加Redis 新节点，需要与之前的Redis node版本和配置一致，然后分别再启动两台Redis node，应为一主一从。 123456192.168.32.133 主192.168.32.139 从# 修改配置文件,主从节点都修改sed -i.bak -e &#x27;/masterauth/a masterauth 123456&#x27; -e &#x27;/# cluster-enabled yes/a cluster-enabled yes&#x27; -e &#x27;/# cluster-config-file nodes-6379.conf/a cluster-config-file nodes-6379.conf&#x27; -e &#x27;/cluster-require-full-coverage yes/c cluster-require-full-coverage no&#x27; /usr/local/src/redis/etc/redis.confsystemctl restart redis 添加新的master节点到集群使用以下命令添加新节点，要添加的新redis节点IP和端口添加到的已有的集群中任意节点的IP:端口 12345add-node new_host:new_port existing_host:existing_port [--slave --master-id&lt;arg&gt;]#说明：new_host:new_port #指定新添加的主机的IP和端口existing_host:existing_port #指定已有的集群中任意节点的IP和端口 Redis 3&#x2F;4 版本的添加命令： 12#把新的Redis 节点192.168.32.133添加到当前Redis集群当中。[root@redis-node1 ~]#redis-trib.rb add-node 192.168.32.133:6379 192.168.32.132:6379 Redis 5 以上版本的添加命令： 123456789101112131415161718192021222324252627282930313233#将一台新的主机加入集群[root@redis-node1 ~]#redis-cli -a 123456 --cluster add-node 192.168.32.133:6379 &lt;当前任意集群节点&gt;:6379[root@centos8 data]# redis-cli -a 123456 --cluster add-node 192.168.32.133:6379 192.168.32.132:6379Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.&gt;&gt;&gt; Adding node 192.168.32.133:6379 to cluster 192.168.32.132:6379&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s)S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731eM: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s)M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195dS: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.&gt;&gt;&gt; Send CLUSTER MEET to node 192.168.32.133:6379 to make it join the cluster.[OK] New node added correctly.[root@centos8 data]# 在新的master上重新分配槽位新的node节点加到集群之后,默认是master节点，但是没有slots，需要重新分配,否则没有槽位将无法访问注意: 重新分配槽位需要清空数据,所以需要先备份数据,扩展后再恢复数据Redis 3&#x2F;4 版本命令: 123[root@redis-node1 ~]# redis-trib.rb check 10.0.0.67:6379 #当前状态[root@redis-node1 ~]# redis-trib.rb reshard &lt;任意节点&gt;:6379 #重新分片[root@redis-node1 ~]# redis-trib.rb fix 10.0.0.67:6379 #如果迁移失败使用此命令修复集群 Redis 5以上版本命令： 123456789101112131415161718192021222324252627282930313233343536[root@redis-node1 ~]#redis-cli -a 123456 --cluster reshard &lt;当前任意集群节点&gt;:6379[root@centos8 data]# redis-cli -a 123456 --cluster reshard 192.168.32.133:6379Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.133:6379)M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots: (0 slots) masterS: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191aM: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-5460] (5461 slots) master 1 additional replica(s)M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731eS: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195dM: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[10923-16383] (5461 slots) master 1 additional replica(s)[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 4096# 复制新加入的节点的ID，即192.168.32.133的节点IDWhat is the receiving node ID? 77cfc3429c8b470331520074faea7c3a21f77d1fPlease enter all the source node IDs. Type &#x27;all&#x27; to use all the nodes as source nodes for the hash slots. Type &#x27;done&#x27; once you entered all the source nodes IDs.Source node #1: all # 选择allDo you want to proceed with the proposed reshard plan (yes/no)? yes 为新的master指定新的slave节点 当前Redis集群中新的master节点存单点问题,还需要给其添加一个对应slave节点，实现高可用功能有两种方式：方法1：在新加节点到集群时，直接将之设置为slaveRedis 3&#x2F;4 添加命令 12redis-trib.rb add-node --slave --master-id750cab050bc81f2655ed53900fd43d2e64423333 192.168.32.139:6379 &lt;任意集群节点&gt;:6379 Redis 5 以上版本添加命令： 12redis-cli -a 123456 --cluster add-node 192.168.32.139:6379 &lt;任意集群节点&gt;:6379 --cluster-slave --cluster-master-id d6e2eca6b338b717923f64866bd31d42e52edc98 范例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 查看当前状态[root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 4096 slots | 1 slaves.192.168.32.133:6379 (77cfc342...) -&gt; 0 keys | 4096 slots | 0 slaves.192.168.32.140:6379 (f49ca2e5...) -&gt; 1 keys | 4096 slots | 1 slaves.192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 4096 slots | 1 slaves.[OK] 1 keys in 4 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s)M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) masterS: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731eM: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s)M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s)S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195dS: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.[root@centos8 ~]# #直接加为slave节点[root@centos8 ~]# redis-cli -a 123456 --cluster add-node 192.168.32.139:6379 192.168.32.132:6379 --cluster-slave --cluster-master-id 77cfc3429c8b470331520074faea7c3a21f77d1f# 验证[root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 4096 slots | 1 slaves.192.168.32.133:6379 (77cfc342...) -&gt; 0 keys | 4096 slots | 1 slaves.192.168.32.140:6379 (f49ca2e5...) -&gt; 1 keys | 4096 slots | 1 slaves.192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 4096 slots | 1 slaves.[OK] 1 keys in 4 masters.0.00 keys per slot on average. 集群缩容缩容适用场景：随着业务萎缩用户量下降明显,和领导商量决定将现有Redis集群的8台主机中下线两台主机挪做它用,缩容后性能仍能满足当前业务需求删除节点过程：扩容时是先添加node到集群，然后再分配槽位，而缩容时的操作相反，是先将被要删除的node上的槽位迁移到集群中的其他node上，然后 才能再将其从集群中删除，如果一个node上的槽位没有被完全迁移空，删除该node时也会提示有数据出错导致无法删除。 迁移要删除的master节点上面的槽位到其它master注意: 被迁移Redis master源服务器必须保证没有数据，否则迁移报错并会被强制中断。Redis 3&#x2F;4 版本命令 12[root@redis-node1 ~]# redis-trib.rb reshard 10.0.0.8:6379[root@redis-node1 ~]# redis-trib.rb fix 10.0.0.8:6379 #如果迁移失败使用此命令修复集群 Redis 5版本以上命令 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# 查看当前状态[root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 4096 slots | 1 slaves.192.168.32.133:6379 (77cfc342...) -&gt; 0 keys | 4096 slots | 1 slaves.192.168.32.140:6379 (f49ca2e5...) -&gt; 1 keys | 4096 slots | 1 slaves.192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 4096 slots | 1 slaves.[OK] 1 keys in 4 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s)M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s)S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731eM: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s)M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s)S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195dS: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1fS: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.[root@centos8 ~]# #连接到任意集群节点，#最后1365个slot从192.168.32.133移动到第一个master节点192.168.32.132上[root@centos8 ~]# redis-cli -a 123456 --cluster reshard 192.168.32.132:6379Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[1365-5460] (4096 slots) master 1 additional replica(s)M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master 1 additional replica(s)S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731eM: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s)M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s)S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195dS: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1fS: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.How many slots do you want to move (from 1 to 16384)? 1356 #共4096/3分别给其它三个master节点What is the receiving node ID? 658dd91e4b51bf06b161e6903d4084c77abd195d # master idPlease enter all the source node IDs. Type &#x27;all&#x27; to use all the nodes as source nodes for the hash slots. Type &#x27;done&#x27; once you entered all the source nodes IDs.Source node #1: 77cfc3429c8b470331520074faea7c3a21f77d1f # 删除ID，192.168.32.133的IDSource node #2: doneDo you want to proceed with the proposed reshard plan (yes/no)? yes# redis-cli -a 123456 --cluster reshard 192.168.32.132:6379 该命令在执行两次 从集群中删除服务器 上面步骤完成后,槽位已经迁移走，但是节点仍然还属于集群成员，因此还需从集群删除该节点注意: 删除服务器前,必须清除主机上面的槽位,否则会删除主机失败Redis 3&#x2F;4命令： 1234567[root@s~]#redis-trib.rb del-node &lt;任意集群节点的IP&gt;:6379dfffc371085859f2858730e1f350e9167e287073#dfffc371085859f2858730e1f350e9167e287073 是删除节点的ID&gt;&gt;&gt; Removing node dfffc371085859f2858730e1f350e9167e287073 from cluster192.168.7.102:6379&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; SHUTDOWN the node. Redis 5以上版本命令： 123[root@redis-node1 ~]#redis-cli -a 123456 --cluster del-node &lt;任意集群节点的IP&gt;:6379cb028b83f9dc463d732f6e76ca6bbcd469d948a7#cb028b83f9dc463d732f6e76ca6bbcd469d948a7是删除节点的ID 范例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 查看节点信息[root@centos8 ~]# redis-cli -a 123456 --cluster check 192.168.32.132:6379Warning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.192.168.32.132:6379 (658dd91e...) -&gt; 0 keys | 8164 slots | 1 slaves.192.168.32.133:6379 (77cfc342...) -&gt; 0 keys | 28 slots | 1 slaves.192.168.32.140:6379 (f49ca2e5...) -&gt; 1 keys | 4096 slots | 1 slaves.192.168.32.137:6379 (46b54e82...) -&gt; 0 keys | 4096 slots | 1 slaves.[OK] 1 keys in 4 masters.0.00 keys per slot on average.&gt;&gt;&gt; Performing Cluster Check (using node 192.168.32.132:6379)M: 658dd91e4b51bf06b161e6903d4084c77abd195d 192.168.32.132:6379 slots:[0-6826],[10923-12259] (8164 slots) master 1 additional replica(s)M: 77cfc3429c8b470331520074faea7c3a21f77d1f 192.168.32.133:6379 slots:[12260-12287] (28 slots) master 1 additional replica(s)S: ba4bb2dc1f4550e8602f500f1e0021896e78bf54 192.168.32.129:6379 slots: (0 slots) slave replicates f49ca2e55dae53fa0a069ea9e1d35a31ee62731eM: f49ca2e55dae53fa0a069ea9e1d35a31ee62731e 192.168.32.140:6379 slots:[12288-16383] (4096 slots) master 1 additional replica(s)M: 46b54e8298e11e77450e232c9a0ee057b362191a 192.168.32.137:6379 slots:[6827-10922] (4096 slots) master 1 additional replica(s)S: f720a02fee9c4826d08258b740de008040cf80c5 192.168.32.136:6379 slots: (0 slots) slave replicates 658dd91e4b51bf06b161e6903d4084c77abd195dS: a44914056fd3a170850ad572c0e238b499455897 192.168.32.139:6379 slots: (0 slots) slave replicates 77cfc3429c8b470331520074faea7c3a21f77d1fS: eec71072ab8ad4068b4604f7196d881f9b5363e0 192.168.32.138:6379 slots: (0 slots) slave replicates 46b54e8298e11e77450e232c9a0ee057b362191a[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.[root@centos8 ~]# # 删除192.168.32.133节点[root@centos8 ~]# redis-cli -a 123456 --cluster del-node 192.168.32.132:6379 77cfc3429c8b470331520074faea7c3a21f77d1fWarning: Using a password with &#x27;-a&#x27; or &#x27;-u&#x27; option on the command line interface may not be safe.&gt;&gt;&gt; Removing node 77cfc3429c8b470331520074faea7c3a21f77d1f from cluster 192.168.32.132:6379&gt;&gt;&gt; Sending CLUSTER FORGET messages to the cluster...&gt;&gt;&gt; Sending CLUSTER RESET SOFT to the deleted node.[root@centos8 ~]# 常见面试题 Redis 做什么的,即在哪些场景下使用 如果监控 Redis 是否出现故障 Redis客户端timeout报错突然增加，排查思路是怎样的？ 请简单描述pipeline功能，为什么pipeline功能会提升redis性能? 本地redis-client访问远程Redis服务出错，说出几种常见的错误? key-value的大小超大或单key的qps超高，会对Redis本身造成什么样的影响、会对访问Redis的其他客户端造成什么样的影响？ Zabbix 监控 Redis 哪些监控项 RDB和AOF持久化区别 docker拉取一个Redis如何实现数据持久化保存 Redis 支持哪些数据类型 Redis 如何实现消息队列 描述下常见的redis集群架构有哪些，他们之间的优缺点对比 主从复制工作原理 Redis 如何实现高可用 哨兵工作原理 Redis 集群的工作原理 Redis 集群如果避免脑裂 Redis 集群最少几个节点为什么? Redis的集群槽位多少个 Redis集群中某个节点缺少一个槽位是否能使用 Redis数据写入的时候是怎么在各个节点槽位分配数据的 Redis的数据存储是以什么样的方式存储 Redis集群的各槽位和总槽位之间什么关系","categories":[{"name":"Redis基础","slug":"Redis基础","permalink":"http://snippet.itshare.work/categories/Redis%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Redis基础","slug":"Redis基础","permalink":"http://snippet.itshare.work/categories/Redis%E5%9F%BA%E7%A1%80/"}]},{"title":"Redis部署和基础使用","slug":"Redis部署和基础使用","date":"2022-12-07T13:16:33.000Z","updated":"2022-12-16T15:10:11.756Z","comments":true,"path":"2022/12/07/Redis部署和基础使用/","link":"","permalink":"http://snippet.itshare.work/2022/12/07/Redis%E9%83%A8%E7%BD%B2%E5%92%8C%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","excerpt":"Redis (Remote Dictionary Server远程字典服务)是一个遵循BSD MIT开源协议的高性能的NoSQL","text":"Redis基础简介Redis (Remote Dictionary Server远程字典服务)是一个遵循BSD MIT开源协议的高性能的NoSQL.Redis基于ANSI C语言语言)编写的key-value数据库,是意大利的Salvatore Sanfilippo在2009年发布，从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal公司赞助。目前国内外使用的公司众多,比如:阿里,腾讯,百度,京东,新浪微博,GitHub,Twitter 等Redis的出现，很大程度补偿了memcached这类key&#x2F;value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Java，C&#x2F;C++，Go, C#，PHP，JavaScript，Perl，Object-C，Python，Ruby，Erlang等客户端DB-Engine月度排行榜Redis在键值型存储类的数据库长期居于首位,远远高于第二位的memcached 特性 速度快: 10W QPS,基于内存,C语言实现 单线程 持久化 支持多种数据结构 支持多种编程语言 功能丰富: 支持Lua脚本,发布订阅,事务,pipeline等功能 简单: 代码短小精悍(单机核心代码只有23000行左右),单线程开发容易,不依赖外部库,使用简单 主从复制 支持高可用和分布式 单线程Redis 6.0版本前一直是单线程方式处理用户的请求 单线程为何如此快? 纯内存 非阻塞避免线程切换和竞态消耗 注意事项 一次只运行一条命令 避免执行长(慢)命令:keys *, flushall, flushdb, slow lua script, mutil&#x2F;exec, operate bigvalue(collection) 其实不是单线程: 早期版本是单进程单线程,3.0 版本后实际还有其它的线程, 实现特定功能,如: fysnc file descriptor,close file descriptor 常见应用场景 缓存：缓存RDBMS中数据,比如网站的查询结果、商品信息、微博、新闻、消息 Session 共享：实现Web集群中的多服务器间的session共享 计数器：商品访问排行榜、浏览数、粉丝数、关注、点赞、评论等和次数相关的数值统计场景 社交：朋友圈、共同好友、可能认识他们等 地理位置: 基于地理信息系统GIS（Geographic Information System)实现摇一摇、附近的人、外卖等功能 消息队列：ELK等日志系统缓存、业务的订阅&#x2F;发布系统 缓存的实现流程数据更新操作流程： 数据读操作流程： Redis安装及连接官网下载地址 1http://download.redis.io/releases/ yum安装查看yum库redis版本 1yum info redis 或者 yum info redis yum 安装 redis 12345678910111213141516171819202122yum install -y redis# 启动systemctl enable --now redis# 连接[root@centos8-backup www]# redis-cli127.0.0.1:6379&gt; # 查看信息127.0.0.1:6379&gt; info# Serverredis_version:5.0.3redis_git_sha1:00000000redis_git_dirty:0redis_build_id:9529b692c0384fb7redis_mode:standaloneos:Linux 4.18.0-348.7.1.el8_5.x86_64 x86_64arch_bits:64multiplexing_api:epoll.................. 编译安装 Redis源码包下载地址 1http://download.redis.io/releases/ 下载源码包 12[root@centos7-master ~]# wget http://download.redis.io/releases/redis-6.2.6.tar.gz[root@centos7-master ~]# tar xf redis-6.2.6.tar.gz 安装依赖 1234# centos[root@centos7-master ~]# yum -y install gcc jemalloc-devel systemd-devel# ubuntuapt -y install make gcc libjemalloc-dev libsystemd-dev 编译安装 1234567891011121314[root@centos7-master ~]# cd redis-6.2.6#如果支持systemd,需要执行下面[root@centos7-master redis-6.2.6]# make -j 2 USE_SYSTEMD=yes PREFIX=/usr/local/src/redis install# 配置环境变量[root@centos7-master ~]# echo &#x27;PATH=/usr/local/src/redis/bin:$PATH&#x27; &gt; /etc/profile.d/redis.sh[root@centos7-master ~]# [root@centos7-master ~]# . /etc/profile.d/redis.sh[root@centos7-master ~]# #准备相关目录和配置文件#创建配置文件、日志、数据等目录[root@centos7-master redis]# mkdir /usr/local/src/redis/&#123;etc,log,data,run&#125;[root@centos7-master redis-6.2.6]# cp redis.conf /usr/local/src/redis/etc/ 修改配置文件 logfile “&#x2F;usr&#x2F;local&#x2F;src&#x2F;redis&#x2F;log&#x2F;redis_6379.log” 1234567891011# Specify the log file name. Also the empty string can be used to force# Redis to log on the standard output. Note that if you use standard# output for logging but daemonize, logs will be sent to /dev/nulllogfile &quot;/usr/local/src/redis/log/redis_6379.log&quot;# To enable logging to the system logger, just set &#x27;syslog-enabled&#x27; to yes,# and optionally update the other syslog parameters to suit your needs.# syslog-enabled no# Specify the syslog identity.# syslog-ident redis pidfile &#x2F;usr&#x2F;local&#x2F;src&#x2F;redis&#x2F;run&#x2F;redis_6379.pid 123456789101112# Note that on modern Linux systems &quot;/run/redis.pid&quot; is more conforming# and should be used instead.#pidfile /var/run/redis_6379.pidpidfile /usr/local/src/redis/run/redis_6379.pid# Specify the server verbosity level.# This can be one of:# debug (a lot of information, useful for development/testing)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel notice dir “&#x2F;usr&#x2F;local&#x2F;src&#x2F;redis&#x2F;data&#x2F;6379” 1234567# Note that you must specify a directory here, not a file name.dir &quot;/usr/local/src/redis/data/6379&quot;################################# REPLICATION ################################## Master-Replica replication. Use replicaof to make a Redis instance a copy of# another Redis server. A few things to understand ASAP about Redis replication. dbfilename ‘dump.rdb’ 1234# sanitize-dump-payload no# The filename where to dump the DBdbfilename &#x27;dump.rdb&#x27; 前台启动redis 1234567891011121314151617181920212223242526272829[root@centos7-master ~]# redis-server /usr/local/src/redis/etc/redis.conf 51487:C 07 Dec 2022 22:27:26.620 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo51487:C 07 Dec 2022 22:27:26.620 # Redis version=6.2.6, bits=64, commit=00000000, modified=0, pid=51487, just started51487:C 07 Dec 2022 22:27:26.620 # Configuration loaded51487:M 07 Dec 2022 22:27:26.620 * Increased maximum number of open files to 10032 (it was originally set to 1024).51487:M 07 Dec 2022 22:27:26.620 * monotonic clock: POSIX clock_gettime _._ _.-``__ &#x27;&#x27;-._ _.-`` `. `_. &#x27;&#x27;-._ Redis 6.2.6 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ &#x27;&#x27;-._ ( &#x27; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;| Port: 6379 | `-._ `._ / _.-&#x27; | PID: 51487 `-._ `-._ `-./ _.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | https://redis.io `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; `-._ `-.__.-&#x27; _.-&#x27; `-._ _.-&#x27; `-.__.-&#x27; 51487:M 07 Dec 2022 22:27:26.621 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.51487:M 07 Dec 2022 22:27:26.621 # Server initialized51487:M 07 Dec 2022 22:27:26.621 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add &#x27;vm.overcommit_memory = 1&#x27; to /etc/sysctl.conf and then reboot or run the command &#x27;sysctl vm.overcommit_memory=1&#x27; for this to take effect.51487:M 07 Dec 2022 22:27:26.621 * Ready to accept connections 帮助 123456789101112131415161718[root@centos7-master ~]# redis-server -hUsage: ./redis-server [/path/to/redis.conf] [options] [-] ./redis-server - (read config from stdin) ./redis-server -v or --version ./redis-server -h or --help ./redis-server --test-memory &lt;megabytes&gt;Examples: ./redis-server (run the server with default conf) ./redis-server /etc/redis/6379.conf ./redis-server --port 7777 ./redis-server --port 7777 --replicaof 127.0.0.1 8888 ./redis-server /etc/myredis.conf --loglevel verbose - ./redis-server /etc/myredis.conf --loglevel verboseSentinel mode: ./redis-server /etc/sentinel.conf --sentinel[root@centos7-master ~]# 消除启动时的三个Warning提示信息(可选) Tcp backlog 12WARNING: The TCP backlog setting of 511 cannot be enforced because/proc/sys/net/core/somaxconn is set to the lower value of 128. Tcp backlog 是指TCP的第三次握手服务器端收到客户端 ack确认号之后到服务器用Accept函数处理请求前的队列长度，即全连接队列 123#vim /etc/sysctl.confnet.core.somaxconn = 511#sysctl -p overcommit_memory 1234WARNING overcommit_memory is set to 0! Background save may fail under low memorycondition. To fix this issue add &#x27;vm.overcommit_memory = 1&#x27; to /etc/sysctl.confand then reboot or run the command &#x27;sysctl vm.overcommit_memory=1&#x27; for this totake effect. 内核参数说明 12345内核参数overcommit_memory 实现内存分配策略,可选值有三个：0、1、20 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则内存申请失败，并把错误返回给应用进程1 表示内核允许分配所有的物理内存，而不管当前的内存状态如何2 表示内核允许分配超过所有物理内存和交换空间总和的内存 123#vim /etc/sysctl.confvm.overcommit_memory = 1#sysctl -p transparent hugepage 123456789WARNING you have Transparent Huge Pages (THP) support enabled in your kernel.This will create latency and memory usage issues with Redis. To fix this issuerun the command &#x27;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&#x27; asroot, and add it to your /etc/rc.local in order to retain the setting after areboot. Redis must be restarted after THP is disabled.警告：您在内核中启用了透明大页面（THP,不同于一般4k内存页,而为2M）支持。 这将在Redis中造成延迟和内存使用问题。 要解决此问题，请以root 用户身份运行命令“echo never&gt;/sys/kernel/mm/transparent_hugepage/enabled”，并将其添加到您的/etc/rc.local中，以便在重启后保留设置。禁用THP后，必须重新启动Redis。 注意：ubuntu20.04, Rocky8&#x2F;CentOS8 默认为 never，所以此值无需优化 验证是否消除warning 12345678910111213141516171819202122232425262728293031[root@centos7-master ~]# redis-server /usr/local/src/redis/etc/redis.conf 51540:C 07 Dec 2022 22:38:45.196 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo51540:C 07 Dec 2022 22:38:45.196 # Redis version=6.2.6, bits=64, commit=00000000, modified=0, pid=51540, just started51540:C 07 Dec 2022 22:38:45.196 # Configuration loaded51540:M 07 Dec 2022 22:38:45.197 * Increased maximum number of open files to 10032 (it was originally set to 1024).51540:M 07 Dec 2022 22:38:45.197 * monotonic clock: POSIX clock_gettime _._ _.-``__ &#x27;&#x27;-._ _.-`` `. `_. &#x27;&#x27;-._ Redis 6.2.6 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ &#x27;&#x27;-._ ( &#x27; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;| Port: 6379 | `-._ `._ / _.-&#x27; | PID: 51540 `-._ `-._ `-./ _.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | https://redis.io `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; `-._ `-.__.-&#x27; _.-&#x27; `-._ _.-&#x27; `-.__.-&#x27; 51540:M 07 Dec 2022 22:38:45.197 # Server initialized51540:M 07 Dec 2022 22:38:45.198 * Loading RDB produced by version 6.2.651540:M 07 Dec 2022 22:38:45.198 * RDB age 2 seconds51540:M 07 Dec 2022 22:38:45.198 * RDB memory usage when created 0.77 Mb51540:M 07 Dec 2022 22:38:45.198 # Done loading RDB, keys loaded: 0, keys expired: 0.51540:M 07 Dec 2022 22:38:45.198 * DB loaded from disk: 0.000 seconds51540:M 07 Dec 2022 22:38:45.198 * Ready to accept connections 创建 Redis 用户和设置数据目录权限 123[root@centos7-master ~]# useradd -r -s /sbin/nologin redis[root@centos7-master ~]# chown -R redis.redis /usr/local/src/redis/[root@centos7-master ~]# 创建 Redis 服务 Service 文件 12345678910111213141516[root@centos7-master ~]# vim /lib/systemd/system/redis.service[Unit]Description=Redis persistent key-value databaseAfter=network.target[Service]ExecStart=/usr/local/src/redis/bin/redis-server /usr/local/src/redis/etc/redis.conf --supervised systemdExecStop=/bin/kill -s QUIT $MAINPIDType=notify User=redisGroup=redisRuntimeDirectory=redisRuntimeDirectoryMode=0755LimitNOFILE=1000000 [Install]WantedBy=multi-user.target Redis 通过Service方式启动 123systemctl daemon-reloadsystemctl restart redissystemctl status redis Redis多实例基于源码编译安装的前提下实现redis的多实例 123456789101112131415161718192021222324252627282930313233343536373839# 进入/usr/local/src/redis/etc[root@centos7-master ~]# cd /usr/local/src/redis/etc/[root@centos7-master etc]# # 修改配置文件，使用6380,6381端口启动实例[root@centos7-master etc]# sed &#x27;s/6379/6380/&#x27; redis.conf &gt; redis6380.conf[root@centos7-master etc]# sed &#x27;s/6379/6380/&#x27; redis.conf &gt; redis6381.conf# 修改所属组[root@centos7-master etc]# chown -R redis.redis *# 修改启动文件[root@centos7-master etc]# cp /lib/systemd/system/redis.service /lib/systemd/system/redis6380.service [root@centos7-master etc]# [root@centos7-master etc]# vim /lib/systemd/system/redis6380.service [Unit]Description=Redis persistent key-value databaseAfter=network.target[Service]ExecStart=/usr/local/src/redis/bin/redis-server /usr/local/src/redis/etc/redis6380.conf --supervised systemdExecStop=/bin/kill -s QUIT $MAINPIDType=notifyUser=redisGroup=redisRuntimeDirectory=redisRuntimeDirectoryMode=0755LimitNOFILE=1000000[Install]WantedBy=multi-user.target# 使用相同方法创建/lib/systemd/system/redis6381.service文件并修改内容# 启动实例[root@centos7-master etc]# systemctl status redis.service[root@centos7-master etc]# systemctl status redis6380.service[root@centos7-master etc]# systemctl status redis6381.service# 查看6379 6380 6381 端口是否启用 连接测试 123[root@centos7-master etc]# redis-cli -p 6379[root@centos7-master etc]# redis-cli -p 6380[root@centos7-master etc]# redis-cli -p 6381 Redis 配置管理配置文件说明123456789101112131415161718bind 0.0.0.0 #指定监听地址，支持用空格隔开的多个监听IPprotected-mode yes #redis3.2之后加入的新特性，在没有设置bind IP和密码的时候,redis只允许访问127.0.0.1:6379，可以远程连接，但当访问将提示警告信息并拒绝远程访问port 6379 #监听端口,默认6379/tcptcp-backlog 511 #三次握手的时候server端收到client ack确认号之后的队列值，即全连接队列长度timeout 0 #客户端和Redis服务端的连接超时时间，默认是0，表示永不超时tcp-keepalive 300 #tcp 会话保持时间300sdaemonize no #默认no,即直接运行redis-server程序时,不作为守护进程运行，而是以前台方式运行，如果想在后台运行需改成yes,当redis作为守护进程运行的时候，它会写一个 pid 到/var/run/redis.pid 文件supervised no #和OS相关参数，可设置通过upstart和systemd管理Redis守护进程，centos7后都使用systemdpidfile /var/run/redis_6379.pid #pid文件路径,可以修改为/apps/redis/run/redis_6379.pidloglevel notice #日志级别logfile &quot;/path/redis.log&quot; #日志路径,示例:logfile &quot;/apps/redis/log/redis_6379.log&quot;databases 16 #设置数据库数量，默认：0-15，共16个库always-show-logo yes #在启动redis 时是否显示或在日志中记录记录redis的logo 1234567891011121314151617181920212223242526272829303132333435363738394041424344save 900 1 #在900秒内有1个key内容发生更改,就执行快照机制save 300 10 #在300秒内有10个key内容发生更改,就执行快照机制save 60 10000 #60秒内如果有10000个key以上的变化，就自动快照备份stop-writes-on-bgsave-error yes #默认为yes时,可能会因空间满等原因快照无法保存出错时，会禁止redis写入操作，生产建议为no#此项只针对配置文件中的自动save有效rdbcompression yes #持久化到RDB文件时，是否压缩，&quot;yes&quot;为压缩，&quot;no&quot;则反之rdbchecksum yes #是否对备份文件开启RC64校验，默认是开启dbfilename dump.rdb #快照文件名dir ./ #快照文件保存路径，示例：dir &quot;/apps/redis/data&quot;#主从复制相关# replicaof &lt;masterip&gt; &lt;masterport&gt; #指定复制的master主机地址和端口，5.0版之前的指令为slaveof# masterauth &lt;master-password&gt; #指定复制的master主机的密码replica-serve-stale-data yes #当从库同主库失去连接或者复制正在进行，从机库有两种运行方式：1、设置为yes(默认设置)，从库会继续响应客户端的读请求，此为建议值2、设置为no，除去特定命令外的任何请求都会返回一个错误&quot;SYNC with master in progress&quot;。replica-read-only yes #是否设置从库只读，建议值为yes,否则主库同步从库时可能会覆盖数据，造成数据丢失repl-diskless-sync no #是否使用socket方式复制数据(无盘同步)，新slave第一次连接master时需要做数据的全量同步，redis server就要从内存dump出新的RDB文件，然后从master传到slave，有两种方式把RDB文件传输给客户端：1、基于硬盘（disk-backed）：为no时，master创建一个新进程dump生成RDB磁盘文件，RDB完成之后由父进程（即主进程）将RDB文件发送给slaves，此为默认值2、基于socket（diskless）：master创建一个新进程直接dump RDB至slave的网络socket，不经过主进程和硬盘#推荐使用基于硬盘（为no），是因为RDB文件创建后，可以同时传输给更多的slave，但是基于socket(为yes)， 新slave连接到master之后得逐个同步数据。只有当磁盘I/O较慢且网络较快时，可用diskless(yes),否则一般建议使用磁盘(no)repl-diskless-sync-delay 5 #diskless时复制的服务器等待的延迟时间，设置0为关闭，在延迟时间内到达的客户端，会一起通过diskless方式同步数据，但是一旦复制开始，master节点不会再接收新slave的复制请求，直到下一次同步开始才再接收新请求。即无法为延迟时间后到达的新副本提供服务，新副本将排队等待下一次RDB传输，因此服务器会等待一段时间才能让更多副本到达。推荐值：30-60repl-ping-replica-period 10 #slave根据master指定的时间进行周期性的PING master,用于监测master状态,默认10srepl-timeout 60 #复制连接的超时时间，需要大于repl-ping-slave-period，否则会经常报超时repl-disable-tcp-nodelay no #是否在slave套接字发送SYNC之后禁用 TCP_NODELAY，如果选择&quot;yes&quot;，Redis将合并多个报文为一个大的报文，从而使用更少数量的包向slaves发送数据，但是将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒，如果 &quot;no&quot; ，数据传输到slave的延迟将会减少，但要使用更多的带宽repl-backlog-size 512mb #复制缓冲区内存大小，当slave断开连接一段时间后，该缓冲区会累积复制副本数据，因此当slave 重新连接时，通常不需要完全重新同步，只需传递在副本中的断开连接后没有同步的部分数据即可。只有在至少有一个slave连接之后才分配此内存空间,建议建立主从时此值要调大一些或在低峰期配置,否则会导致同步到slave失败 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748repl-backlog-ttl 3600 #多长时间内master没有slave连接，就清空backlog缓冲区replica-priority 100 #当master不可用，哨兵Sentinel会根据slave的优先级选举一个master，此值最低的slave会优先当选master，而配置成0，永远不会被选举，一般多个slave都设为一样的值，让其自动选择#min-replicas-to-write 3 #至少有3个可连接的slave，mater才接受写操作#min-replicas-max-lag 10 #和上面至少3个slave的ping延迟不能超过10秒，否则master也将停止写操作requirepass foobared #设置redis连接密码，之后需要AUTH pass,如果有特殊符号，用&quot; &quot;引起来,生产建议设置rename-command #重命名一些高危命令，示例：rename-command FLUSHALL &quot;&quot; 禁用命令#示例: rename-command del magedumaxclients 10000 #Redis最大连接客户端maxmemory &lt;bytes&gt; #redis使用的最大内存，单位为bytes字节，0为不限制，建议设为物理内存一半，8G内存的计算方式8(G)*1024(MB)1024(KB)*1024(Kbyte)，需要注意的是缓冲区是不计算在maxmemory内,生产中如果不设置此项,可能会导致OOM#maxmemory-policy noeviction 此为默认值# MAXMEMORY POLICY：当达到最大内存时，Redis 将如何选择要删除的内容。您可以从以下行为中选择一种：## volatile-lru -&gt; Evict 使用近似 LRU，只有设置了过期时间的键。# allkeys-lru -&gt; 使用近似 LRU 驱逐任何键。# volatile-lfu -&gt; 使用近似 LFU 驱逐，只有设置了过期时间的键。# allkeys-lfu -&gt; 使用近似 LFU 驱逐任何键。# volatile-random -&gt; 删除设置了过期时间的随机密钥。# allkeys-random -&gt; 删除一个随机密钥，任何密钥。# volatile-ttl -&gt; 删除过期时间最近的key（次TTL）# noeviction -&gt; 不要驱逐任何东西，只是在写操作时返回一个错误。## LRU 表示最近最少使用# LFU 表示最不常用## LRU、LFU 和 volatile-ttl 都是使用近似随机算法实现的。## 注意：使用上述任何一种策略，当没有合适的键用于驱逐时，Redis 将在需要更多内存的写操作时返回错误。这些通常是创建新密钥、添加数据或修改现有密钥的命令。一些示例是：SET、INCR、HSET、LPUSH、SUNIONSTORE、SORT（由于 STORE 参数）和 EXEC（如果事务包括任何需要内存的命令）。#MAXMEMORY POLICY：当达到最大内存时，Redis 将如何选择要删除的内容。可以从下面行为中进行选择：# volatile-lru -&gt; 在具有过期集的键中使用近似 LRU 驱逐。# allkeys-lru -&gt; 使用近似 LRU 驱逐任何键。# volatile-lfu -&gt; 在具有过期集的键中使用近似 LFU 驱逐。# allkeys-lfu -&gt; 使用近似 LFU 驱逐任何键。# volatile-random -&gt; 从具有过期设置的密钥中删除一个随机密钥。# allkeys-random -&gt; 删除一个随机密钥，任何密钥。# volatile-ttl -&gt; 删除过期时间最近的key（次TTL）# noeviction -&gt; 不要驱逐任何东西，只是在写操作时返回一个错误。## LRU 表示最近最少使用 123456789101112131415161718192021222324252627282930313233343536373839404142# LFU 表示最不常用## LRU、LFU 和 volatile-ttl 均使用近似实现随机算法。## 注意：使用上述任何一种策略，Redis 都会在写入时返回错误操作，当没有合适的键用于驱逐时。appendonly no #是否开启AOF日志记录，默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了，但是redis如果中途宕机，会导致可能有几分钟的数据丢失(取决于dump数据的间隔时间)，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性，Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。默认不启用此功能appendfilename &quot;appendonly.aof&quot; #文本文件AOF的文件名，存放在dir指令指定的目录中appendfsync everysec #aof持久化策略的配置#no表示由操作系统保证数据同步到磁盘,Linux的默认fsync策略是30秒，最多会丢失30s的数据#always表示每次写入都执行fsync，以保证数据同步到磁盘,安全性高,性能较差#everysec表示每秒执行一次fsync，可能会导致丢失这1s数据,此为默认值,也生产建议值#同时在执行bgrewriteaof操作和主进程写aof文件的操作，两者都会操作磁盘，而bgrewriteaof往往会涉及大量磁盘操作，这样就会造成主进程在写aof文件的时候出现阻塞的情形,以下参数实现控制no-appendfsync-on-rewrite no #在aof rewrite期间,是否对aof新记录的append暂缓使用文件同步策略,主要考虑磁盘IO开支和请求阻塞时间。#默认为no,表示&quot;不暂缓&quot;,新的aof记录仍然会被立即同步到磁盘，是最安全的方式，不会丢失数据，但是要忍受阻塞的问题#为yes,相当于将appendfsync设置为no，这说明并没有执行磁盘操作，只是写入了缓冲区，因此这样并不会造成阻塞（因为没有竞争磁盘），但是如果这个时候redis挂掉，就会丢失数据。丢失多少数据呢？Linux的默认fsync策略是30秒，最多会丢失30s的数据,但由于yes性能较好而且会避免出现阻塞因此比较推荐#rewrite 即对aof文件进行整理,将空闲空间回收,从而可以减少恢复数据时间auto-aof-rewrite-percentage 100 #当Aof log增长超过指定百分比例时，重写AOF文件，设置为0表示不自动重写Aof日志，重写是为了使aof体积保持最小，但是还可以确保保存最完整的数据auto-aof-rewrite-min-size 64mb #触发aof rewrite的最小文件大小aof-load-truncated yes #是否加载由于某些原因导致的末尾异常的AOF文件(主进程被kill/断电等)，建议yesaof-use-rdb-preamble no #redis4.0新增RDB-AOF混合持久化格式，在开启了这个功能之后，AOF重写产生的文件将同时包含RDB格式的内容和AOF格式的内容，其中RDB格式的内容用于记录已有的数据，而AOF格式的内容则用于记录最近发生了变化的数据，这样Redis就可以同时兼有RDB持久化和AOF持久化的优点（既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据）,默认为no,即不启用此功能lua-time-limit 5000 #lua脚本的最大执行时间，单位为毫秒cluster-enabled yes #是否开启集群模式，默认不开启,即单机模式cluster-config-file nodes-6379.conf #由node节点自动生成的集群配置文件名称cluster-node-timeout 15000 #集群中node节点连接超时时间，单位ms,超过此时间，会踢出集群cluster-replica-validity-factor 10 #单位为次,在执行故障转移的时候可能有些节点和master断开一段时间导致数据比较旧，这些节点就不适用于选举为master，超过这个时间的就不会被进行故障转移,不能当选master，计算公式：(node-timeout * replica-validity-factor) + repl-ping-replica-period 12345678910111213141516cluster-migration-barrier 1 #集群迁移屏障，一个主节点至少拥有1个正常工作的从节点，即如果主节点的slave节点故障后会将多余的从节点分配到当前主节点成为其新的从节点。cluster-require-full-coverage yes #集群请求槽位全部覆盖，如果一个主库宕机且没有备库就会出现集群槽位不全，那么yes时redis集群槽位验证不全,就不再对外提供服务(对key赋值时,会出现CLUSTERDOWN The cluster is down的提示,cluster_state:fail,但ping 仍PONG)，而no则可以继续使用,但是会出现查询数据查不到的情况(因为有数据丢失)。生产建议为nocluster-replica-no-failover no #如果为yes,此选项阻止在主服务器发生故障时尝试对其主服务器进行故障转移。 但是，主服务器仍然可以执行手动强制故障转移，一般为no#Slow log 是 Redis 用来记录超过指定执行时间的日志系统，执行时间不包括与客户端交谈，发送回复等I/O操作，而是实际执行命令所需的时间（在该阶段线程被阻塞并且不能同时为其它请求提供服务）,由于slow log 保存在内存里面，读写速度非常快，因此可放心地使用，不必担心因为开启 slow log 而影响Redis 的速度slowlog-log-slower-than 10000 #以微秒为单位的慢日志记录，为负数会禁用慢日志，为0会记录每个命令操作。默认值为10ms,一般一条命令执行都在微秒级,生产建议设为1ms-10ms之间slowlog-max-len 128 #最多记录多少条慢日志的保存队列长度，达到此长度后，记录新命令会将最旧的命令从命令队列中删除，以此滚动删除,即,先进先出,队列固定长度,默认128,值偏小,生产建议设为1000以上 Redis的配置文件介绍 config 命令实现动态修改配置config 命令用于查看当前redis配置、以及不重启redis服务实现动态更改redis配置等注意：不是所有配置都可以动态修改,且此方式无法持久保存 1234567891011121314CONFIG SET parameter value时间复杂度：O(1)CONFIG SET 命令可以动态地调整 Redis 服务器的配置(configuration)而无须重启。可以使用它修改配置参数，或者改变 Redis 的持久化(Persistence)方式。CONFIG SET 可以修改的配置参数可以使用命令 CONFIG GET * 来列出，所有被 CONFIG SET 修改的配置参数都会立即生效。CONFIG GET parameter时间复杂度： O(N)，其中 N 为命令返回的配置选项数量。CONFIG GET 命令用于取得运行中的 Redis 服务器的配置参数(configuration parameters)，在Redis 2.4 版本中， 有部分参数没有办法用 CONFIG GET 访问，但是在最新的 Redis 2.6 版本中，所有配置参数都已经可以用 CONFIG GET 访问了。CONFIG GET 接受单个参数 parameter 作为搜索关键字，查找所有匹配的配置参数，其中参数和值以“键-值对”(key-value pairs)的方式排列。比如执行 CONFIG GET s* 命令，服务器就会返回所有以 s 开头的配置参数及参数的值： 设置客户端连接密码1234567#设置连接密码127.0.0.1:6379&gt; CONFIG SET requirepass 123456OK#查看连接密码127.0.0.1:6379&gt; CONFIG GET requirepass1) &quot;requirepass&quot;2) &quot;123456&quot; 获取当前配置123456789101112131415161718192021222324252627282930#奇数行为键，偶数行为值127.0.0.1:6379&gt; CONFIG GET *1) &quot;dbfilename&quot;2) &quot;dump.rdb&quot;3) &quot;requirepass&quot;4) &quot;&quot;5) &quot;masterauth&quot;6) &quot;&quot;7) &quot;cluster-announce-ip&quot;8) &quot;&quot;9) &quot;unixsocket&quot;10) &quot;&quot;11) &quot;logfile&quot;12) &quot;/var/log/redis/redis.log&quot;13) &quot;pidfile&quot;14) &quot;/var/run/redis_6379.pid&quot;15) &quot;slave-announce-ip&quot;16) &quot;&quot;17) &quot;replica-announce-ip&quot;18) &quot;&quot;19) &quot;maxmemory&quot;20) &quot;0&quot;......#查看bind127.0.0.1:6379&gt; CONFIG GET bind1) &quot;bind&quot;2) &quot;0.0.0.0&quot;#Redis5.0有些设置无法修改,Redis6.2.6版本支持修改bind127.0.0.1:6379&gt; CONFIG SET bind 127.0.0.1(error) ERR Unsupported CONFIG parameter: bind 设置Redis使用的最大内存量12345127.0.0.1:6379&gt; CONFIG SET maxmemory 8589934592OK127.0.0.1:6379&gt; CONFIG GET maxmemory1) &quot;maxmemory&quot;2) &quot;8589934592&quot; 慢查询范例：SLOW LOG 1234567891011121314151617181920212223242526272829303132333435vim /etc/redis.confslowlog-log-slower-than 1 #指定超过1us即为慢的指令，默认值为10000usslowlog-max-len 1024 #指定只保存最近的1024条慢记录，默认值为128127.0.0.1:6379&gt; SLOWLOG LEN #查看慢日志的记录条数(integer) 14127.0.0.1:6379&gt; SLOWLOG GET [n] #查看慢日志的n条记录1) 1) (integer) 142) (integer) 15446906173) (integer) 4 #第3)行表示每条指令的执行时长4) 1) &quot;slowlog&quot;127.0.0.1:6379&gt; SLOWLOG GET 31) 1) (integer) 72) (integer) 16029015453) (integer) 264) 1) &quot;SLOWLOG&quot;2) &quot;get&quot;5) &quot;127.0.0.1:38258&quot;6) &quot;&quot;2) 1) (integer) 62) (integer) 16029015403) (integer) 224) 1) &quot;SLOWLOG&quot;2) &quot;get&quot;3) &quot;2&quot;5) &quot;127.0.0.1:38258&quot;6) &quot;&quot;3) 1) (integer) 52) (integer) 16029014973) (integer) 224) 1) &quot;SLOWLOG&quot;2) &quot;GET&quot;5) &quot;127.0.0.1:38258&quot;6) &quot;&quot;127.0.0.1:6379&gt; SLOWLOG RESET #清空慢日志OK Redis持久化 RDBRDB 工作原理 配置 AOF","categories":[{"name":"Redis基础","slug":"Redis基础","permalink":"http://snippet.itshare.work/categories/Redis%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Redis基础","slug":"Redis基础","permalink":"http://snippet.itshare.work/categories/Redis%E5%9F%BA%E7%A1%80/"}]},{"title":"网络文件共享服务","slug":"网络文件共享服务","date":"2022-12-04T04:03:44.000Z","updated":"2022-12-16T14:57:05.620Z","comments":true,"path":"2022/12/04/网络文件共享服务/","link":"","permalink":"http://snippet.itshare.work/2022/12/04/%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/","excerpt":"Network File System 网络文件系统，基于内核的文件系统。Sun 公司开发，通过使用 NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件","text":"NFS服务NFS工作原理 NFS：Network File System 网络文件系统，基于内核的文件系统。Sun 公司开发，通过使用 NFS，用户和程序可以像访问本地文件一样访问远端系统上的文件，基于RPC（Remote Procedure CallProtocol 远程过程调用）实现。RPC采用C&#x2F;S模式，客户机请求程序调用进程发送一个有进程参数的调用信息到服务进程，然后等待应答信息。在服务器端，进程保持睡眠状态直到调用信息到达为止。当一个调用信息到达，服务器获得进程参数，计算结果，发送答复信息，然后等待下一个调用信息，最后，客户端调用进程接收答复信息，获得进程结果，然后调用执行继续进行。 NFS优势：节省本地存储空间，将常用的数据,如：&#x2F;home目录，存放在NFS服务器上且可以通过网络访问，本地终端将可减少自身存储空间的使用。 NFS软件介绍软件包：nfs-utils（包括服务器和客户端相关工具，CentOS8 最小化安装时默认没有安装），nfs-common(Ubuntu中包名)相关软件包：rpcbind（必须），tcp_wrappersKernel支持：nfs.ko端口：2049(nfsd), 其它端口由portmap(111)分配NFS服务主要进程： rpc.nfsd 最主要的NFS进程，管理客户端是否可登录 rpc.mountd 挂载和卸载NFS文件系统，包括权限管理 rpc.lockd 非必要，管理文件锁，避免同时写出错 rpc.statd 非必要，检查文件一致性，可修复文件 说明：CentOS 6 开始portmap进程由rpcbind代替日志：&#x2F;var&#x2F;lib&#x2F;nfs&#x2F;NFS配置文件 12/etc/exports/etc/exports.d/*.exports 常用选项 1234567891011默认选项：(ro,sync,root_squash,no_all_squash)ro,rw 只读和读写async 异步，数据变化后不立即写磁盘，先写入到缓冲区中，过一段时间再写入磁盘，性能高,安全性低sync（1.0.0后为默认）同步，数据在请求时立即写入共享存储磁盘,性能低,安全性高root_squash （默认）远程root映射为nfsnobody,UID为65534，CentOS8 为nobody,CentOS7以前的版本为nfsnobodyno_root_squash 远程root映射成NFS服务器的root用户all_squash 所有远程用户(包括root)都变成nfsnobody,CentOS8 为nobodyno_all_squash （默认）保留共享文件的UID和GIDanonuid和anongid 指明匿名用户映射为特定用户UID和组GID，而非nobody,可配合all_squash使用 NFS工具rpcinforpcinfo 工具可以查看RPC相关信息查看注册在指定主机的RPC程序 1rpcinfo -p hostname 查看RPC注册程序 1rpcinfo -s hostname exportfsexportfs:可用于管理NFS导出的文件系统常见选项 1234-v #查看本机所有NFS共享-r #重读配置文件，并共享目录-a #输出本机所有共享-au #停止本机所有共享 showmount常见用法： 12#查看远程主机的NFS共享showmount -e hostname mount.nfs客户端NFS挂载NFS相关的挂载选项：man 5 nfs 12345678fg #（默认）前台挂载bg #后台挂载hard #（默认）持续请求soft #非持续请求intr #和hard配合，请求可中断rsize #和wsize 一次读和写数据最大字节数，rsize=32768_netdev #无网络服务时不挂载NFS资源vers #指定版本，客户端centos8默认4.2 ，centos7默认4.1 centos6默认4.0 提示：基于安全考虑，建议使用 nosuid,netdev,noexec 挂载选项 实战案例 NFS服务器安装软件 1234567yum install -y nfs-utils# 启动rpcbindsystemctl start rpcbind# 启动nfs-serversystemctl start nfs-server NFS服务器创建共享文件 12# 共享根目录下的share目录mkdir /share 添加uid和gid为300的用户nfs-upload 12345[root@centos7-master ~]# groupadd -g 300 nfs-upload[root@centos7-master ~]# useradd -u 300 -g 300 nfs-upload[root@centos7-master ~]# #修改所属组权限[root@centos7-master share]# chown -R 300:300 /share 修改NFS服务器配置文件 123[root@centos7-master ~]# vim /etc/exports# 加入如下内容，*表示任何人，rw表示读写/share/ 192.168.179.*(rw,anongid=300,anonuid=300) 重新加载配置 12345# 重新加载配置文件[root@centos7-master ~]# exportfs -r[root@centos7-master ~]# exportfs -v/share 192.168.179.*(sync,wdelay,hide,no_subtree_check,anonuid=300,anongid=300,sec=sys,rw,secure,root_squash,no_all_squash)[root@centos7-master ~]# 客户端安装软件 1234567yum install -y nfs-utils# 启动rpcbindsystemctl start rpcbind# 启动nfs-serversystemctl start nfs-server 添加用户和组 12[root@centos7-slave /]# groupadd -g 300 nfs-upload[root@centos7-slave /]# useradd -u 300 -g 300 nfs-upload 在客户端挂载，挂载&#x2F;nfsshare目录下 123456789101112131415161718# 创建目录mkdir /nfsshare# 查看服务器端可挂载点[root@centos7-slave ~]# showmount -e 192.168.179.170Export list for 192.168.179.170:/share *[root@centos7-slave nfsshare]# # 挂载方式1，关机重启会失效[root@centos7-slave ~]# mount 192.168.179.170:/share/ /nfsshare# 方式二修改配置文件，关机重启不失效[root@centos7-slave ~]# vim /etc/fstab # 加入如下内容192.168.179.170:/share /nfsshare nfs defaults,_netdev 0 0# 使配置文件生效[root@centos7-slave nfsshare]# mount -a[root@centos7-slave nfsshare]# 测试 123456789101112131415# 在客户端上查看/nfsshare的内容[root@centos7-slave nfsshare]# lltotal 8-rw-r--r-- 1 nfs-upload nfs-upload 5 Dec 5 23:14 a.xtxdrwxr-xr-x 2 nfs-upload nfs-upload 6 Dec 5 23:17 newfile-rw-r--r-- 1 nfs-upload nfs-upload 17 Dec 5 23:11 test.log[root@centos7-slave nfsshare]# # 在服务器端查看/share目录[root@centos7-master share]# lltotal 8-rw-r--r-- 1 nfs-upload nfs-upload 5 Dec 5 23:14 a.xtxdrwxr-xr-x 2 nfs-upload nfs-upload 6 Dec 5 23:17 newfile-rw-r--r-- 1 nfs-upload nfs-upload 17 Dec 5 23:11 test.log[root@centos7-master share]# 数据的实时同步实时同步技术介绍实现实时同步的方法 inotify + rsync 方式实现数据同步 sersync ：前金山公司周洋（花椒直播）在 inotify 软件基础上进行开发的，功能更加强大 工作原理： 要利用监控服务（inotify），监控同步数据服务器目录中信息的变化 发现目录中数据产生变化，就利用rsync服务推送到备份服务器上 inotify：异步的文件系统事件监控机制，利用事件驱动机制，而无须通过诸如cron等的轮询机制来获取事件，linux内核从2.6.13起支持 inotify，通过inotify可以监控文件系统中添加、删除，修改、移动等各种事件 实现inotify软件： inotify-tools sersync lrsyncd inotify+rsync使用方式 inotify 对同步数据目录信息的监控 rsync 完成对数据的同步 利用脚本进行结合 实现 inotify内核是否支持inotifyLinux支持inotify的内核最小版本为 2.6.13，参看man 7 inotify inotify 内核参数说明： max_queued_events：inotify 事件队列最大长度，如值太小会出现 Event Queue Overflow 错误，默认值：16384, 生产环境建议调大,比如:327679 max_user_instances：每个用户创建inotify实例最大值，默认值：128 max_user_watches：可以监视的文件的总数量（inotifywait 单进程），默认值：8192,建议调大 inotify-tools工具inotify-tools参考文档：https://github.com/rvoicilas/inotify-tools/wiki安装inotify-tools：基于epel源 12yum install epel-releaseyum -y install inotify-tools inotify-tools包主要工具： inotifywait： 在被监控的文件或目录上等待特定文件系统事件（open ，close，delete等）发生，常用于实时同步的目录监控 inotifywatch：收集被监控的文件系统使用的统计数据，指文件系统事件发生的次数统计 inotifywait 命令格式: 1inotifywait [ options ] file1 [ file2 ] [ file3 ] [ ... ] 常用选项 1234567891011-m, --monitor 始终保持事件监听-d, --daemon 以守护进程方式执行，和-m相似，配合-o使用-r, --recursive 递归监控目录数据信息变化-q, --quiet 输出少量事件信息--exclude &lt;pattern&gt; 指定排除文件或目录，使用扩展的正则表达式匹配的模式实现--excludei &lt;pattern&gt; 和exclude相似，不区分大小写-o, --outfile &lt;file&gt; 打印事件到文件中，相当于标准正确输出，注意：使用绝对路径-s, --syslogOutput 发送错误到syslog相当于标准错误输出--timefmt &lt;fmt&gt; 指定时间输出格式--format &lt;fmt&gt; 指定的输出格式；即实际监控输出内容-e inotifywait 的–timefmt 时间格式参考 man 3 strftime 1234567%Y #年份信息，包含世纪信息%y #年份信息，不包括世纪信息%m #显示月份，范围 01-12%d #每月的第几天，范围是 01-31%H #小时信息，使用 24小时制，范围 00-23%M #分钟，范围 00-59%S #秒，范例 0-60 范例： 1--timefmt &quot;%Y-%m-%d %H:%M:%S&quot; inotifywait 的 –format 格式定义 12345%T #输出时间格式中定义的时间格式信息，通过 --timefmt option 语法格式指定时间信息%w #事件出现时，监控文件或目录的名称信息，相当于dirname%f #事件出现时，将显示监控目录下触发事件的文件或目录信息，否则为空，相当于basename%e #显示发生的事件信息，不同的事件默认用逗号分隔%Xe #显示发生的事件信息，不同的事件指定用X进行分隔 范例 12--format &quot;%T %w%f event: %;e&quot;--format &#x27;%T %w %f&#x27; inotifywait -e 选项指定的事件类型 123456789101112131415create #文件或目录创建delete #文件或目录被删除modify #文件或目录内容被写入attrib #文件或目录属性改变close_write #文件或目录关闭，在写入模式打开之后关闭的close_nowrite #文件或目录关闭，在只读模式打开之后关闭的close #文件或目录关闭，不管读或是写模式open #文件或目录被打开lsdir #浏览目录内容moved_to #文件或目录被移动到监控的目录中moved_from #文件或目录从监控的目录中被移动move #文件或目录不管移动到或是移出监控目录都触发事件access #文件或目录内容被读取delete_self #文件或目录被删除，目录本身被删除unmount #取消挂载 范例 1-e create,delete,moved_to,close_write,attrib 范例：使用inotifywait 123456789101112131415161718192021222324252627282930313233# 监控一次事件[root@centos7 /]# inotifywait /data/www/Setting up watches.Watches established./data/www/ CREATE,ISDIR html[root@centos7 /]# # 持续前台监控[root@centos7 /]# inotifywait -mrq /data/www --exclude=&quot;.*\\.swx|\\.swp&quot;/data/www/ OPEN,ISDIR /data/www/ CLOSE_NOWRITE,CLOSE,ISDIR /data/www/ CREATE mysql.log/data/www/ OPEN mysql.log/data/www/ ATTRIB mysql.log/data/www/ CLOSE_WRITE,CLOSE mysql.log/data/www/ OPEN,ISDIR /data/www/ CLOSE_NOWRITE,CLOSE,ISDIR /data/www/ MODIFY mysql.log/data/www/ OPEN mysql.log/data/www/ MODIFY mysql.log/data/www/ CLOSE_WRITE,CLOSE mysql.log/data/www/ OPEN,ISDIR /data/www/ CLOSE_NOWRITE,CLOSE,ISDIR /data/www/ OPEN mysql.log/data/www/ ACCESS mysql.log/data/www/ CLOSE_NOWRITE,CLOSE mysql.log#持续后台监控，并记录日志inotifywait -o /root/inotify.log -drq /data/www --timefmt &quot;%Y-%m-%d %H:%M:%S&quot; --format &quot;%T %w%f event: %e&quot;#持续前台监控特定事件inotifywait -mrq /data/www --timefmt &quot;%F %H:%M:%S&quot; --format &quot;%T %w%f event:%;e&quot; -e create,delete,moved_to,close_write,attrib rsync 服务rsync 常用于做为 linux系统下的数据镜像备份工具，实现远程同步，支持本地复制，或者与其他SSH、rsync主机同步数据，支持增量备份，配合任务计划，rsync能实现定时或间隔同步，配合inotify或sersync，可以实现触发式的实时数据同步官方网站: http://rsync.samba.org/ 软件包：rsync，rsync-daemon（CentOS 8）服务文件：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;rsyncd.service配置文件：&#x2F;etc&#x2F;rsyncd.conf端口：873&#x2F;tcp rsync命令rsync 格式 12345678910111213141516#Local:rsync [OPTION...] SRC... [DEST]#Access via remote shell:Pull:rsync [OPTION...] [USER@]HOST:SRC... [DEST]Push:rsync [OPTION...] SRC... [USER@]HOST:DEST#Access via rsync daemon:Pull:rsync [OPTION...] [USER@]HOST::SRC... [DEST]rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]Push:rsync [OPTION...] SRC... [USER@]HOST::DESTrsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DESTThe &#x27;:&#x27; usages connect via remote shell, while &#x27;::&#x27; &amp; &#x27;rsync://&#x27; usages connectto an rsync daemon, and require SRC or DEST to start with a module name. rsync有三种工作方式： 本地文件系统上实现同步。命令行语法格式为上述”Local”段的格式。 本地主机使用远程shell和远程主机通信。命令行语法格式为上述”Access via remote shell”段的格式。 本地主机通过网络套接字连接远程主机上的rsync daemon。命令行语法格式为上述”Access viarsync daemon”段的格式。前两者的本质是通过本地或远程shell，而第3种方式则是让远程主机上运行rsyncd服务，使其监听在一个端口上，等待客户端的连接。常见选项： 123456789101112131415161718192021222324252627282930313233343536373839404142-v：显示rsync过程中详细信息。可以使用&quot;-vvvv&quot;获取更详细信息。-P：显示文件传输的进度信息。(实际上&quot;-P&quot;=&quot;--partial --progress&quot;，其中的&quot;--progress&quot;才是显示进度信息的)。-n --dry-run ：仅测试传输，而不实际传输。常和&quot;-vvvv&quot;配合使用来查看rsync是如何工作的。-a --archive ：归档模式，表示递归传输并保持文件属性。等同于&quot;-rtopgDl&quot;。-r --recursive：递归到目录中去。-t --times：保持mtime属性。强烈建议任何时候都加上&quot;-t&quot;，否则目标文件mtime会设置为系统时间，导致下次更新：检查出mtime不同从而导致增量传输无效。-o --owner：保持owner属性(属主)。-g --group：保持group属性(属组)。-p --perms：保持perms属性(权限，不包括特殊权限)-D ：是&quot;--device --specials&quot;选项的组合，即也拷贝设备文件和特殊文件。-l --links：如果文件是软链接文件，则拷贝软链接本身而非软链接所指向的对象-z ：传输时进行压缩提高效率-R --relative：使用相对路径。意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端，包括它们的属性。用法见下文示例。--size-only ：默认算法是检查文件大小和mtime不同的文件，使用此选项将只检查文件大小。-u --update ：仅在源mtime比目标已存在文件的mtime新时才拷贝。注意，该选项是接收端判断的，不会影响删除行为。-d --dirs ：以不递归的方式拷贝目录本身。默认递归时，如果源为&quot;dir1/file1&quot;，则不会拷贝dir1目录，使用该选项将拷贝dir1但不拷贝file1。--max-size ：限制rsync传输的最大文件大小。可以使用单位后缀，还可以是一个小数值(例如：&quot;--max-size=1.5m&quot;)--min-size ：限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件。--exclude ：指定排除规则来排除不需要传输的文件。--delete ：以SRC为主，对DEST进行同步。多则删之，少则补之。注意&quot;--delete&quot;是在接收端执行的，所以它是在：exclude/include规则生效之后才执行的。-b --backup ：对目标上已存在的文件做一个备份，备份的文件名后默认使用&quot;~&quot;做后缀。--backup-dir：指定备份文件的保存路径。不指定时默认和待备份文件保存在同一目录下。-e ：指定所要使用的远程shell程序，默认为ssh。--port ：连接daemon时使用的端口号，默认为873端口。--password-file：daemon模式时的密码文件，可以从中读取密码实现非交互式。注意，这不是远程shell认证的密码，而是rsync模块认证的密码。-W --whole-file：rsync将不再使用增量传输，而是全量传输。在网络带宽高于磁盘带宽时，该选项比增量传输更高效。--existing ：要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。--ignore-existing：要求只更新目标端不存在的文件。和&quot;--existing&quot;结合使用有特殊功能，见下文示例。--remove-source-files：要求删除源端已经成功传输的文件 范例：两种格式访问 rsync daemon 服务 环境 12data-server:192.168.179.171(数据服务器)backup-server:192.168.179.165(备份服务器) 1234567891011121314151617181920212223242526#在备份服务器启动 rsync 进程[root@centos8-backup ~]#rsync --daemonFailed to parse config file: /etc/rsyncd.conf[root@centos8-backup ~]#touch /etc/rsyncd.conf[root@centos8-backup ~]#rsync --daemon[root@centos8-backup /]# cat /etc/rsyncd.conf [backup]path = /web/www/read only = no [root@centos8-backup /]# #指定目录给nobody权限，默认用户以nobody访问此目录[root@centos8-backup ~]#setfacl -m u:nobody:rwx /data/backup/#查看rsync服务器的模块名称[root@centos7-slave /]# rsync rsync://192.168.179.165backup [root@centos7-slave /]# [root@centos7-slave /]# rsync 192.168.179.165::backup#访问rsync服务器的共享目录#推[root@centos7-slave /]# rsync /xy.log 192.168.179.165::backup[root@centos7-slave /]# rsync /etc/shells rsync://root@192.168.179.165/backup[root@centos7-slave /]#rsync 192.168.179.165::backup/* /opt[root@centos7-slave /]#rsync rsync://192.168.179.165/backup/* /mnt 范例：以独立服务方式运行 rsync 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# 修改配置文件[root@centos8-backup etc]# cat rsyncd.conf#uid = root #提定以哪个用户来访问共享目录，将之指定为生成的文件所有者，默认为nobody#gid = root #默认为nobody,Ubuntu中为nogroup#port = 874 可指定非标准端口,默认873/tcp#use chroot = no#max connections = 0#ignore errors#exclude = lost+found/#log file = /var/log/rsyncd.log#pid file = /var/run/rsyncd.pid#lock file = /var/run/rsyncd.lock#reverse lookup = no#hosts allow = 10.0.0.0/24#[backup] #每个模块名对应一个不同的path目录，如果同名后面模块生效#path = /data/backup/#comment = backup dir#read only = no #默认是yes,即只读#auth users = rsyncuser #默认anonymous可以访问rsync服务器#secrets file = /etc/rsync.pas# /etc/rsyncd: configuration file for rsync daemon mode# See rsyncd.conf man page for more options.# configuration example:# uid = nobody# gid = nobody# use chroot = yes# max connections = 4# pid file = /var/run/rsyncd.pid# exclude = lost+found/# transfer logging = yes# timeout = 900# ignore nonreadable = yes# dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2# [ftp]# path = /home/ftp# comment = ftp export areauid = root gid = root max connections = 0ignore errorsexclude = lost+found/log file = /var/log/rsyncd.logpid file = /var/run/rsyncd.pidlock file = /var/run/rsyncd.lockreverse lookup = no[backup] path = /web/backup/ comment = backup dirread only = no auth users = rsyncuser secrets file = /etc/rsync.pas[root@centos8-backup etc]# #服务器端生成验证文件[root@centos8-backup ~]#echo &quot;rsyncuser:123456&quot; &gt; /etc/rsync.pas[root@centos8-backup ~]#chmod 600 /etc/rsync.pas#服务器端启动rsync服务[root@centos8-backup ~]#rsync --daemon #可加入/etc/rc.d/rc.local实现开机启动#客户端配置密码文件#也可将密码赋值给环境变量RSYNC_PASSWORD变量,但不安全#export RSYNC_PASSWORD=123456[root@centos7-slave ~]#echo &quot;123456&quot; &gt; /etc/rsync.pas[root@centos7-slave ~]#chmod 600 /etc/rsync.pas #此为必要项,权限必须修改#查看远程rsync服务器的模块信息[root@centos7-slave etc]# rsync rsync://192.168.179.165backup backup dir[root@centos7-slave etc]# #交互式验证查看具体模块内的文件[root@centos7-slave etc]# rsync rsync://rsyncuser@192.168.179.165/backupPassword: #非交互式查看共享目录[root@centos7-slave etc]# rsync --password-file=/etc/rsync.pas rsync://rsyncuser@192.168.179.165/backupdrwxrwxrwx 34 2022/12/07 16:20:07 .-rw-r--r-- 0 2022/12/07 16:20:07 xy.log-rw-r--r-- 0 2022/12/07 16:09:50 zz.log[root@centos7-slave etc]# #客户端测试同步数据[root@data-centos8 ~]#rsync -avz --delete --password-file=/etc/rsync.pas /data/www/ rsyncuser@rsync服务器IP::backup[root@data-centos8 ~]#rsync -avz --delete --password-file=/etc/rsync.pas rsyncuser@rsync服务器IP::backup /data/www/ inotify+rsync+shell 脚本实现实时数据同步 按 5.3 搭建好 rsyncd的备份服务器，在数据服务器上创建inotify_rsync.sh脚本注意: 此脚本执行前先确保两主机初始数据处于同步状态,此脚本实现后续的数据同步 12345678910111213141516[root@centos7-slave ~]# vim inotify_rsync.sh #!/bin/bashSRC=&#x27;/data/www/&#x27; #注意最后的/DEST=&#x27;rsyncuser@rsync服务器IP::backup&#x27;rpm -q inotify-tools &amp;&gt; /dev/null ||yum -y install inotify-toolsrpm -q rsync &amp;&gt; /dev/null || yum -y install rsyncinotifywait -mrq --exclude=&quot;.*\\.swp&quot; --timefmt &#x27;%Y-%m-%d %H:%M:%S&#x27; --format&#x27;%T %w %f&#x27; -e create,delete,moved_to,close_write,attrib $&#123;SRC&#125; |while read DATETIME DIR FILE;doFILEPATH=$&#123;DIR&#125;$&#123;FILE&#125;rsync -az --delete --password-file=/etc/rsync.pas $SRC $DEST &amp;&amp; echo&quot;At $&#123;TIME&#125; on $&#123;DATE&#125;, file $FILEPATH was backuped up via rsync&quot; &gt;&gt;/var/log/changelist.logdone#查看文件传输日志[root@centos7-slave www]# tail -f /var/log/changelist.log sersync 实现实时数据同步sersync 介绍sersync类似于inotify，同样用于监控，但它克服了inotify的缺点.inotify最大的不足是会产生重复事件，或者同一个目录下多个文件的操作会产生多个事件，例如，当监控目录中有5个文件时，删除目录时会产生6个监控事件，从而导致重复调用rsync命令。另外比如：vim文件时，inotify会监控到临时文件的事件，但这些事件相对于rsync来说是不应该被监控的 sersync 优点： sersync是使用c++编写，而且对linux系统文件系统产生的临时文件和重复的文件操作进行过滤，所以在结合rsync同步的时候，节省了运行时耗和网络资源。因此更快。 sersync配置很简单，其中提供了静态编译好的二进制文件和xml配置文件，直接使用即可 sersync使用多线程进行同步，尤其在同步较大文件时，能够保证多个服务器实时保持同步状态 sersync有出错处理机制，通过失败队列对出错的文件重新同步，如果仍旧失败，则按设定时长对同步失败的文件重新同步 sersync不仅可以实现实时同步，另外还自带crontab功能，只需在xml配置文件中开启，即也可以按要求隔一段时间整体同步一次，而无需再额外配置crontab功能 sersync 可以二次开发 sersync项目地址： https://code.google.com/archive/p/sersync/sersync下载地址： https://code.google.com/archive/p/sersync/downloads 基于rsync daemon 实现 sersync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123# #在数据服务器上下载sersync，并拷贝至相应的目录，设置PATH变量wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/sersync/sersync2.5.4_64bit_binary_stable_final.tar.gz[root@centos7-slave ~]# tar -vxf sersync2.5.4_64bit_binary_stable_final.tar.gz [root@centos7-slave ~]# cp -r GNU-Linux-x86/ /usr/local/sersync[root@centos7-slave sersync]# echo &#x27;PATH=/usr/local/sersync:$PATH&#x27; &gt; /etc/profile.d/sersync.sh[root@centos7-slave sersync]# source /etc/profile.d/sersync.sh[root@centos7-slave sersync]# #确认安装rsync客户端工具rpm -q rsync &amp;&gt; /dev/null || dnf -y install rsync#备份sersync配置文件cp /usr/local/sersync/confxml.xml&#123;,.bak&#125;# 修改配置文件vim /usr/local/sersync/confxml.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;ISO-8859-1&quot;?&gt;&lt;head version=&quot;2.5&quot;&gt;&lt;host hostip=&quot;localhost&quot; port=&quot;8008&quot;&gt;&lt;/host&gt;&lt;debug start=&quot;false&quot;/&gt; # 是否开启调试模式&lt;fileSystem xfs=&quot;false&quot;/&gt;&lt;filter start=&quot;false&quot;&gt; #不开启文件过滤功能，当为true时,以下类型的文件将不同步&lt;exclude expression=&quot;(.*)\\.svn&quot;&gt;&lt;/exclude&gt;&lt;exclude expression=&quot;(.*)\\.gz&quot;&gt;&lt;/exclude&gt;&lt;exclude expression=&quot;^info/*&quot;&gt;&lt;/exclude&gt;&lt;exclude expression=&quot;^static/*&quot;&gt;&lt;/exclude&gt;&lt;/filter&gt;&lt;inotify&gt; # 监控事件，默认监控delete/close_write/moved_from/moved_to/create folder&lt;delete start=&quot;true&quot;/&gt;&lt;createFolder start=&quot;true&quot;/&gt;&lt;createFile start=&quot;false&quot;/&gt;&lt;closeWrite start=&quot;true&quot;/&gt;&lt;moveFrom start=&quot;true&quot;/&gt;&lt;moveTo start=&quot;true&quot;/&gt;&lt;attrib start=&quot;true&quot;/&gt; #修改此行为true，文件属性变化后也会同步&lt;modify start=&quot;false&quot;/&gt;&lt;/inotify&gt;&lt;sersync&gt; # rsync命令的配置段&lt;localpath watch=&quot;/data/www&quot;&gt; #修改此行,需要同步的源目录或文件，建议同步目录&lt;remote ip=&quot;备份服务器IP&quot; name=&quot;backup&quot;/&gt; #修改此行,指定备份服务器地址和rsyncdaemon的模块名，如果下面开启了ssh start，此时name为远程shell方式运行时的目标目录&lt;!--&lt;remote ip=&quot;192.168.8.39&quot; name=&quot;tongbu&quot;/&gt;--&gt;&lt;!--&lt;remote ip=&quot;192.168.8.40&quot; name=&quot;tongbu&quot;/&gt;--&gt;&lt;/localpath&gt;&lt;rsync&gt;&lt;commonParams params=&quot;-artuz&quot;/&gt; # 指定rsync选项&lt;auth start=&quot;true&quot; users=&quot;rsyncuser&quot; passwordfile=&quot;/etc/rsync.pas&quot;/&gt; #修改此行为true,指定备份服务器的rsync配置的用户和密码文件&lt;userDefinedPort start=&quot;false&quot; port=&quot;874&quot;/&gt;&lt;!-- port=874 --&gt;#指定rsync的非标准端口号&lt;timeout start=&quot;false&quot; time=&quot;100&quot;/&gt;&lt;!-- timeout=100 --&gt;&lt;ssh start=&quot;false&quot;/&gt; #默认使用rsync daemon运行rsync命令,true为使用远程shell模式&lt;/rsync&gt;&lt;failLog path=&quot;/tmp/rsync_fail_log.sh&quot; timeToExecute=&quot;60&quot;/&gt;&lt;!--default every60mins execute once--&gt; #错误重传及日志文件路径&lt;crontab start=&quot;false&quot; schedule=&quot;600&quot;&gt;&lt;!--600mins--&gt; #不开启crontab功能&lt;crontabfilter start=&quot;false&quot;&gt; #不开启crontab定时传输的筛选功能&lt;exclude expression=&quot;*.php&quot;&gt;&lt;/exclude&gt;&lt;exclude expression=&quot;info/*&quot;&gt;&lt;/exclude&gt;&lt;/crontabfilter&gt;&lt;/crontab&gt;&lt;plugin start=&quot;false&quot; name=&quot;command&quot;/&gt;&lt;/sersync&gt;#####################################以下行不需要修改####################################&lt;plugin name=&quot;command&quot;&gt;&lt;param prefix=&quot;/bin/sh&quot; suffix=&quot;&quot; ignoreError=&quot;true&quot;/&gt; &lt;!--prefix/opt/tongbu/mmm.sh suffix--&gt;&lt;filter start=&quot;false&quot;&gt;&lt;include expression=&quot;(.*)\\.php&quot;/&gt;&lt;include expression=&quot;(.*)\\.sh&quot;/&gt;&lt;/filter&gt;&lt;/plugin&gt;&lt;plugin name=&quot;socket&quot;&gt;&lt;localpath watch=&quot;/opt/tongbu&quot;&gt;&lt;deshost ip=&quot;192.168.138.20&quot; port=&quot;8009&quot;/&gt;&lt;/localpath&gt;&lt;/plugin&gt;&lt;plugin name=&quot;refreshCDN&quot;&gt;&lt;localpath watch=&quot;/data0/htdocs/cms.xoyo.com/site/&quot;&gt;&lt;cdninfo domainname=&quot;ccms.chinacache.com&quot; port=&quot;80&quot; username=&quot;xxxx&quot;passwd=&quot;xxxx&quot;/&gt;&lt;sendurl base=&quot;http://pic.xoyo.com/cms&quot;/&gt; &lt;regexurl regex=&quot;false&quot; match=&quot;cms.xoyo.com/site([/a-zA-Z0-9]*).xoyo.com/images&quot;/&gt;&lt;/localpath&gt;&lt;/plugin&gt;&lt;/head&gt;#创建连接rsynd服务器的用户密码文件,并必须修改权限echo 123456 &gt; /etc/rsync.paschmod 600 /etc/rsync.pas#查看帮助sersync2 -hset the system paramexecute：echo 50000000 &gt; /proc/sys/fs/inotify/max_user_watchesexecute：echo 327679 &gt; /proc/sys/fs/inotify/max_queued_eventsparse the command param_______________________________________________________参数-d:启用守护进程模式参数-r:在监控前，将监控目录与远程主机用rsync命令推送一遍c参数-n: 指定开启守护线程的数量，默认为10个参数-o:指定配置文件，默认使用当前工作目录下的confxml.xml文件参数-m:单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块参数-m:单独启用其他模块，使用 -m socket 开启socket模块参数-m:单独启用其他模块，使用 -m http 开启http模块不加-m参数，则默认执行同步程序#以后台方式执行同步sersync2 -dro /usr/local/sersync/confxml.xml#如果同步失败,可以手动执行下面命令,观察过程cd /data/www &amp;&amp; rsync -artuz -R --delete ./ rsyncuser@backup-server::backup --password-file=/etc/rsync.pas &gt;/dev/null 2&gt;&amp;1#sersync支持多实例，也即监控多个目录时，只需分别配置不同配置文件，然后使用sersync2指定对应配置文件运行sersync2 -rd -o /etc/sersync.d/nginx.xml","categories":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"日志服务管理","slug":"日志服务管理","date":"2022-12-03T02:55:19.000Z","updated":"2022-12-16T14:56:47.152Z","comments":true,"path":"2022/12/03/日志服务管理/","link":"","permalink":"http://snippet.itshare.work/2022/12/03/%E6%97%A5%E5%BF%97%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/","excerpt":"在现实生活中，记录日志非常重要","text":"系统日志管理系统日志介绍在现实生活中，记录日志非常重要﹐比如:银行转账时会有转账记录﹔飞机飞行过程中的黑盒子（飞行数据记录器）记录着飞机的飞行过程. 那么将系统和应用发生的事件记录至日志中，也很意义,常可以助于排错和分析使用 日志记录的内容包括： 历史事件：时间，地点，人物，事件 日志级别：事件的关键性程度，Loglevel sysklogd 系统日志服务CentOS 5 之前版本采用的日志管理系统服务klogd: linux kernel 记录内核日志syslogd: system application 记录应用日志事件记录格式：日期时间 主机 进程[pid]: 事件内容C&#x2F;S架构：通过TCP或UDP协议的服务完成日志记录传送，将分布在不同主机的日志实现集中管理 rsyslog 系统日志服务rsyslog是CentOS 6 以后版本的系统管理服务.它提供了高性能，出色的安全性和模块化设计。 尽管rsyslog最初是常规的syslogd，但已发展成为一种瑞士军刀式的记录工具，能够接受来自各种来源的输入，并将其转换，然后输出到不同的目的地。当应用有限的处理时，RSYSLOG每秒可以将超过一百万的消息传递到本地目的地。 即使在远程的目的地和更精细的处理中，性能通常也被认为是“惊人的”。 官网网站 1https://www.rsyslog.com/ rsyslog 特性 多线程 UDP, TCP, SSL, TLS, RELP MySQL, PGSQL, Oracle实现日志存储 强大的过滤器，可实现过滤记录日志信息中任意部分 自定义输出格式 适用于企业级中继链 rsyslog 管理系统日志术语facility：设施，从功能或程序上对日志进行归类 12345#内置分类auth, authpriv, cron, daemon,ftp,kern, lpr, mail, news, security(auth),user, uucp, syslog#自定义的分类local0-local7 Priority 优先级别，从低到高排序 12debug,info, notice, warn(warning), err(error), crit(critical), alert,emerg(panic) 参看帮助： man 3 syslog，man logger 12[root@centos8 ~]#yum -y install man-pages[root@centos8 ~]#man 3 syslog rsyslog 相关文件 程序包：rsyslog 主程序：&#x2F;usr&#x2F;sbin&#x2F;rsyslogd CentOS 6：&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;rsyslog {start|stop|restart|status} CentOS 7,8：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;rsyslog.service 配置文件：&#x2F;etc&#x2F;rsyslog.conf，&#x2F;etc&#x2F;rsyslog.d&#x2F;.conf 库文件： &#x2F;lib64&#x2F;rsyslog&#x2F;.so rsyslog配置文件&#x2F;etc&#x2F;rsyslog.conf 配置文件格式：由三部分组成 MODULES：相关模块配置 GLOBAL DIRECTIVES：全局配置 RULES：日志记录相关的规则配置 RULES配置格式： 1facility.priority; facility.priority… target facility格式： 12* #所有的facilityfacility1,facility2,facility3,... #指定的facility列表 priority格式： 1234*: 所有级别none：没有级别，即不记录PRIORITY：指定级别（含）以上的所有级别=PRIORITY：仅记录指定级别的日志信息 target格式： 1234文件路径：通常在/var/log/，文件路径前的-表示异步写入用户：将日志事件通知给指定的用户，* 表示登录的所有用户日志服务器：@host，把日志送往至指定的远程UDP日志服务器 @@host 将日志发送到远程TCP日志服务器管道： | COMMAND，转发给其它命令处理 通常的日志文件的格式： 日志文件有很多，如： &#x2F;var&#x2F;log&#x2F;messages,cron,secure等，基本格式都是类似的。格式如下 1事件产生的日期时间 主机 进程(pid)：事件内容 范例：日志文件格式 123456789101112[root@centos7 ~]# tail -f /var/log/messagesDec 3 16:58:40 centos7 dbus[653]: [system] Activating via systemd: service name=&#x27;org.freedesktop.nm_dispatcher&#x27; unit=&#x27;dbus-org.freedesktop.nm-dispatcher.service&#x27;Dec 3 16:58:40 centos7 systemd: Starting Network Manager Script Dispatcher Service...Dec 3 16:58:40 centos7 dhclient[51210]: bound to 192.168.179.170 -- renewal in 745 seconds.Dec 3 16:58:40 centos7 dbus[653]: [system] Successfully activated service &#x27;org.freedesktop.nm_dispatcher&#x27;Dec 3 16:58:40 centos7 systemd: Started Network Manager Script Dispatcher Service.Dec 3 16:58:40 centos7 nm-dispatcher: req:1 &#x27;dhcp4-change&#x27; [ens33]: new request (2 scripts)Dec 3 16:58:40 centos7 nm-dispatcher: req:1 &#x27;dhcp4-change&#x27; [ens33]: start running ordered scripts...Dec 3 17:01:01 centos7 systemd: Started Session 95 of user root.Dec 3 17:11:05 centos7 dhclient[51210]: DHCPREQUEST on ens33 to 192.168.179.254 port 67 (xid=0x1f435c38)Dec 3 17:11:11 centos7 dhclient[51210]: DHCPREQUEST on ens33 to 192.168.179.254 port 67 (xid=0x1f435c38)Dec 3 17:11:26 centos7 dhclient[51210]: DHCPREQUEST on ens33 to 192.168.179.254 port 67 (xid=0x1f435c38) 1234567891011[root@centos7 ~]# tail -f /var/log/secureNov 29 22:58:18 centos7 sshd[49904]: pam_unix(sshd:session): session closed for user rootNov 30 19:58:03 centos7 sshd[50030]: Accepted password for root from 192.168.179.1 port 51814 ssh2Nov 30 19:58:03 centos7 sshd[50030]: pam_unix(sshd:session): session opened for user root by (uid=0)Nov 30 21:15:17 centos7 sshd[48764]: pam_unix(sshd:session): session closed for user rootDec 2 21:22:51 centos7 sshd[51123]: Accepted password for root from 192.168.179.1 port 53924 ssh2Dec 2 21:22:51 centos7 sshd[51123]: pam_unix(sshd:session): session opened for user root by (uid=0)Dec 3 09:08:03 centos7 sshd[50030]: pam_unix(sshd:session): session closed for user rootDec 3 09:53:40 centos7 sshd[51295]: Accepted password for root from 192.168.179.1 port 56421 ssh2Dec 3 09:53:40 centos7 sshd[51295]: pam_unix(sshd:session): session opened for user root by (uid=0)Dec 3 11:14:12 centos7 sshd[51123]: pam_unix(sshd:session): session closed for user root 范例：将ssh服务的日志记录至自定义的local的日志设备 修改sshd服务的配置 12345[root@centos7 ~]# vim /etc/ssh/sshd_config # 配置文件修改内容如下所示SyslogFacility local2# 重新加载sshd服务配置文件[root@centos7 ~]# service sshd reload 修改rsyslog配置 12345[root@centos7 ~]# vim /etc/rsyslog.conf # 加入如下内容local2.* /var/log/sshd.log# 重启服务[root@centos7 ~]# systemctl restart rsyslog 测试验证 123# ssh 登入该服务器# 查看日志文件内容tail -f /var/log/sshd.log 1234[root@centos7 ~]# tail -f /var/log/sshd.log Dec 3 20:06:35 centos7 sshd[49356]: Server listening on 0.0.0.0 port 22.Dec 3 20:06:35 centos7 sshd[49356]: Server listening on :: port 22.Dec 3 20:07:06 centos7 sshd[52189]: Accepted publickey for root from 192.168.179.171 port 33434 ssh2: RSA SHA256:HohSbRRS/oP0nLbEZTqgSJ6WQ5Mjp3f9DxM+spRO+SI 日志中可以看到192.168.179.171的IP地址通过root用户ssh登入该设备 启用网络日志服务启用网络日志服务功能，可以将多个远程主机的日志，发送到集中的日志服务器，方便统一管理。 范例：CentOS 7 和6 启用网络日志功能 123日志服务器：centos7.9，主机名称：centos7,ip:192.168.179.157客户端1：centos7.9，主机名称：centos7-master,ip:192.168.179.170客户端2：centos7.9，主机名称：centos7-slave,ip:192.168.179.171 修改日志服务器配置文件 12# 192.168.179.157上操作[root@centos7 ~]# vim /etc/rsyslog.conf 重启日志服务器rsyslog服务 1[root@centos7 ~]# systemctl restart rsyslog 修改客户端配置文件 12345678910# 修改192.168.179.170配置文件[root@centos7-master ~]# vim /etc/rsyslog.conf # 修改内容如下*.info;mail.none;authpriv.none;cron.none /var/log/messages*.info;mail.none;authpriv.none;cron.none @@192.168.179.157:514 #TCP*.info;mail.none;authpriv.none;cron.none @192.168.179.157:514 #udp# 重启服务systemctl restart rsyslog# 192.168.179.171客户端使用上面方法操作修改配置文件 测试验证 12# 在日志服务器上查看日志[root@centos7 ~]# tail -f /var/log/messages 可以看到主机名称centos7-master、centos7-slave上的日志说明实验成功 范例：CentOS 8 启用网络日志功能 12345678910## MODULES ####...省略...# Provides UDP syslog reception# for parameters see http://www.rsyslog.com/doc/imudp.htmlmodule(load=&quot;imudp&quot;) # needs to be done just onceinput(type=&quot;imudp&quot; port=&quot;514&quot;)# Provides TCP syslog reception# for parameters see http://www.rsyslog.com/doc/imtcp.htmlmodule(load=&quot;imtcp&quot;) # needs to be done just onceinput(type=&quot;imtcp&quot; port=&quot;514&quot;) 常见日志文件 &#x2F;var&#x2F;log&#x2F;secure：系统安全日志，文本格式，应周期性分析 &#x2F;var&#x2F;log&#x2F;btmp：当前系统上，用户的失败尝试登录相关的日志信息，二进制格式，lastb命令进行查看 &#x2F;var&#x2F;log&#x2F;wtmp：当前系统上，用户正常登录系统的相关日志信息，二进制格式，last命令可以查看 &#x2F;var&#x2F;log&#x2F;lastlog:每一个用户最近一次的登录信息，二进制格式，lastlog命令可以查看 &#x2F;var&#x2F;log&#x2F;dmesg：CentOS7 之前版本系统引导过程中的日志信息，文本格式，开机后的硬件变化 将不再记录，也可以通过专用命令dmesg查看，可持续记录硬件变化的情况 &#x2F;var&#x2F;log&#x2F;boot.log 系统服务启动的相关信息，文本格式 &#x2F;var&#x2F;log&#x2F;messages ：系统中大部分的信息 &#x2F;var&#x2F;log&#x2F;anaconda : anaconda的日志 实战案例：利用 MySQL 存储日志信息 目标利用rsyslog日志服务，将收集的日志记录于MySQL中 环境准备123两台主机一台：rsyslog日志服务器，IP：192.168.179.157一台：mariadb数据库服务器，IP：192.168.179.178 实现步骤1234567891011121314151617181920212223242526272829303132333435363738394041# 在rsyslog服务器上安装连接mysql模块相关的程序包[root@centos7 ~]# yum install rsyslog-mysql[root@centos7 ~]# rpm -ql rsyslog-mysql/usr/lib64/rsyslog/ommysql.so/usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql[root@centos7 ~]# #将sql脚本复制到数据库服务器上[root@centos7 ~]# scp /usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql 192.168.179.148:/root/# 在192.168.179.148上安装mysqlyum install mysql-server -y# #在mysql数据库服务器上创建相关数据库和表，并授权rsyslog能连接至当前服务器root@ubuntu1804:~# mysqlmysql&gt; source /root/mysql-createDB.sql;Query OK, 1 row affected (0.00 sec)mysql&gt; create user &#x27;rsyslog&#x27;@&#x27;192.168.179.%&#x27; identified by &#x27;123456&#x27;;Query OK, 0 rows affected (0.04 sec)mysql&gt; grant all on Syslog.* to &#x27;rsyslog&#x27;@&#x27;192.168.179.%&#x27;;Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; # 配置日志服务器将日志发送至指定数据库vim /etc/rsyslog.conf####MODULES#####在 MODULES 语言下面，如果是 CentOS 8 加下面行module(load=&quot;ommysql&quot;)#在 MODULES 语言下面，如果是 CentOS 7，6 加下面行$ModLoad ommysql#在RULES语句块加下面行的格式#facility.priority :ommysql:DBHOST,DBNAME,DBUSER, PASSWORD*.info :ommysql:192.168.179.148,Syslog,rsyslog,123456# 重启服务 测试12345678910111213# 在日志服务器上生成日志logger &#x27;this is test log&#x27;#在数据库上查询到上面的测试日志mysql&gt; select count(*) from SystemEvents;+----------+| count(*) |+----------+| 66 |+----------+1 row in set (0.00 sec)mysql&gt; logrotate 日志转储logrotate 介绍logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，称为日志转储或滚动。可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行 logrotate 配置软件包：logrotate相关文件 计划任务：&#x2F;etc&#x2F;cron.daily&#x2F;logrotate 程序文件：&#x2F;usr&#x2F;sbin&#x2F;logrotate 配置文件： &#x2F;etc&#x2F;logrotate.conf 日志文件：&#x2F;var&#x2F;lib&#x2F;logrotate&#x2F;logrotate.status 配置文件主要参数如下： 范例：对指定日志手动执行日志转储 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 生成测试日志[root@centos7-master ~]# dd if=/dev/zero of=/var/log/test1.log bs=2M count=11+0 records in1+0 records out2097152 bytes (2.1 MB) copied, 0.0017554 s, 1.2 GB/s[root@centos7-master ~]# [root@centos7-master ~]# dd if=/dev/zero of=/var/log/test2.log bs=2M count=11+0 records in1+0 records out2097152 bytes (2.1 MB) copied, 0.00240458 s, 872 MB/s[root@centos7-master ~]# #针对不同的日志创建转储配置文件[root@centos7-master ~]# vim /etc/logrotate.d/test1/var/log/test1.log &#123; daily rotate 5 compress delaycompress missingok size 1M notifempty create 640 bin nobody postrotate echo `date +%F_%T` &gt;&gt; /data/test1.log endscript&#125;[root@centos7-master ~]# vim /etc/logrotate.d/test2/var/log/test2.log &#123; daily rotate 5 compress delaycompress missingok size 1M notifempty create 644 root root postrotate echo `date +%F_%T` &gt;&gt; /data/test2.log endscript&#125;#针对一个测试日志，手动执行日志转储[root@centos7-master ~]# logrotate /etc/logrotate.d/test1[root@centos7-master ~]# ll /var/log/test*-rw-r----- 1 bin nobody 0 Dec 4 11:12 /var/log/test1.log-rw-r--r-- 1 root root 2097152 Dec 4 11:07 /var/log/test1.log.1-rw-r--r-- 1 root root 2097152 Dec 4 11:07 /var/log/test2.log[root@centos7-master ~]# [root@centos7-master ~]# ll /data/total 1800-rw-r--r-- 1 root root 915255 Nov 27 17:22 1127.sql-rw-r--r-- 1 root root 914921 Nov 25 10:23 all.sqldrwxr-xr-x 3 root root 18 Nov 29 22:45 mastermhadrwxr-x--- 11 mysql mysql 4096 Dec 3 20:30 mysql-rw-r--r-- 1 root root 20 Dec 4 11:12 test1.log[root@centos7-master ~]# #对所有日志进行手动转储[root@centos7-master ~]# logrotate /etc/logrotate.conf","categories":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"MySQL备份和恢复","slug":"MySQL备份脚本","date":"2022-11-21T14:28:03.000Z","updated":"2022-12-29T08:26:14.300Z","comments":true,"path":"2022/11/21/MySQL备份脚本/","link":"","permalink":"http://snippet.itshare.work/2022/11/21/MySQL%E5%A4%87%E4%BB%BD%E8%84%9A%E6%9C%AC/","excerpt":"硬件故障、软件故障、自然灾害、黑客攻击、误操作测试等数据丢失场景","text":"实战案例：特定数据库的备份脚本 系统：centos8.5 MySQL版本：8.0 12345678910111213#!/bin/bashTIME=`date +%F_%H-%M-%S`# 备份目录DIR=/mysql_backup# 备份数据库DB=hellodb# 数据库密码PASSWD=123456# 判断备份数据库目录是否存在[ -d $DIR ] || mkdir $DIR# 备份mysqldump -uroot -p&quot;$PASSWD&quot; -F -E -R --triggers --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip &gt; $&#123;DIR&#125;/$&#123;DB&#125;_$&#123;TIME&#125;.sql.gz 实战案例：分库备份的实战脚本 系统：centos8.5 MySQL版本：8.0 12345678#!/bin/bashTIME=`date +%F_%H-%M-%S`DIR=/backupPASS=123456[ -d &quot;$DIR&quot; ] || mkdir $DIRfor DB in `mysql -uroot -p&quot;$PASS&quot; -e &#x27;show databases&#x27; | grep -Ev &quot;^Database|.*schema$&quot;`;do mysqldump -uroot -p&quot;$PASS&quot; -F --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip &gt; $&#123;DIR&#125;/$&#123;DB&#125;_$&#123;TIME&#125;.sql.gzdone","categories":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}],"tags":[{"name":"MySQL基础","slug":"MySQL基础","permalink":"http://snippet.itshare.work/tags/MySQL%E5%9F%BA%E7%A1%80/"}],"keywords":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}]},{"title":"软件测试基础面试题","slug":"SoftwareTestingQuestions","date":"2022-11-03T03:54:32.000Z","updated":"2022-11-10T12:20:36.147Z","comments":true,"path":"2022/11/03/SoftwareTestingQuestions/","link":"","permalink":"http://snippet.itshare.work/2022/11/03/SoftwareTestingQuestions/","excerpt":"我只是搬运工，如果文中有冒犯到你的地方，请告知我删除内容，或添加来源。","text":"APP测试APP专项测试有哪些？专项的测试方法，包括：兼容性测试、流量测试、电量测试、弱网络测试、稳定性测试、 安全测试和环境相关测试。 第一：兼容性测试 针对App通常会考虑这些方面： 1） 操作系统版本 包括Andoird版本，iOS版本 2）屏幕分辨率 3）不同厂家的ROM 4) 网络类型 比如Wifi、3G、4G下的功能情况 第二：流量测试 在 移动产品的测试中，很有必要对App使用的流量进行度量，大致来说，流量可以从用户使用的的相关性角度分为：一类是用户的操作直接导致的流量消耗；另一类是后台，即在用户没有直接使用情况下的流量消耗。 第三：电量测试 在木器电池 技术没有取得巨大突破前提下，这方面始终会存在一些瓶颈，如果一些App架构设计的不好，或者代码偶缺陷，就可能导致电量消耗比较高，所以电量测试也是很重要的。 第四：弱网络测试 移动互联网产品相比PC互联网产品，有一个特点是前者使用的网络比较多样，除了Wif之外，很多时候是在移动网络下使用的，移动网络遇到的情况又比较复杂，比如地铁、隧道、体育场等。所以网络不稳定的情况是比较容易发生的，很多情况下App的一些问题是在复杂的网络情况下才会暴露，与其让用户发现和投诉这些问题，不如我们在测试阶段尽量模拟这样的网络情况，及早发现和修复这些问题。 第五：稳定性测试 在保证基本功能正确基础之上，App的稳定性就显得非常重要，如果一个App经常出现闪退或者卡死，那么用户体验就会受到很大伤害，在有其他竞争产品的情况下很容易造成用户的流失。 第六：安全测试 包括安装包的安全测试（能否反编译代码、安装包是否签名等）、敏感信息测试、软键盘劫持、账户安全、数据通信安全等。服务器端的 SQL注入测试、XSS跨站脚本攻击等。 第七：环境相关的测试 在实际项目中，有一些缺陷我发现是和App所处的运行环境相关的，所以设计测试的时候，要多考虑这些场景，比如： 1）干扰测试 收到 电话、收到 短信、收到通知栏消息、无电提示框弹出、第三方安全软件告警弹出。 2）权限测试 一些用户在实际使用App的时候回有意识阻止某些功能。例如有的用户感觉让某个App访问电话本或者相册可能泄漏隐私，就在手机中设置了禁止了该App访问相册的权限。 3）边界测试 手机环境本身也有其边界情况需要在测试中覆盖。常见的场景有： 可用存储空间过少、没有SD卡&#x2F;双SD卡、飞行模式、系统时间有误（晚于和早于标准时间）、第三方依赖（比如我们的App依赖第三方App，但是现在第三方App没有安装或者版本过低的测试情况）","categories":[{"name":"软件测试面经","slug":"软件测试面经","permalink":"http://snippet.itshare.work/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E9%9D%A2%E7%BB%8F/"}],"tags":[{"name":"软件测试工程师面试基础","slug":"软件测试工程师面试基础","permalink":"http://snippet.itshare.work/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80/"}],"keywords":[{"name":"软件测试面经","slug":"软件测试面经","permalink":"http://snippet.itshare.work/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E9%9D%A2%E7%BB%8F/"}]},{"title":"HTTP超文本传输协议","slug":"http","date":"2022-10-15T06:10:20.000Z","updated":"2022-12-16T14:57:57.377Z","comments":true,"path":"2022/10/15/http/","link":"","permalink":"http://snippet.itshare.work/2022/10/15/http/","excerpt":"首先你听的最多的应该就是 HTTP 是一种 超文本传输协议(Hypertext Transfer Protocol)，这你一定能说出来，但是这样还不够，假如你是大厂面试官，这不可能是他想要的最终结果，我们在面试的时候往往把自己知道的尽可能多的说出来，才有和面试官谈价钱的资本。那么什么是超文本传输协议？","text":"OSI模型 名称 协议 7 应用层 DNS、http、ssh、FTP等 6 表示层 DNS、http、ssh、FTP等 5 会话层 DNS、http、ssh、FTP等 4 传输层 tcp、udp 3 网络层 IPV4、IPV6、ARP 2 数据链路层 以太网、无线LAN 1 物理层 光纤 http协议http协议：超文本传输协议，基于TCP协议的应用层传输协议，一种 无状态的、以请求&#x2F;应答方式的运行的协议（无状态：对于事物处理没有记忆功能） 主要组成http协议主要有三大部分组成 起始行：描述请求或相应的文本 头部字段：使用key-value形式更加详细说明报文 消息正文：实际传输的数据，可以是文本、图片、视频等 http请求报文 请求行 请求头 请求体 http响应报文 响应行 响应头 响应体 TCP协议tcp&#x2F;ip协议：面向连接的、可靠的基于字节流的传输层协议。 特点 基于连接的：数据传输前需要建立连接 全双工：双向传输 字节流：不限制传输大小 流量缓冲：解决双方处理能力的不匹配 可靠的传输服务：保证可达、信息丢包时通过重发机制实施可靠性 拥塞控制：防止网络出现恶性拥塞 三次握手 刚开始客户端处于 closed 的状态，服务端处于 listen 状态。然后1、第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN（c）。此时客户端处于 SYN_Send 状态。 2、第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。 3、第三次握手：客户端收到 ACK+SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 establised 状态。 4、服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。 SYN是同步的缩写，SYN段是发送到另外一台计算机的TCP数据包，请求在她们之间建立连接 ACK是“确认”的缩写。ACK数据包是任何确认收到一条消息或一系列数据包的TCP数据包 **四次挥手** 刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则： 1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。 2、第二次握手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态。 3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。 4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态 5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。 为什么TIME-WAIT状态必须等待2MSL的时间？ 保证客户端最后一个ACK能够到达服务器端 防止失效的请求报文段出现在本次连接中","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://snippet.itshare.work/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"网络基础","slug":"网络基础","permalink":"http://snippet.itshare.work/tags/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"}],"keywords":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://snippet.itshare.work/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]},{"title":"在线一键安装MySQL脚本","slug":"MySQLinstallScript","date":"2022-09-29T16:19:44.000Z","updated":"2022-12-29T08:26:25.638Z","comments":true,"path":"2022/09/30/MySQLinstallScript/","link":"","permalink":"http://snippet.itshare.work/2022/09/30/MySQLinstallScript/","excerpt":"Rocky8.5系统在线一键安装MySQL脚本","text":"环境： 系统：rocky8.5 MySQL版本:8.0.28 在线安装 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#!/bin/bash##Author yuankun#Date 2022-09-29#Filename install_mysql-8.0.28-linux-glibc2.12-x86_64.sh. /etc/init.d/functionscolor=&#x27;echo -e \\E[01;31m&#x27;end=&#x27;\\E[0m&#x27;# 设置mysql root用户密码MYSQL_ROOT_PASSWD=123456MYSQL_VERSION=mysql-8.0.28-linux-glibc2.12-x86_64.tar.xzcheck()&#123; $&#123;color&#125;安装前环境检查......$&#123;end&#125; # 判断当前用户是否是root用户，不是则退出安装 if [ $&#123;UID&#125; -ne 0 ];then action &quot;当前用户不是root,安装失败!&quot; false exit fi # 判断是否安装wget，没有安装则使用yum安装wget rpm -q wget || yum install -y wget # 判断/usr/local/mysql目录是否存在，存在则exit if [ -e /usr/local/mysql ];then $&#123;color&#125;&quot;mysql已经安装,安装失败!&quot;$&#123;end&#125; exit fi # 下载二进制程序包 wget https://cdn.mysql.com/archives/mysql-8.0/mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz # 判断二进制程序包是否存在 if [ ! -e $&#123;MYSQL_VERSION&#125; ];then $&#123;color&#125;&quot;文件不存在,安装失败!&quot;$&#123;end&#125; $&#123;color&#125;&quot;请检查脚本以及主机环境，然后再次尝试安装。即将退出安装流程!&quot;$&#123;end&#125; exit else $&#123;color&#125;&quot;安装前环境检查完毕,环境要求满足!&quot;$&#123;end&#125; fi&#125;# 安装mysqlinstall_mysql()&#123; $&#123;color&#125;&quot;开始安装mysql......&quot;$&#123;end&#125; # 安装依赖 yum install -y -q libaio numactl-libs # 解压缩 tar xf $&#123;MYSQL_VERSION&#125; -C /usr/local/ cd /usr/local/ MYSQL_FILE=`echo $&#123;MYSQL_VERSION&#125; | sed -nr &#x27;s/^(.*[0-9]).*/\\1/p&#x27;` ln -s /usr/local/$&#123;MYSQL_FILE&#125; /usr/local/mysql chown -R root.root /usr/local/mysql/ id mysql &amp;&gt; /dev/null || &#123; useradd -s /sbin/nologin -r mysql ; action &quot;创建mysql用户&quot;; &#125; # 环境变量 echo &#x27;PATH=/usr/local/mysql/bin/:$PATH&#x27; &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ # 配置文件 cat &gt; /etc/my.cnf &lt;&lt;-EOF[mysqld]server-id=1log-bindatadir=/data/mysqlsocket=/data/mysql/mysql.socklog-error=/data/mysql/mysql.logpid-file=/data/mysql/mysql.pid[client]socket=/data/mysql/mysql.sockEOF [ -d /data ] || mkdir /data mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] &amp;&amp; &#123; $color&quot;数据库启动失败，退出!&quot;$end;exit; &#125; sleep 3 MYSQL_OLDPASSWORD=`awk &#x27;/A temporary password/&#123;print $NF&#125;&#x27; /data/mysql/mysql.log` mysqladmin -uroot -p$&#123;MYSQL_OLDPASSWORD&#125; password $&#123;MYSQL_ROOT_PASSWD&#125; &amp;&gt;/dev/null action &quot;数据库安装完成&quot;&#125;# 调用函数checkinstall_mysql 扩展：在线一键安装MySQL5.7.39脚本 系统：rocky8.5 MySQL版本:5.7.39 在线安装 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#!/bin/bash##Author yuankun#Date 2022-11-19#Filename install_mysql-5.7.39-linux-glibc2.12-x86_64.sh. /etc/init.d/functionscolor=&#x27;echo -e \\E[01;31m&#x27;end=&#x27;\\E[0m&#x27;# 设置mysql root用户密码MYSQL_ROOT_PASSWD=123456MYSQL_VERSION=mysql-5.7.39-linux-glibc2.12-x86_64.tar.gzcheck()&#123; $&#123;color&#125;安装前环境检查......$&#123;end&#125; # 判断当前用户是否是root用户，不是则退出安装 if [ $&#123;UID&#125; -ne 0 ];then action &quot;当前用户不是root,安装失败!&quot; false exit fi # 判断是否安装wget，没有安装则使用yum安装wget rpm -q wget || yum install -y wget # 判断/usr/local/mysql目录是否存在，存在则exit if [ -e /usr/local/mysql ];then $&#123;color&#125;&quot;mysql已经安装,安装失败!&quot;$&#123;end&#125; exit fi # 下载二进制程序包 wget https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.39-linux-glibc2.12-x86_64.tar.gz # 判断二进制程序包是否存在 if [ ! -e $&#123;MYSQL_VERSION&#125; ];then $&#123;color&#125;&quot;文件不存在,安装失败!&quot;$&#123;end&#125; $&#123;color&#125;&quot;请检查脚本以及主机环境，然后再次尝试安装。即将退出安装流程!&quot;$&#123;end&#125; exit else $&#123;color&#125;&quot;安装前环境检查完毕,环境要求满足!&quot;$&#123;end&#125; fi&#125;# 安装mysqlinstall_mysql()&#123; $&#123;color&#125;&quot;开始安装mysql......&quot;$&#123;end&#125; # 安装依赖 yum install -y -q libaio numactl-libs # 解压缩 tar xf $&#123;MYSQL_VERSION&#125; -C /usr/local/ cd /usr/local/ MYSQL_FILE=`echo $&#123;MYSQL_VERSION&#125; | sed -nr &#x27;s/^(.*[0-9]).*/\\1/p&#x27;` ln -s /usr/local/$&#123;MYSQL_FILE&#125; /usr/local/mysql chown -R root.root /usr/local/mysql/ id mysql &amp;&gt; /dev/null || &#123; useradd -s /sbin/nologin -r mysql ; action &quot;创建mysql用户&quot;; &#125; # 环境变量 echo &#x27;PATH=/usr/local/mysql/bin/:$PATH&#x27; &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ # 配置文件 cat &gt; /etc/my.cnf &lt;&lt;-EOF[mysqld]server-id=1log-bindatadir=/data/mysqlsocket=/data/mysql/mysql.socklog-error=/data/mysql/mysql.logpid-file=/data/mysql/mysql.pid[client]socket=/data/mysql/mysql.sockEOF [ -d /data ] || mkdir /data mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] &amp;&amp; &#123; $color&quot;数据库启动失败，退出!&quot;$end;exit; &#125; sleep 3 MYSQL_OLDPASSWORD=`awk &#x27;/A temporary password/&#123;print $NF&#125;&#x27; /data/mysql/mysql.log` mysqladmin -uroot -p$&#123;MYSQL_OLDPASSWORD&#125; password $&#123;MYSQL_ROOT_PASSWD&#125; &amp;&gt;/dev/null action &quot;数据库安装完成&quot;&#125;# 调用函数checkinstall_mysql 离线安装 注意：需要提前将二进制包下载到本地 系统：rocky8.5 MySQL版本:8.0.28 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#!/bin/bash##Author yuankun#Date 2022-11-19#Filename install_offline_mysql-8.0.28-linux-glibc2.12-x86_64.sh. /etc/init.d/functionscolor=&#x27;echo -e \\E[01;31m&#x27;end=&#x27;\\E[0m&#x27;# 设置mysql root用户密码MYSQL_ROOT_PASSWD=123456# mysql 版本MYSQL_VERSION=mysql-8.0.28-linux-glibc2.12-x86_64.tar.xzcheck()&#123; $&#123;color&#125;安装前环境检查......$&#123;end&#125; # 判断当前用户是否是root用户，不是则退出安装 if [ $&#123;UID&#125; -ne 0 ];then action &quot;当前用户不是root,安装失败!&quot; false exit fi # 判断/usr/local/mysql目录是否存在，存在则exit if [ -e /usr/local/mysql ];then $&#123;color&#125;&quot;mysql已经安装，安装失败!&quot;$&#123;end&#125; exit fi # 判断二进制程序包是否存在 if [ ! -e $&#123;MYSQL_VERSION&#125; ];then $&#123;color&#125;&quot;文件不存在,安装失败!&quot;$&#123;end&#125; $&#123;color&#125;&quot;请检查脚本以及主机环境，然后再次尝试安装。即将退出安装流程!&quot;$&#123;end&#125; exit else $&#123;color&#125;&quot;安装前环境检查完毕,环境要求满足!&quot;$&#123;end&#125; fi&#125;install_mysql()&#123; $&#123;color&#125;&quot;开始安装mysql......&quot;$&#123;end&#125; # 安装依赖 yum install -y -q libaio numactl-libs # 解压缩 tar xf $&#123;MYSQL_VERSION&#125; -C /usr/local/ cd /usr/local/ MYSQL_FILE=`echo $&#123;MYSQL_VERSION&#125; | sed -nr &#x27;s/^(.*[0-9]).*/\\1/p&#x27;` ln -s /usr/local/$&#123;MYSQL_FILE&#125; /usr/local/mysql chown -R root.root /usr/local/mysql/ id mysql &amp;&gt; /dev/null || &#123; useradd -s /sbin/nologin -r mysql ; action &quot;创建mysql用户&quot;; &#125; # 环境变量 echo &#x27;PATH=/usr/local/mysql/bin/:$PATH&#x27; &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ # 配置文件 cat &gt; /etc/my.cnf &lt;&lt;-EOF[mysqld]server-id=1log-bindatadir=/data/mysqlsocket=/data/mysql/mysql.socklog-error=/data/mysql/mysql.logpid-file=/data/mysql/mysql.pid[client]socket=/data/mysql/mysql.sockEOF [ -d /data ] || mkdir /data mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] &amp;&amp; &#123; $color&quot;数据库启动失败，退出!&quot;$end;exit; &#125; sleep 3 MYSQL_OLDPASSWORD=`awk &#x27;/A temporary password/&#123;print $NF&#125;&#x27; /data/mysql/mysql.log` mysqladmin -uroot -p$&#123;MYSQL_OLDPASSWORD&#125; password $&#123;MYSQL_ROOT_PASSWD&#125; &amp;&gt;/dev/null action &quot;数据库安装完成&quot;&#125;# 调用函数checkinstall_mysql 离线安装Mysql5.7.38 操作系统：centos7.9 mysql版本：5.7.38 mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz下载链接 1wget https://mirrors.cloud.tencent.com/mysql/downloads/MySQL-5.7/mysql-5.7.38-linux-glibc2.12-x86_64.tar.gz 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#!/bin/bash##Author yuankun#Date 2022-11-24#Filename install_offline_mysql-5.7.38-linux-glibc2.12-x86_64.sh. /etc/init.d/functionscolor=&#x27;echo -e \\E[01;31m&#x27;end=&#x27;\\E[0m&#x27;# 设置mysql root用户密码MYSQL_ROOT_PASSWD=123456# mysql 版本MYSQL_VERSION=mysql-5.7.38-linux-glibc2.12-x86_64.tar.gzcheck()&#123; $&#123;color&#125;安装前环境检查......$&#123;end&#125; # 判断当前用户是否是root用户，不是则退出安装 if [ $&#123;UID&#125; -ne 0 ];then action &quot;当前用户不是root,安装失败!&quot; false exit fi # 判断/usr/local/mysql目录是否存在，存在则exit if [ -e /usr/local/mysql ];then $&#123;color&#125;&quot;mysql已经安装，安装失败!&quot;$&#123;end&#125; exit fi # 判断二进制程序包是否存在 if [ ! -e $&#123;MYSQL_VERSION&#125; ];then $&#123;color&#125;&quot;文件不存在,安装失败!&quot;$&#123;end&#125; $&#123;color&#125;&quot;请检查脚本以及主机环境，然后再次尝试安装。即将退出安装流程!&quot;$&#123;end&#125; exit else $&#123;color&#125;&quot;安装前环境检查完毕,环境要求满足!&quot;$&#123;end&#125; fi&#125;install_mysql()&#123; $&#123;color&#125;&quot;开始安装mysql......&quot;$&#123;end&#125; # 安装依赖 yum install -y -q libaio numactl-libs # 解压缩 tar xf $&#123;MYSQL_VERSION&#125; -C /usr/local/ cd /usr/local/ MYSQL_FILE=`echo $&#123;MYSQL_VERSION&#125; | sed -nr &#x27;s/^(.*[0-9]).*/\\1/p&#x27;` ln -s /usr/local/$&#123;MYSQL_FILE&#125; /usr/local/mysql chown -R root.root /usr/local/mysql/ id mysql &amp;&gt; /dev/null || &#123; useradd -s /sbin/nologin -r mysql ; action &quot;创建mysql用户&quot;; &#125; # 环境变量 echo &#x27;PATH=/usr/local/mysql/bin/:$PATH&#x27; &gt; /etc/profile.d/mysql.sh . /etc/profile.d/mysql.sh ln -s /usr/local/mysql/bin/* /usr/bin/ # 配置文件 cat &gt; /etc/my.cnf &lt;&lt;-EOF[mysqld]server-id=1log-bindatadir=/data/mysqlsocket=/data/mysql/mysql.socklog-error=/data/mysql/mysql.logpid-file=/data/mysql/mysql.pid[client]socket=/data/mysql/mysql.sockEOF [ -d /data ] || mkdir /data mysqld --initialize --user=mysql --datadir=/data/mysql cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service mysqld start [ $? -ne 0 ] &amp;&amp; &#123; $color&quot;数据库启动失败，退出!&quot;$end;exit; &#125; sleep 3 MYSQL_OLDPASSWORD=`awk &#x27;/A temporary password/&#123;print $NF&#125;&#x27; /data/mysql/mysql.log` mysqladmin -uroot -p$&#123;MYSQL_OLDPASSWORD&#125; password $&#123;MYSQL_ROOT_PASSWD&#125; &amp;&gt;/dev/null action &quot;数据库安装完成&quot;&#125;# 调用函数checkinstall_mysql","categories":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}],"tags":[{"name":"MySQL基础","slug":"MySQL基础","permalink":"http://snippet.itshare.work/tags/MySQL%E5%9F%BA%E7%A1%80/"}],"keywords":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}]},{"title":"MySQL数据库基础和安装使用","slug":"MySQL","date":"2022-09-28T14:42:41.000Z","updated":"2022-12-16T14:58:25.192Z","comments":true,"path":"2022/09/28/MySQL/","link":"","permalink":"http://snippet.itshare.work/2022/09/28/MySQL/","excerpt":"MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一","text":"MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，属于 Oracle 旗下产品。MySQL 是最流行的关系型数据库管理系统之一，在 WEB 应用方面，MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一 MySQL的特性 MySQL安装安装方式介绍程序包管理器管理的程序包源代码编译安装二进制格式的程序包：展开至特定路径，并经过简单配置后即可使用 rpm安装CentOS 安装光盘项目官方：https://downloads.mariadb.org/mariadb/repositories/国内镜像：https://mirrors.tuna.tsinghua.edu.cn/mariadb/yum/https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/ 范例1：CentOS 7 利用yum源安装MySQL8.0 MySQL官网 官网下载rpm包 利用rz命令将rpm包上传到主机 扩展： 1rz命令yum安装:yum install lrzsz 安装rpm包 1root@centos7[~]-&gt;yum install mysql80-community-release-el7-7.noarch.rpm 安装MySQL 1root@centos7[~]-&gt;yum install -y mysql-community-server 范例2：CentOS 7 利用yum源安装MySQL5.7 123456789[root@centos7 ~]#tee /etc/yum.repos.d/mysql.repo &lt;&lt;EOF[mysql]name=mysql5.7baseurl=https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/mysql-5.7-community-el7-x86_64/gpgcheck=0EOF[root@centos7 ~]#yum -y install mysql-community-server[root@centos7 ~]#systemctl enable --now mysqld 二进制安装环境 系统：rocky8.5 MySQL版本：mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz 步骤 安装相关包 1yum -y install libaio numactl-libs 准备用户 12groupadd mysqluseradd -r -g mysql -s /bin/false mysql 下载二进制程序包 123456# -P下载到指定目录wget https://cdn.mysql.com/archives/mysql-8.0/mysql-8.0.28-linux-glibc2.12-x86_64.tar.xz -P /usr/local/ ln -s mysql-8.0.28-linux-glibc2.12-x86_64 mysql chown -R root.root /usr/local/mysql/ 准备环境变量 12echo &#x27;PATH=/usr/local/mysql/bin:$PATH&#x27; &gt; /etc/profile.d/mysql.sh. /etc/profile.d/mysql.sh 准备配置文件 123456789vim /etc/my.cnf[mysqld]datadir=/data/mysqlskip_name_resolve=1socket=/data/mysql/mysql.socklog-error=/data/mysql/mysql.logpid-file=/data/mysql/mysql.pid[client]socket=/data/mysql/mysql.sock 初始化数据库文件并提取root密码 12mkdir -pv /data/mysqlgrep password /data/mysql/mysql.log 生成随机密码 1mysqld --initialize --user=mysql --datadir=/data/mysql 生成空密码 1mysqld --initialize-insecure --user=mysql --datadir=/data/mysql 准备服务脚本和启动 12345[root@rocky local]# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqldchkconfig --add mysqld# 启动服务service mysqld start 修改口令 12345# 修改随机密码为指定密码mysqladmin -uroot -p&#x27;9ATjCOB(jIef&#x27; password 123456#修改前面生成的空密码为指定密码mysqladmin -uroot password 123456 测试登录 1mysql -uroot -p&#x27;123456&#x27; 注意：登录mysql报如下信息 1mysql: error while loading shared libraries: libtinfo.so.5: cannot open shared object file: No such file or directory 解决方法： 1ln -s /usr/lib64/libtinfo.so.6.1 /usr/lib64/libtinfo.so.5 登录成功： 源码编译安装MySQL多实例SQL语言SQL语言的兴起与语法标准SQL语句分类 DDL: Data Defination Language 数据定义语言CREATE，DROP，ALTER DML: Data Manipulation Language 数据操纵语言INSERT，DELETE，UPDATE软件开发：CRUD DQL：Data Query Language 数据查询语言SELECT DCL：Data Control Language 数据控制语言GRANT，REVOKE TCL：Transaction Control Language 事务控制语言COMMIT，ROLLBACK，SAVEPOINT 字符集和排序 查看所有支持的字符集 12show character set;show charset; 查看支持的所有排序 1234show collation;#注意utf8_general_ci不区分大小写utf8_bin 区分大小写 查看当前使用的排序规则 123456789mysql&gt; show variables like &#x27;collation%&#x27;;+----------------------+-------------------+| Variable_name | Value |+----------------------+-------------------+| collation_connection | utf8_general_ci || collation_database | latin1_swedish_ci || collation_server | latin1_swedish_ci |+----------------------+-------------------+3 rows in set (0.01 sec) 设置服务器端默认字符集 1234567vim /etc/my.cnf#针对mysql客户端[mysql]default-character-set=utf8mb4#针对所有MySQL客户端[client]default-character-set=utf8mb4 查看当前字符集的使用情况 12345678910111213141516mysql&gt; show variables like &#x27;character%&#x27;;+--------------------------+----------------------------------------------------------------+| Variable_name | Value |+--------------------------+----------------------------------------------------------------+| character_set_client | utf8mb4 || character_set_connection | utf8mb4 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | utf8mb4 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/local/mysql-5.7.39-linux-glibc2.12-x86_64/share/charsets/ |+--------------------------+----------------------------------------------------------------+8 rows in set (0.00 sec)mysql&gt; 面试题: VARCHAR(50) 能存放几个 UTF8 编码的汉字？ 12345存放的汉字个数与版本相关。mysql 4.0以下版本，varchar(50) 指的是 50 字节，如果存放 UTF8 格式编码的汉字时（每个汉字3字节），只能存放16 个。mysql 5.0以上版本，varchar(50) 指的是 50 字符，无论存放的是数字、字母还是 UTF8 编码的汉字，都可以存放 50 个。 ＭySQL用户管理 相关数据库和表 12元数据数据库：mysql系统授权表：db, host, user,columns_priv, tables_priv, procs_priv, proxies_priv 用户账号 1234567&#x27;USERNAME&#x27;@&#x27;HOST&#x27;@&#x27;HOST&#x27;: 主机名： user1@&#x27;web1.magedu.org&#x27;IP地址或Network通配符： % _示例：wang@&#x27;172.16.%.%&#x27;user2@&#x27;192.168.1.%&#x27;mage@&#x27;10.0.0.0/255.255.0.0&#x27; 创建用户：create user 1234CREATE USER &#x27;USERNAME&#x27;@&#x27;HOST&#x27; [IDENTIFIED BY &#x27;password&#x27;]；#示例:create user test@&#x27;10.0.0.0/255.255.255.0&#x27; identified by &#x27;123456&#x27;;create user test2@&#x27;10.0.0.%&#x27; identified by 123456 新建用户的默认权限：USAGE 用户重命名：RENAME USER 1RENAME USER old_user_name TO new_user_name; 删除用户 1DROP USER &#x27;USERNAME&#x27;@&#x27;HOST&#x27; 删除空用户 1DROP USER &#x27;&#x27;@&#x27;localhost&#x27;; 修改密码 注意 新版mysql中用户密码可以保存在mysql.user表的authentication_string字段中如果mysql.user表的authentication_string和password字段都保存密码，authentication_string优先生效 123456789101112131415#方法1,用户可以也可通过此方式修改自已的密码SET PASSWORD FOR &#x27;user&#x27;@&#x27;host&#x27; = PASSWORD(&#x27;password&#x27;); #MySQL8.0 版本不支持此方法,因为password函数被取消set password for root@&#x27;localhost&#x27;=&#x27;123456&#x27; ; #MySQL8.0版本支持此方法,此方式直接将密码123456加密后存放在mysql.user表的authentication_string字段#方法2ALTER USER test@&#x27;%&#x27; IDENTIFIED BY &#x27;centos&#x27;; #通用改密码方法, 用户可以也可通过此方式修改自已的密码,MySQL8 版本修改密码#方法3 此方式MySQL8.0不支持,因为password函数被取消UPDATE mysql.user SET password=PASSWORD(&#x27;password&#x27;) WHERE clause;#mariadb 10.3update mysql.user set authentication_string=password(&#x27;ubuntu&#x27;) whereuser=&#x27;mage&#x27;;#此方法需要执行下面指令才能生效：FLUSH PRIVILEGES; 忘记管理员密码解决方法 启动mysqld进程时，为其使用如下选项： 12--skip-grant-tables--skip-networking 使用UPDATE命令修改管理员密码 关闭mysqld进程，移除上述两个选项，重启mysqld 范例:Mariadb 和MySQL5.6版之前破解root密码 1234567891011121314151617181920212223[root@centos8 ~]#vim /etc/my.cnf[mysqld]skip-grant-tablesskip-networking[root@centos8 ~]#systemctl restart mysqld|mariadb[root@centos8 ~]#mysql#方法1#mariadb 旧版和MySQL5.6版之前MariaDB [(none)]&gt; update mysql.user set password=password(&#x27;ubuntu&#x27;) whereuser=&#x27;root&#x27;;#mariadb 新版MariaDB [(none)]&gt; update mysql.user set authentication_string=password(&#x27;ubuntu&#x27;)where user=&#x27;root&#x27;;#方法2MariaDB [(none)]&gt; flush privileges;MariaDB [(none)]&gt; alter user root@&#x27;localhost&#x27; identified by &#x27;ubuntu&#x27;;[root@centos8 ~]#vim /etc/my.cnf[mysqld]#skip-grant-tables#skip-networking[root@centos8 ~]#systemctl restart mysqld|mariadb[root@centos8 ~]#mysql -uroot -pubuntu 范例: MySQL5.7和8.0 破解root密码 12345678910111213141516171819[root@centos8 ~]#vim /etc/my.cnf[mysqld]skip-grant-tablesskip-networking #MySQL8.0不需要[root@centos8 ~]#systemctl restart mysqld#方法1mysql&gt; update mysql.user set authentication_string=&#x27;&#x27; where user=&#x27;root&#x27; andhost=&#x27;localhost&#x27;;#方法2mysql&gt; flush privileges;#再执行下面任意一个命令mysql&gt; alter user root@&#x27;localhost&#x27; identified by &#x27;ubuntu&#x27;;mysql&gt; set password for root@&#x27;localhost&#x27;=&#x27;ubuntu&#x27;;[root@centos8 ~]#vim /etc/my.cnf[mysqld]#skip-grant-tables#skip-networking[root@centos8 ~]#systemctl restart mysqld[root@centos8 ~]#mysql -uroot -pubuntu 范例: 删库跑路之清空root密码方法 1234#此方法适用于包安装方式的MySQL或Mariadb[root@centos8 ~]#systemctl stop mysqld[root@centos8 ~]#rm -rf /var/lib/mysql/*[root@centos8 ~]#systemctl start mysqld 权限管理权限类别： 管理类 程序类 数据库级别 表级别 字段级别 管理类： CREATE USER FILE SUPER SHOW DATABASES RELOAD SHUTDOWN REPLICATION SLAVE REPLICATION CLIENT LOCK TABLES PROCESS CREATE TEMPORARY TABLES 程序类：针对 FUNCTION、PROCEDURE、TRIGGER CREATE ALTER DROP EXCUTE库和表级别：针对 DATABASE、TABLE ALTER CREATE CREATE VIEW DROP INDEX SHOW VIEW WITH GRANT OPTION：能将自己获得的权限转赠给其他用户数据操作 SELECT-INSERT DELETE UPDATE字段级别 SELECT(col1,col2,…) UPDATE(col1,col2,…) INSERT(col1,col2,…)所有权限 ALL PRIVILEGES 或 ALL 授权 授权：GRANT 1234567GRANT SELECT (col1), INSERT (col1,col2) ON mydb.mytbl TO &#x27;someuser&#x27;@&#x27;somehost&#x27;;GRANT ALL ON wordpress.* TO wordpress@&#x27;10.0.0.%&#x27; ;GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;10.0.0.%&#x27; WITH GRANT OPTION;#创建用户和授权同时执行的方式在MySQL8.0取消了GRANT ALL ON wordpress.* TO wordpress@&#x27;192.168.8.%&#x27; IDENTIFIED BY &#x27;magedu&#x27;;GRANT ALL PRIVILEGES ON *.* TO &#x27;root&#x27;@&#x27;192.168.8.%&#x27; IDENTIFIED BY &#x27;magedu&#x27;WITH GRANT OPTION; 取消授权 取消授权：REVOKE 1REVOKE DELETE ON *.* FROM &#x27;testuser&#x27;@&#x27;172.16.0.%&#x27;; 查看指定用户获得的授权 123Help SHOW GRANTSSHOW GRANTS FOR &#x27;user&#x27;@&#x27;host&#x27;;SHOW GRANTS FOR CURRENT_USER[()]; 注意：MariaDB服务进程启动时会读取mysql库中所有授权表至内存(1) GRANT或REVOKE等执行权限操作会保存于系统表中，MariaDB的服务进程通常会自动重读授权表，使之生效(2) 对于不能够或不能及时重读授权表的命令，可手动让MariaDB的服务进程重读授权表：mysql&gt; FLUSH PRIVILEGES; MyISAM 存储引擎MyISAM 引擎特点 不支持事务 表级锁定 读写相互阻塞，写入不能读，读时不能写 只缓存索引 不支持外键约束 不支持聚簇索引 读取数据较快，占用资源较少 不支持MVCC（多版本并发控制机制）高并发 崩溃恢复性较差 MySQL5.5.5 前默认的数据库引擎 MyISAM 存储引擎适用场景 只读（或者写较少） 表较小（可以接受长时间进行修复操作） MyISAM 引擎文件 tbl_name.frm 表格式定义 tbl_name.MYD 数据文件 tbl_name.MYI 索引文件 InnoDB 引擎InnoDB引擎特点 行级锁 支持事务，适合处理大量短期事务 读写阻塞与事务隔离级别相关 可缓存数据和索引 支持聚簇索引 崩溃恢复性更好 支持MVCC高并发 从MySQL5.5后支持全文索引 从MySQL5.5.5开始为默认的数据库引擎 管理存储引擎查看mysql支持的存储引擎 1show engines; 查看当前默认的存储引擎 1show variables like &#x27;%storage_engine%&#x27;; 设置默认的存储引擎 123vim /etc/my.cnf[mysqld]default_storage_engine= InnoDB 查看库中所有表使用的存储引擎 1show table status from db_name; 查看库中指定表的存储引擎 12show table status like &#x27;tb_name&#x27;;show create table tb_name; 设置表的存储引擎： 12CREATE TABLE tb_name(... ) ENGINE=InnoDB;ALTER TABLE tb_name ENGINE=InnoDB; 实战案例：数据库冷备份和热备份MySQL8.0 冷备份： 12345678910备份过程# 停止数据库systemctl stop mysql# rsync可以保留文件属性[root@centos8 ~]#rsync -a /var/lib/mysql 10.0.0.28:/data/#如果配置及二进制文件相关有特殊设置也需要备份#还原[root@centos8 ~]#yum -y install mysql-server[root@centos8 ~]#cp -a /data/mysql/* /var/lib/mysql/[root@centos8 ~]#systemctl start mysqld mysqldump备份工具mysqldump 说明逻辑备份工具：mysqldump, mydumper, phpMyAdminSchema和数据存储在一起、巨大的SQL语句、单个巨大的备份文件mysqldump是MySQL的客户端命令，通过mysql协议连接至mysql服务器进行备份命令格式: 1234mysqldump [OPTIONS] database [tables] #支持指定数据库和指定多表的备份，但数据库本身定义不备份mysqldump [OPTIONS] -B DB1 [DB2 DB3...] #支持指定数据库备份，包含数据库本身定义也会备份mysqldump [OPTIONS] -A [OPTIONS] #备份所有数据库，包含数据库本身定义也会备份 mysqldump参考： 1https://dev.mysql.com/doc/refman/5.7/en/mysqldump.html mysqldump 常见通用选项： 123456789101112131415161718192021222324252627-u, --user=name User for login if not current user-p, --password[=name] Password to use when connecting to server-A, --all-databases #备份所有数据库，含create database-B, --databases db_name… #指定备份的数据库，包括create database语句-E, --events：#备份相关的所有event scheduler-R, --routines：#备份所有存储过程和自定义函数--triggers：#备份表相关触发器，默认启用,用--skip-triggers，不备份触发器--default-character-set=utf8 #指定字符集--master-data[=#]：#注意：MySQL8.0.26版以后，此选项变为--source-data#此选项须启用二进制日志#1：所备份的数据之前加一条记录为CHANGE MASTER TO语句，非注释，不指定#，默认为1，适合于主从复制多机使用#2：记录为被注释的#CHANGE MASTER TO语句，适合于单机使用,适用于备份还原#此选项会自动关闭--lock-tables功能，自动打开-x | --lock-all-tables功能（除非开启--single-transaction）-F, --flush-logs #备份前滚动日志，锁定表完成后，执行flush logs命令,生成新的二进制日志文件，配合-A 或 -B 选项时，会导致刷新多次数据库。建议在同一时刻执行转储和日志刷新，可通过和--single-transaction或-x，--master-data 一起使用实现，此时只刷新一次二进制日志--compact #去掉注释，适合调试，节约备份占用的空间,生产不使用-d, --no-data #只备份表结构,不备份数据,即只备份create table-t, --no-create-info #只备份数据,不备份表结构,即不备份create table-n,--no-create-db #不备份create database，可被-A或-B覆盖--flush-privileges #备份mysql或相关时需要使用-f, --force #忽略SQL错误，继续执行--hex-blob #使用十六进制符号转储二进制列，当有包括BINARY,VARBINARY,BLOB，BIT的数据类型的列时使用，避免乱码-q, --quick #不缓存查询，直接输出，加快备份速度 mysqldump的MyISAM存储引擎相关的备份选项：MyISAM不支持事务，只能支持温备；不支持热备，所以必须先锁定要备份的库，而后启动备份操作 12345-x,--lock-all-tables #加全局读锁，锁定所有库的所有表，同时加--single-transaction或--lock-tables选项会关闭此选项功能，注意：数据量大时，可能会导致长时间无法并发访问数据库-l,--lock-tables #对于需要备份的每个数据库，在启动备份之前分别锁定其所有表，默认为on,--skip-lock-tables选项可禁用,对备份MyISAM的多个库,可能会造成数据不一致#注：以上选项对InnoDB表一样生效，实现温备，但不推荐使用 mysqldump的InnoDB存储引擎相关的备份选项：InnoDB 存储引擎支持事务,可以利用事务的相应的隔离级别,实现热备，也可以实现温备但不建议用 12345678--single-transaction#此选项Innodb中推荐使用，不适用MyISAM，此选项会开始备份前，先执行START TRANSACTION指令开启事务#此选项通过在单个事务中转储所有表来创建一致的快照。 仅适用于存储在支持多版本控制的存储引擎中的表（目前只有InnoDB可以）; 转储不保证与其他存储引擎保持一致。 在进行单事务转储时，要确保有效的转储文件（正确的表内容和二进制日志位置），没有其他连接应该使用以下语句：ALTER TABLE，DROP TABLE，RENAME TABLE，TRUNCATE TABLE,此选项和--lock-tables（此选项隐含提交挂起的事务）选项是相互排斥,备份大型表时，建议将--single-transaction选项和--quick结合一起使用 生产环境实战备份策略InnoDB建议备份策略 123mysqldump -uroot -p -A -F -E -R --triggers --single-transaction --master-data=1--flush-privileges --default-character-set=utf8 --hex-blob&gt;$&#123;BACKUP&#125;/fullbak_$&#123;BACKUP_TIME&#125;.sql MyISAM建议备份策略 123mysqldump -uroot -p -A -F -E -R -x --master-data=1 --flush-privileges --triggers --default-character-set=utf8 --hex-blob&gt;$&#123;BACKUP&#125;/fullbak_$&#123;BACKUP_TIME&#125;.sql mysqldump 备份还原实战案例实战案例：特定数据库的备份脚本系统：centos8.5 mysql:8.0 123456789101112131415#!/bin/bashTIME=`date +%F_%H-%M-%S`# 备份目录DIR=/mysql_backup# 备份数据库DB=hellodb# 数据库密码PASSWD=123456# 判断备份数据库目录是否存在[ -d $DIR ] || mkdir $DIR# 备份mysqldump -uroot -p&quot;$PASSWD&quot; -F -E -R --triggers --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip &gt; $&#123;DIR&#125;/$&#123;DB&#125;_$&#123;TIME&#125;.sql.gz 实战案例：分库备份的实战脚本 系统：centos8.5 MySQL版本：8.0 12345678#!/bin/bashTIME=`date +%F_%H-%M-%S`DIR=/backupPASS=123456[ -d &quot;$DIR&quot; ] || mkdir $DIRfor DB in `mysql -uroot -p&quot;$PASS&quot; -e &#x27;show databases&#x27; | grep -Ev &quot;^Database|.*schema$&quot;`;do mysqldump -uroot -p&quot;$PASS&quot; -F --single-transaction --master-data=2 --default-character-set=utf8mb4 -q -B $DB | gzip &gt; $&#123;DIR&#125;/$&#123;DB&#125;_$&#123;TIME&#125;.sql.gzdone 实战案例：完全备份和还原1234567891011121314#开启二进制日志[root@centos8 ~]#vim /etc/my.cnf.d/mariadb-server.cnf[mysqld]log-bin#备份[root@centos8 ~]#mysqldump -uroot -pmagedu -A -F --single-transaction --master-data=2 |gzip &gt; /backup/all-`date +%F`.sql.gz#还原[root@centos8 backup]#dnf install mariadb-server[root@centos8 backup]#gzip -d all-2019-11-27.sql.gz[root@centos8 ~]#mysqlMariaDB [(none)]&gt; set sql_log_bin=off;MariaDB [(none)]&gt; source /backup/all-2019-11-27.sqlMariaDB [(none)]&gt; set sql_log_bin=on; 实战案例：恢复误删除的表案例说明：每天2：30做完全备份，早上10：00误删除了表students，10：10才发现故障，现需要将数据库还原到10：10的状态，且恢复被删除的students表 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#查看数据库是否开启二进制mysql&gt; select @@log_bin;+-----------+| @@log_bin |+-----------+| 1 |+-----------+1 row in set (0.01 sec)mysql&gt; select @@sql_log_bin;+---------------+| @@sql_log_bin |+---------------+| 1 |+---------------+1 row in set (0.01 sec)mysql&gt; # log_bin、sql_log_bin的值为1说明已经开启二进制日志# 查看当前二进制文件在什么位置mysql&gt; show master logs;+------------------+-----------+-----------+| Log_name | File_size | Encrypted |+------------------+-----------+-----------+| mysql-bin.000001 | 204 | No || mysql-bin.000002 | 157 | No |+------------------+-----------+-----------+2 rows in set (0.01 sec)mysql&gt; # 备份的时候开启刷新二进制日志，会生成新的二进制的日志#完全备份[root@centos7 ~]# mysqldump -uroot -p123456 -A -F --single-transaction --master-data=2 | gzip &gt; /backup/all_`date +%F`.sql.gz# 完全备份后进行数据更新mysql&gt; insert students (name,age,gender) values(&#x27;jack&#x27;,22,&#x27;M&#x27;);Query OK, 1 row affected (0.01 sec)mysql&gt; insert students (name,age,gender) values(&#x27;rose&#x27;,20,&#x27;f&#x27;);Query OK, 1 row affected (0.01 sec)# 误删除学生表mysql&gt; drop table students;Query OK, 0 rows affected (0.07 sec)mysql&gt; # 后续其他表继续更新mysql&gt; insert teachers (name,age,gender)values(&#x27;wang&#x27;,30,&#x27;M&#x27;);Query OK, 1 row affected (0.01 sec)mysql&gt; mysql&gt; insert teachers (name,age,gender)values(&#x27;mage&#x27;,28,&#x27;M&#x27;);Query OK, 1 row affected (0.05 sec)mysql&gt; # 停止数据库访问# 备份从完全备份后的二进制日志[root@centos7 ~]# mysqlbinlog --start-position=157 /data/mysql/mysql-bin.000003 &gt; /backup/inc.sql# 找到误删除的语句，从备份中删除此语句#DROP TABLE `students` /* generated by server */#利用完全备份和修改过的二进制日志进行还原[root@centos8 ~]#mysql -uroot -pmysql&gt; set sql_log_bin=0;mysql&gt; source /backup/allbackup_2019-11-27_10:20:08.sql;mysql&gt; source /backup/inc.sqlmysql&gt; set sql_log_bin=1;","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://snippet.itshare.work/categories/MySQL/"}],"tags":[{"name":"MySQL基础","slug":"MySQL基础","permalink":"http://snippet.itshare.work/tags/MySQL%E5%9F%BA%E7%A1%80/"}],"keywords":[{"name":"MySQL","slug":"MySQL","permalink":"http://snippet.itshare.work/categories/MySQL/"}]},{"title":"Linux防火墙","slug":"FireWall","date":"2022-09-25T13:28:11.000Z","updated":"2022-12-16T14:57:40.222Z","comments":true,"path":"2022/09/25/FireWall/","link":"","permalink":"http://snippet.itshare.work/2022/09/25/FireWall/","excerpt":"firewall一般指防火墙。 防火墙（英语：Firewall）技术是通过有机结合各类用于安全管理与筛选的软件和硬件设备，帮助计算机网络于其内、外网之间构建一道相对隔绝的保护屏障，以保护用户资料与信息安全性的一种技术。","text":"firewall一般指防火墙。 防火墙（英语：Firewall）技术是通过有机结合各类用于安全管理与筛选的软件和硬件设备，帮助计算机网络于其内、外网之间构建一道相对隔绝的保护屏障，以保护用户资料与信息安全性的一种技术。 防火墙基本认识Netfilter Linux防火墙是由Netfilter组件提供的，Netfilter工作在内核空间，集成在linux内核中。Netfilter 是Linux 2.4.x之后新一代的Linux防火墙机制，是linux内核的一个子系统。Netfilter采用模块化设计，具有良好的可扩充性，提供扩展各种网络服务的结构化底层框架。Netfilter与IP协议栈是无缝契合，并允许对数据报进行过滤、地址转换、处理等操作。 Netfilter官网文档 123456789101112[root@centos7 ~]# grep -m 10 NETFILTER /boot/config-3.10.0-1160.el7.x86_64 CONFIG_NETFILTER=y# CONFIG_NETFILTER_DEBUG is not setCONFIG_NETFILTER_ADVANCED=yCONFIG_BRIDGE_NETFILTER=mCONFIG_NETFILTER_NETLINK=mCONFIG_NETFILTER_NETLINK_ACCT=mCONFIG_NETFILTER_NETLINK_QUEUE=mCONFIG_NETFILTER_NETLINK_LOG=mCONFIG_NETFILTER_NETLINK_QUEUE_CT=yCONFIG_NETFILTER_SYNPROXY=m[root@centos7 ~]# 防火墙工具介绍iptables由软件包iptables提供的命令行工具，工作在用户空间，用来编写规则，写好的规则被送往netfilter，告诉内核如何去处理信息包。 查看iptables信息 1234567891011121314151617181920212223[root@centos7 ~]# rpm -qi iptablesName : iptablesVersion : 1.4.21Release : 35.el7Architecture: x86_64Install Date: Sat 17 Sep 2022 10:31:09 AM CSTGroup : System Environment/BaseSize : 1556976License : GPLv2Signature : RSA/SHA256, Thu 15 Oct 2020 02:51:02 AM CST, Key ID 24c6a8a7f4a80eb5Source RPM : iptables-1.4.21-35.el7.src.rpmBuild Date : Fri 02 Oct 2020 12:52:54 AM CSTBuild Host : x86-01.bsys.centos.orgRelocations : (not relocatable)Packager : CentOS BuildSystem &lt;http://bugs.centos.org&gt;Vendor : CentOSURL : http://www.netfilter.org/Summary : Tools for managing Linux kernel packet filtering capabilitiesDescription :The iptables utility controls the network packet filtering code in theLinux kernel. If you need to set up firewalls and/or IP masquerading,you should install this package.[root@centos7 ~]# 范例：安装iptables的server包 1234567891011121314151617181920# 安装dnf[root@centos7 ~]# yum install dnf# 安装iptables-services[root@centos7 ~]# dnf -y install iptables-services# 查看iptables-services文件列表[root@centos7 ~]# rpm -ql iptables-services/etc/sysconfig/ip6tables/etc/sysconfig/iptables/usr/lib/systemd/system/ip6tables.service/usr/lib/systemd/system/iptables.service/usr/libexec/initscripts/legacy-actions/ip6tables/usr/libexec/initscripts/legacy-actions/ip6tables/panic/usr/libexec/initscripts/legacy-actions/ip6tables/save/usr/libexec/initscripts/legacy-actions/iptables/usr/libexec/initscripts/legacy-actions/iptables/panic/usr/libexec/initscripts/legacy-actions/iptables/save/usr/libexec/iptables/usr/libexec/iptables/ip6tables.init/usr/libexec/iptables/iptables.init[root@centos7 ~]# firewalld从CentOS 7 版开始引入了新的前端管理工具软件包： firewalld firewalld-config 管理工具： firewall-cmd 命令行工具 firewall-config 图形工作 nftables它重用了netfilter框架的许多部分，例如连接跟踪和NAT功能。它还保留了命名法和基本iptables设计的几个部分，例如表，链和规则。就像iptables一样，表充当链的容器，并且链包含单独的规则，这些规则可以执行操作，例如丢弃数据包，移至下一个规则或跳至新链。从用户的角度来看，nftables添加了一个名为nft的新工具，该工具替代了iptables，arptables和ebtables中的所有其他工具。从体系结构的角度来看，它还替换了内核中处理数据包过滤规则集运行时评估的那些部分。 查看软件信息 12345678910111213141516171819202122[root@centos7 ~]# rpm -qi nftablesName : nftablesEpoch : 1Version : 0.8Release : 14.el7Architecture: x86_64Install Date: Wed 28 Sep 2022 11:36:55 AM CSTGroup : UnspecifiedSize : 500068License : GPLv2Signature : RSA/SHA256, Fri 23 Aug 2019 05:36:19 AM CST, Key ID 24c6a8a7f4a80eb5Source RPM : nftables-0.8-14.el7.src.rpmBuild Date : Fri 09 Aug 2019 09:13:15 AM CSTBuild Host : x86-01.bsys.centos.orgRelocations : (not relocatable)Packager : CentOS BuildSystem &lt;http://bugs.centos.org&gt;Vendor : CentOSURL : http://netfilter.org/projects/nftables/Summary : Netfilter Tables userspace utillitesDescription :Netfilter Tables userspace utilities.[root@centos7 ~]# 范例：centos8支持三种防火墙服务 123456789101112131415[root@rocky ~]# systemctl status iptables.service● iptables.service - IPv4 firewall with iptables Loaded: loaded (/usr/lib/systemd/system/iptables.service; disabled; vendor preset: disabled) Active: inactive (dead)[root@rocky ~]# systemctl status firewalld.service● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1)[root@rocky ~]# systemctl status nftables.service● nftables.service - Netfilter Tables Loaded: loaded (/usr/lib/systemd/system/nftables.service; disabled; vendor preset: disabled) Active: inactive (dead) Docs: man:nft(8)[root@rocky ~]# netfilter中五个勾子函数和报文流向Netfilter在内核中选取五个位置放了五个hook(勾子) function(INPUT、OUTPUT、FORWARD、PREROUTING、POSTROUTING)，而这五个hook function向用户开放，用户可以通过一个命令工具（iptables）向其写入规则。 由信息过滤表（table）组成，包含控制IP包处理的规则集（rules），规则被分组放在链（chain）上。 提示：从 Linux kernel 4.2 版以后，Netfilter 在prerouting 前加了一个 ingress 勾子函数。可以使用这个新的入口挂钩来过滤来自第2层的流量，这个新挂钩比预路由要早，基本上是 tc 命令（流量控制工具）的替代品。三种报文流向 流入本机：PREROUTING –&gt; INPUT–&gt;用户空间进程 流出本机：用户空间进程 –&gt;OUTPUT–&gt; POSTROUTING 转发：PREROUTING –&gt; FORWARD –&gt; POSTROUTING iptables组成iptables由五个表table和五个链chain以及一些规则组成 链 chain： 内置链：每个内置链对应于一个钩子函数 自定义链：用于对内置链进行扩展或补充，可实现更灵活的规则组织管理机制；只有Hook钩子调用自定义链时，才生效 五个内置链chain: 1INPUT,OUTPUT,FORWARD,PREROUTING,POSTROUTING 五个表：filter、nat、mangle、raw、security filter：过滤规则表，根据预定义的规则过滤符合条件的数据包,默认表 nat：network address translation 地址转换规则表 mangle：修改数据标记位规则表 raw：关闭启用的连接跟踪机制，加快封包穿越防火墙速度 security：用于强制访问控制（MAC）网络规则，由Linux安全模块（如SELinux）实现优先级由高到低的顺序为： 优先级由高到低的顺序为 1security --&gt;raw--&gt;mangle--&gt;nat--&gt;filter 表和链对应关系 数据包过滤匹配流程 内核中数据包的传输过程 当一个数据包进入网卡时，数据包首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去 如果数据包是进入本机的，数据包就会沿着图向下移动，到达INPUT链。数据包到达INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包经过OUTPUT链，然后到达POSTROUTING链输出 如果数据包是要转发出去的，且内核允许转发，数据包就会向右移动，经过FORWARD链，然后到达POSTROUTING链输出 范例 12345678910111213141516[root@rocky ~]# iptables -vnL -t filter Chain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 168 10248 ACCEPT all -- * * 0.0.0.0/0 0.0.0.0/0 state RELATED,ESTABLISHED 0 0 ACCEPT icmp -- * * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT all -- lo * 0.0.0.0/0 0.0.0.0/0 0 0 ACCEPT tcp -- * * 0.0.0.0/0 0.0.0.0/0 state NEW tcp dpt:22 0 0 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 0 0 REJECT all -- * * 0.0.0.0/0 0.0.0.0/0 reject-with icmp-host-prohibitedChain OUTPUT (policy ACCEPT 101 packets, 11034 bytes) pkts bytes target prot opt in out source destination [root@rocky ~]# CentOS 6 nat表不支持INPUT链 iptablesiptables规则说明iptables规则组成规则rule：根据规则的匹配条件尝试匹配报文，对匹配成功的报文根据规则定义的处理动作作出处理，规则在链接上的次序即为其检查时的生效次序匹配条件：默认为与条件，同时满足基本匹配：IP，端口，TCP的Flags（SYN,ACK等）扩展匹配：通过复杂高级功能匹配处理动作：称为target，跳转目标 内建处理动作：ACCEPT,DROP,REJECT,SNAT,DNAT,MASQUERADE,MARK,LOG… 自定义处理动作：自定义chain，利用分类管理复杂情形 规则要添加在链上，才生效；添加在自定义链上不会自动生效白名单:只有指定的特定主机可以访问,其它全拒绝黑名单:只有指定的特定主机拒绝访问,其它全允许,默认方式 iptables规则添加时考量点 要实现哪种功能：判断添加在哪张表上 报文流经的路径：判断添加在哪个链上 报文的流向：判断源和目的 匹配规则：业务需要 iptables用法说明帮助：man 8 iptables格式： 1iptables [-t table] &#123;-A|-C|-D&#125; chain rule-specification 范例：filter表中INPUT规则 iptables命令格式详解 12iptables [-t table] SUBCOMMAND chain [-m matchname [per-match-options]]-j targetname [per-target-options] 1、-t table：指定表raw, mangle, nat, [filter]默认2、SUBCOMMAND：子命令链管理类： 1234-N：new, 自定义一条新的规则链-E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除-X：delete，删除自定义的空的规则链-P：Policy，设置默认策略；对filter表中的链而言，其默认策略有：ACCEPT：接受, DROP：丢弃 范例 12# 定义新的规则链[root@rocky ~]# iptables -N web_chain","categories":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"DNS服务","slug":"DNS","date":"2022-09-22T14:01:44.000Z","updated":"2022-12-16T14:57:34.485Z","comments":true,"path":"2022/09/22/DNS/","link":"","permalink":"http://snippet.itshare.work/2022/09/22/DNS/","excerpt":"DNS一般指域名系统。 域名系统（英文：Domain Name System，缩写：DNS）是互联网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用UDP端口53","text":"DNS一般指域名系统。 域名系统（英文：Domain Name System，缩写：DNS）是互联网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用UDP端口53 名字解析介绍和DNSDNS服务工作原理 DNS查询类型 递归查询：是指DNS服务器在收到用户发起的请求时，必须向用户返回一个准确的查询结果。如果DNS服务器本地没有存储与之对应的信息，则该服务器需要询问其他服务器，并将返回的查询结构提交给用户。一般客户机和本地DNS服务器之间属于递归查询，即当客户机向DNS服务器发出请求后,若DNS服务器本身不能解析，则会向另外的DNS服务器发出查询请求，得到最终的肯定或否定的结果后转交给客户机。此查询的源和目标保持不变,为了查询结果只需要发起一次查询递归算法:客户端向LocalDNS发起域名查询–&gt;localDNS不知道域名对应的IP–&gt;但它知道谁知道-&gt;他代为帮客户端去查找–&gt;最后再返回最终结果 迭代查询：是指DNS服务器在收到用户发起的请求时，并不直接回复查询结果，而是告诉另一台DNS服务器的地址，用户再向这台DNS服务器提交请求，这样依次反复，直到返回查询结果。一般情况下(有例外)本地的DNS服务器向其它DNS服务器的查询属于迭代查询,如：若对方不能返回权威的结果，则它会向下一个DNS服务器(参考前一个DNS服务器返回的结果)再次发起进行查询，直到返回查询的结果为止。此查询的源不变,但查询的目标不断变化,为查询结果一般需要发起多次查询 迭代算法︰客户端向LocalDNS发起域名查询–&gt;localDNS不知道域名对应的IP–&gt;但它知道谁知道并推荐客户端应该找谁–&gt;客户端自己去找它 DNS缓存:DNS缓存是将解析数据存储在靠近发起请求的客户端的位置，也可以说DNS数据是可以缓存在任意位置，最终目的是以此减少递归查询过程，可以更快的让用户获得请求结果。 解析类型 FQDN –&gt; IP 正向解析 IP –&gt; FQDN 反向解析注意：正反向解析是两个不同的名称空间，是两棵不同的解析树 完整查询流程12Client --&gt;hosts文件 --&gt; Client DNS Service Local Cache --&gt; DNS Server (recursion递归) --&gt; DNS Server Cache --&gt;DNS iteration(迭代) --&gt; 根--&gt; 顶级域名DNS--&gt;二级域名DNS… DNS服务相关概念和技术各种资源记录区域解析库：由众多资源记录RR(Resource Record)组成记录类型：A, AAAA, PTR, SOA, NS, CNAME, MX SOA：Start Of Authority，起始授权记录；一个区域解析库有且仅能有一个SOA记录，必须位于解析库的第一条记录 A：internet Address，作用，FQDN –&gt; IP AAAA：FQDN –&gt; IPv6 PTR：PoinTeR，IP –&gt; FQDN NS：Name Server，专用于标明当前区域的DNS服务器 CNAME ： Canonical Name，别名记录 MX：Mail eXchanger，邮件交换器 TXT：对域名进行标识和说明的一种方式，一般做验证记录时会使用此项，如：SPF（反垃圾邮件）记录，https验证等，如下示例： 1_dnsauth TXT 2012011200000051qgs69bwoh4h6nht4n1h0lr038x SOA记录name: 当前区域的名字，例如”magedu.org.”value: 有多部分组成注意： 当前区域的主DNS服务器的FQDN，也可以使用当前区域的名字，只是注释功能，可以不需要配置对应的NS记录和A记录 当前区域管理员的邮箱地址；但地址中不能使用@符号，一般用.替换，例如：admin.magedu.org 主从服务区域传输相关定义以及否定的答案的统一的TTL 范例 1234567magedu.org. 86400 IN SOA ns.magedu.org. nsadmin.magedu.org. (2015042201 ;序列号2H ;刷新时间10M ;重试时间1W ;过期时间1D ;否定答案的TTL值) NS记录name: 当前区域的名字value: 当前区域的某DNS服务器的名字，例如: ns.magedu.org.注意： 相邻的两个资源记录的name相同时，后续的可省略 对NS记录而言，任何一个ns记录后面的服务器名字，都应该在后续有一个A记录 一个区域可以有多个NS记录范例： 12magedu.org. IN NS ns1.magedu.org.magedu.org. IN NS ns2.magedu.org. MX记录name: 当前区域的名字value: 当前区域的某邮件服务器(smtp服务器)的主机名注意： 一个区域内，MX记录可有多个；但每个记录的value之前应该有一个数字(0-99)，表示此服务器的优先级；数字越小优先级越高 对MX记录而言，任何一个MX记录后面的服务器名字，都应该在后续有一个A记录范例：1234magedu.org. IN MX 10 mx1.magedu.org.IN MX 20 mx2.magedu.org.mx1 A 10.0.0.100mx2 A 10.0.0.200 A记录name: 某主机的FQDN，例如：www.magedu.org.value: 主机名对应主机的IP地址避免用户写错名称时给错误答案，可通过泛域名解析进行解析至某特定地址范例： 12345678www.magedu.org. IN A 1.1.1.1www.magedu.org. IN A 2.2.2.2mx1.magedu.org. IN A 3.3.3.3mx2.magedu.org. IN A 4.4.4.4$GENERATE 1-254 HOST$ IN A 1.2.3.$*.magedu.org. IN A 5.5.5.5magedu.org. IN A 6.6.6.6#注意：如果有和DNS的IP相同的多个同名的A记录，优先返回DNS的本机IP AAAA记录12name: FQDN value: IPv6 PTR记录123name: IP，有特定格式，把IP地址反过来写，1.2.3.4，要写作4.3.2.1；而有特定后缀：in-addr.arpa.，所以完整写法为：4.3.2.1.in-addr.arpa.value: FQDN 注意：网络地址及后缀可省略；主机地址依然需要反着写例如： 1234.3.2.1.in-addr.arpa. IN PTR www.magedu.org.#如1.2.3为网络地址，可简写成：4 IN PTR www.magedu.org. CNAME别名记录12name: 别名的FQDNvalue: 真正名字的FQDN 例如 1www.magedu.org. IN CNAME websrv.magedu.org. DNS软件bindDNS服务器软件：bind，powerdns，dnsmasq，unbound，coredns bind相关程序包yum list all bind* bind：服务器bind-utils: 客户端bind-libs：相关库,依赖关系自动安装bind-chroot: 安全包，将dns相关文件放至 &#x2F;var&#x2F;named&#x2F;chroot&#x2F; 范例：安装bind软件 12[root@centos8 ~]#dnf -y install bind bind-utils[root@ubuntu2004 ~]#apt -y install bind9 bind9-utils bind包相关文件BIND主程序：&#x2F;usr&#x2F;sbin&#x2F;named服务脚本和Unit名称：&#x2F;etc&#x2F;rc.d&#x2F;init.d&#x2F;named，&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;named.service主配置文件：&#x2F;etc&#x2F;named.conf, &#x2F;etc&#x2F;named.rfc1912.zones, &#x2F;etc&#x2F;rndc.key管理工具：&#x2F;usr&#x2F;sbin&#x2F;rndc：remote name domain controller，默认与bind安装在同一主机，且只能通过127.0.0.1连接named进程，提供辅助性的管理功能；953&#x2F;tcp解析库文件：&#x2F;var&#x2F;named&#x2F;ZONE_NAME.ZONE注意：(1) 一台物理服务器可同时为多个区域提供解析(2) 必须要有根区域文件；named.ca(3) 应该有两个（如果包括ipv6的，应该更多）实现localhost和本地回环地址的解析库 主配置文件 全局配置：options {}; 日志子系统配置：logging {}; 区域定义：本机能够为哪些zone进行解析，就要定义哪些zonezone “ZONE_NAME” IN {};注意： 任何服务程序如果期望其能够通过网络被其它主机访问，至少应该监听在一个能与外部主机通信的IP地址上 缓存名称服务器的配置：监听外部地址即可 dnssec: 建议关闭dnssec，设为no","categories":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"时间同步机制和架构","slug":"TimeSynchronization","date":"2022-09-17T10:32:45.000Z","updated":"2022-12-16T14:59:58.756Z","comments":true,"path":"2022/09/17/TimeSynchronization/","link":"","permalink":"http://snippet.itshare.work/2022/09/17/TimeSynchronization/","excerpt":"多主机协作工作时，各个主机的时间同步很重要，时间不一致会造成很多重要应用的故障，如：加密协议，日志，集群等， 利用NTP（Network Time Protocol） 协议使网络中的各个计算机时间达到同步。目前NTP协议属于运维基础架构中必备的基本服务之一","text":"多主机协作工作时，各个主机的时间同步很重要，时间不一致会造成很多重要应用的故障，如：加密协议，日志，集群等， 利用NTP（Network Time Protocol） 协议使网络中的各个计算机时间达到同步。目前NTP协议属于运维基础架构中必备的基本服务之一 时间同步服务时间同步软件 ntpdate chrony ntp: 将系统时钟和世界协调时钟UTC同步，精度在局域网内可达0.1ms，在互联网上绝大多数的地方精度可以达到1-50ms项目官网：http://www.ntp.org 范例：ubuntu同步时间 安装ntpdate 1apt install ntpdate 同步时间 12# ntp.aliyun.com阿里云时间同步服务器地址ntpdate ntp.aliyun.com 扩展： 1234567891011阿里云公共NTP服务器Unix/linux类：ntp.aliyun.com，ntp1-7.aliyun.comwindows类： time.pool.aliyun.com腾讯公共NTPtime1-5.cloud.tencent.com大学ntp服务s1a.time.edu.cn 北京邮电大学s1b.time.edu.cn 清华大学s1c.time.edu.cn 北京大学国家授时中心服务器：210.72.145.44美国标准技术院: time.nist.gov 注意：CentOS 8上已经没有ntpdate命令，因此该种时间同步方式不建议使用 **chrony：** 实现NTP协议的的自由软件。可使系统时钟与NTP服务器，参考时钟（例如GPS接收器）以及使用手表 和键盘的手动输入进行同步。还可以作为NTPv4（RFC 5905）服务器和对等体运行，为网络中的计算机 提供时间服务。设计用于在各种条件下良好运行，包括间歇性和高度拥挤的网络连接，温度变化（计算 机时钟对温度敏感），以及不能连续运行或在虚拟机上运行的系统。 通过Internet同步的两台机器之间的典型精度在几毫秒之内，在LAN上，精度通常为几十微秒。利用硬 件时间戳或硬件参考时钟，可实现亚微秒的精度 chronychrony介绍chrony 的优势： 更快的同步只需要数分钟而非数小时时间，从而最大程度减少了时间和频率误差，对于并非全天24 小时运行的虚拟计算机而言非常有用 能够更好地响应时钟频率的快速变化，对于具备不稳定时钟的虚拟机或导致时钟频率发生变化的节能技术而言非常有用 在初始同步后，它不会停止时钟，以防对需要系统时间保持单调的应用程序造成影响 在应对临时非对称延迟时（例如，在大规模下载造成链接饱和时）提供了更好的稳定性 无需对服务器进行定期轮询，因此具备间歇性网络连接的系统仍然可以快速同步时钟chrony官网：https://chrony.tuxfamily.orgchrony官方文档：https://chrony.tuxfamily.org/documentation.html chrony 文件组成包：chrony两个主要程序：chronyd和chronyc chronyd：后台运行的守护进程，用于调整内核中运行的系统时钟和时钟服务器同步。它确定计算机增减时间的比率，并对此进行补偿 chronyc：命令行用户工具，用于监控性能并进行多样化的配置。它可以在chronyd实例控制的计算机上工作，也可在一台不同的远程计算机上工作服务unit 文件： &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;chronyd.service监听端口： 服务端: 123&#x2F;udp,客户端: 323&#x2F;udp配置文件： &#x2F;etc&#x2F;chrony.conf 配置文件chrony.conf官网文档: https://chrony.tuxfamily.org/doc/3.5/chrony.conf.html 123456789101112131415server #可用于时钟服务器，iburst 选项当服务器可达时，发送一个八个数据包而不是通常的一个数据包。 包间隔通常为2秒,可加快初始同步速度pool #该指令的语法与server 指令的语法相似，不同之处在于它用于指定NTP服务器池而不是单个NTP服务器。池名称应解析为随时间可能会变化的多个地址driftfile #根据实际时间计算出计算机增减时间的比率，将它记录到一个文件中，会在重启后为系统时钟作出补偿rtcsync #启用内核模式，系统时间每11分钟会拷贝到实时时钟（RTC）allow / deny #指定一台主机、子网，或者网络以允许或拒绝访问本服务器cmdallow / cmddeny #可以指定哪台主机可以通过chronyd使用控制命令bindcmdaddress #允许chronyd监听哪个接口来接收由chronyc执行的命令makestep # 通常chronyd将根据需求通过减慢或加速时钟，使得系统逐步纠正所有时间偏差。在某些特定情况下，系统时钟可能会漂移过快，导致该调整过程消耗很长的时间来纠正系统时钟。该指令强制chronyd在调整期大于某个阀值时调整系统时钟local stratum 10 #即使server指令中时间服务器不可用，也允许将本地时间作为标准时间授时给其它客户端 NTP 客户端工具chronyc 可以运行在交互式和非交互式两种方式，支持以下子命令 12345678910help 命令可以查看更多chronyc的交互命令accheck 检查是否对特定主机可访问当前服务器activity 显示有多少NTP源在线/离线sources [-v] 显示当前时间源的同步信息sourcestats [-v]显示当前时间源的同步统计信息add server 手动添加一台新的NTP服务器clients 报告已访问本服务器的客户端列表delete 手动移除NTP服务器或对等服务器settime 手动设置守护进程时间tracking 显示系统时间信息 时间工具 timedatectl 时间和时区管理 查看日期时间和时区以及NTP状态 123456789root@ubuntu2004:~# timedatectl Local time: Sat 2022-09-17 11:49:00 UTC Universal time: Sat 2022-09-17 11:49:00 UTC RTC time: Sat 2022-09-17 11:49:00 Time zone: Etc/UTC (UTC, +0000) System clock synchronized: yes NTP service: active RTC in local TZ: no root@ubuntu2004:~# 查看时区列表 1234567891011121314151617181920root@ubuntu2004:~# root@ubuntu2004:~# timedatectl list-timezonesAfrica/AbidjanAfrica/AccraAfrica/Addis_AbabaAfrica/AlgiersAfrica/AsmaraAfrica/AsmeraAfrica/BamakoAfrica/BanguiAfrica/BanjulAfrica/BissauAfrica/BlantyreAfrica/BrazzavilleAfrica/BujumburaAfrica/CairoAfrica/CasablancaAfrica/Ceuta.................. 修改时区 123# 修改时区亚洲上海root@ubuntu2004:~# timedatectl set-timezone Asia/Shanghairoot@ubuntu2004:~# 修改时区方式2 1234567#修改时区root@ubuntu2004:~# rm -f /etc/localtimeroot@ubuntu2004:~# ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime#修改日期时间：timedatectl set-time &quot;2017-01-23 10:30:00&quot;#开启NTP：timedatectl set-ntp true/false 修改时间 12345678#修改日期时间：timedatectl set-time &quot;2017-01-23 10:30:00&quot; #需要修改时间为24小时，可以修改/etc/default/locale，默认没有LC_TIME这个变量，在文件中增加一行：LC_TIME=en_DK.UTF-8 #开启NTP：timedatectl set-ntp true/false 实战：实现私有的时间服务器 安装chrony 1234567891011# centos系统检查是否安装rpm -q chrony# 安装yum install chrony# 启动服务 systemctl start chronyd # ubuntu系统上安装,ubuntu系统上安装完成后已经启动 apt install chrony 服务器端配置 123456789# IP:192.168.179.146作为时间同步服务器端，192.168.179.146的时间与阿里云时间同步器服务器同步[root@centos7 ~]# hostname -I192.168.179.146 [root@centos7 ~]# # 修改192.168.179.146配置文件 /etc/chrony.confserver ntp.aliyun.com iburstserver ntp1.aliyun.com iburstserver ntp2.aliyun.com iburst allow 0.0.0.0&#x2F;0 #加此行,指定允许同步的网段 删除此行注释,当互联网无法连接,仍然可以为客户端提供时间同步服务 重启chrony服务 1systemctl restart chronyd 服务启动后会打开端口123&#x2F;udp 显示当前的时间源同步信息 123456789[root@centos7 ~]# chronyc sources -V210 Number of sources = 2MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* 203.107.6.88 2 6 37 58 -365us[-3079us] +/- 40ms^? 120.25.115.20 2 7 110 123 -773us[-3488us] +/- 26ms[root@centos7 ~]# # *号表示当前同步的时间源地址 客户端配置 1234567# 客户端root@ubuntu2004:~# hostname -I192.168.179.147 root@ubuntu2004:~# #ubuntu系统配置文件与centos目录不一样root@ubuntu2004:~# vim /etc/chrony/chrony.conf 重启chrony服务 1root@ubuntu2004:~# systemctl restart chronyd 确认同步成功 12345678root@ubuntu2004:~# chronyc sources -V210 Number of sources = 1MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^* 192.168.179.146 3 6 17 44 +64us[ +218us] +/- 38msroot@ubuntu2004:~# # ^* 192.168.179.146表示已经成功与192.168.179.146时间同步","categories":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"批量修改多台主机的root密码为随机密码","slug":"批量修改主机密码为随机字符","date":"2022-09-12T15:35:13.000Z","updated":"2022-12-29T08:26:45.501Z","comments":true,"path":"2022/09/12/批量修改主机密码为随机字符/","link":"","permalink":"http://snippet.itshare.work/2022/09/12/%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%AF%86%E7%A0%81%E4%B8%BA%E9%9A%8F%E6%9C%BA%E5%AD%97%E7%AC%A6/","excerpt":"centos、ubuntu批量修改多台主机的root密码为随机密码","text":"批量修改多台主机的root密码为随机密码 12345678910111213141516171819202122232425#!/bin/bash# 检查sshpass是否安装，没有安装则安装sshpassrpm -q sshpass &amp;&gt; /dev/null || yum install sshpass# 主机root用户密码export SSHPASS=123456# 主机地址NET=192.168.179# 主机地址for i in &#123;20..140&#125;;do &#123; # 生成随机密码 PASS=`openssl rand -base64 9` # 链接远程主机并修改root用户密码 StrictHostKeyChecking=no 跳过检查 sshpass -e ssh -o StrictHostKeyChecking=no $&#123;NET&#125;.$&#123;i&#125; &quot;echo root:$&#123;PASS&#125; | chpasswd &amp;&gt; /dev/null&quot; # IP和密码重定向到文件中 echo $NET.$i:$PASS &gt;&gt; host.txt &#125;&amp; # 后台运行donewait sshpass使用帮助 123456789101112131415[root@centos7 data]# sshpass --helpsshpass: invalid option -- &#x27;-&#x27;Usage: sshpass [-f|-d|-p|-e] [-hV] command parameters -f filename Take password to use from file -d number Use number as file descriptor for getting password -p password Provide password as argument (security unwise) -e Password is passed as env-var &quot;SSHPASS&quot; With no parameters - password will be taken from stdin -P prompt Which string should sshpass search for to detect a password prompt -v Be verbose about what you&#x27;re doing -h Show help (this screen) -V Print version informationAt most one of -f, -d, -p or -e should be used[root@centos7 data]#","categories":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"shell脚本","slug":"shell脚本","permalink":"http://snippet.itshare.work/categories/shell%E8%84%9A%E6%9C%AC/"}]},{"title":"SSH服务","slug":"ssh服务","date":"2022-09-12T14:01:08.000Z","updated":"2022-12-16T14:59:15.357Z","comments":true,"path":"2022/09/12/ssh服务/","link":"","permalink":"http://snippet.itshare.work/2022/09/12/ssh%E6%9C%8D%E5%8A%A1/","excerpt":"ssh: secure shell protocol, 22/tcp, 安全的远程登录，实现加密通信，代替传统的 telnet 协议","text":"ssh: secure shell protocol, 22/tcp, 安全的远程登录，实现加密通信，代替传统的 telnet 协议 ssh服务介绍ssh: secure shell protocol, 22&#x2F;tcp, 安全的远程登录，实现加密通信，代替传统的 telnet 协议具体的软件实现： OpenSSH：ssh协议的开源实现，CentOS 默认安装 dropbear：另一个ssh协议的开源项目的实现 SSH 协议版本 v1：基于CRC-32做MAC，不安全；man-in-middle v2：双方主机协议选择安全的MAC方式，基于DH算法做密钥交换，基于RSA或DSA实现身份认证 openssh 服务OpenSSH是SSH （Secure SHell） 协议的免费开源实现，一般在各种Linux版本中会默认安装，基于C&#x2F;S结构Openssh软件相关包： openssh openssh-clients openssh-server 客户端 ssh命令ssh命令是ssh客户端，允许实现对远程系统经验证地加密安全访问当用户远程连接ssh服务器时，会复制ssh服务器&#x2F;etc&#x2F;ssh&#x2F;ssh_host*key.pub文件中的公钥到客户机的~&#x2F;.ssh&#x2F;know_hosts中。下次连接时，会自动匹配相对应的私钥，不能匹配，将拒绝连接 **ssh客户端配置文件： &#x2F;etc&#x2F;ssh&#x2F;ssh_config ****主要配置: ** 12345678#StrictHostKeyChecking ask#首次登录不显示检查提示StrictHostKeyChecking no# IdentityFile ~/.ssh/id_rsa# IdentityFile ~/.ssh/id_dsa# IdentityFile ~/.ssh/id_ecdsa# IdentityFile ~/.ssh/id_ed25519# Port 22 范例：禁止首次连接的询问过程 12[root@centos7 ~]#sed -i.bak &#x27;/StrictHostKeyChecking/s/.*/StrictHostKeyCheckingno/&#x27; /etc/ssh/ssh_config 格式 12ssh [user@]host [COMMAND]ssh [-l user] host [COMMAND] 常用选项 12345678910-p port #远程服务器监听的端口-b #指定连接的源IP-v #调试模式-C #压缩方式-X #支持x11转发-t #强制伪tty分配，如：ssh -t remoteserver1 ssh -t remoteserver2 sshremoteserver3-o option 如：-o StrictHostKeyChecking=no-i &lt;file&gt; #指定私钥文件路径，实现基于key验证，默认使用文件： ~/.ssh/id_dsa,~/.ssh/id_ecdsa, ~/.ssh/id_ed25519，~/.ssh/id_rsa等 在远程主机执行本地脚本 1234567[root@rocky ~]# cat test.sh #!/bin/bashhostname -I[root@rocky ~]# ssh root@192.168.179.145 /bin/bash &lt;test.sh root@192.168.179.145&#x27;s password: 192.168.179.145 [root@rocky ~]# 其他ssh客户端工具scp命令1scp [options] SRC... DEST/ 方式： 123scp [options] [user@]host:/sourcefile /destpathscp [options] /sourcefile [user@]host:/destpathscp [options] [user@]host1:/sourcetpath [user@]host2:/destpath 常用选项 12345-C 压缩数据流-r 递归复制-p 保持原文件的属性信息-q 静默模式-P PORT 指明remote host的监听的端口 范例:从远程机器复制文件到本地目录 1scp root@10.10.10.10:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ 范例： 上传本地文件到远程机器指定目录 1scp /opt/soft/nginx-0.5.38.tar.gz root@10.10.10.10:/opt/soft/scptest 注:复制目录加上选项-r ### rsync命令 rsync工具可以基于ssh和rsync协议实现高效率的远程系统之间复制文件，使用安全的shell连接做为传输方式，比scp更快，基于增量数据同步，即只复制两方不同的文件，此工具来自于rsync包注意：通信两端主机都需要安装 rsync 软件 12rsync -av /etc server1:/tmp/ #复制目录和目录下文件rsync -av /etc/ server1:/tmp/ #只复制目录下文件 ** 常用选型** 123456789101112131415-n 模拟复制过程-v 显示详细过程-r 递归复制目录树-p 保留权限-t 保留修改时间戳-g 保留组信息-o 保留所有者信息-l 将软链接文件本身进行复制（默认）-L 将软链接文件指向的文件复制-u 如果接收者的文件比发送者的文件较新，将忽略同步-z 压缩，节约网络带宽-a 存档，相当于-rlptgoD，但不保留ACL（-A）和SELinux属性（-X）--delete 源数据删除，目标数据也自动同步删除--progress 显示进度--bwlimit=5120 #限速以KB为单位,5120表示5MB 范例:复制文件到远程主机目录下 1rsync ./test.sh root@192.168.179.145:/root 自动登录 ssh工具 sshpass由EPEL源提供，ssh登陆不能在命令行中指定密码。sshpass的出现，解决了这一问题。sshpass用于非交互SSH的密码验证，一般用在sh脚本中，无须再次输入密码（本机known_hosts文件中有的主机才能生效）。它允许你用 -p 参数指定明文密码，然后直接登录远程服务器，它支持密码从命令行、文件、环境变量中读取。格式： 1sshpass [option] command parameters 常用选项 123-p password #后跟密码它允许你用 -p 参数指定明文密码，然后直接登录远程服务器-f filename #后跟保存密码的文件名，密码是文件内容的第一行-e #将环境变量SSHPASS作为密码 范例:登录远程主机执行指定命令 123456789# 检测sshpass是否安装[root@rocky ~]# rpm -q sshpasspackage sshpass is not installed# 安装sshpass[root@rocky ~]# yum install sshpass# 登录远程主机，首次登录不显示检查提示，执行hostname -I命令[root@rocky ~]# sshpass -p 123456 ssh -o StrictHostKeyChecking=no root@192.168.179.145 hostname -I192.168.179.145 [root@rocky ~]# 实现基于密钥登录方式验证在客户端生成密钥对 1ssh-keygen -t rsa [-P &#x27;password&#x27;] [-f “~/.ssh/id_rsa&quot;] 把公钥文件传输至远程服务器对应用户的家目录 1ssh-copy-id [-i [identity_file]] [user@]host 重设私钥口令： 1ssh-keygen -p 在SecureCRT或Xshell实现基于key验证在SecureCRT工具—&gt;创建公钥—&gt;生成Identity.pub文件转化为openssh兼容格式（适合SecureCRT，Xshell不需要转化格式），并复制到需登录主机上相应文件authorized_keys中,注意权限必须为600，在需登录的ssh主机上执行： 1ssh-keygen -i -f Identity.pub &gt;&gt; .ssh/authorized_keys 范例：实现基于 key 验证 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@centos8 ~]#ssh-keygenGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): #回车，接受默认值Enter passphrase (empty for no passphrase): #回车，接受默认值，空密码Enter same passphrase again: #回车，接受默认值Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:vpPtmqRv1llmoSvqT2Lx5C0LPGTE0pvdAqhDqlR5jLY root@centos8.wangxiaochun.comThe key&#x27;s randomart image is:+---[RSA 3072]----+| || ++ || .=oo= || oo.oo = . . ||..oE * S .. . ||o . + * o. + ||. * B+.* || . B*== || .+*B=. |+----[SHA256]-----+[root@centos8 ~]#ll .ssh/total 8-rw------- 1 root root 2622 May 22 09:51 id_rsa-rw-r--r-- 1 root root 583 May 22 09:51 id_rsa.pub[root@centos8 ~]## 将本主机的公钥复制到远程主机的authorized_keys中[root@centos8 ~]#ssh-copy-id root@10.0.0.7/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed:&quot;/root/.ssh/id_rsa.pub&quot;The authenticity of host &#x27;10.0.0.7 (10.0.0.7)&#x27; can&#x27;t be established.ECDSA key fingerprint is SHA256:s//WMgPVXmOjqfOg3f3X0nmaPZF+Fj5vPdWCnAzDcpU.Are you sure you want to continue connecting (yes/no/[fingerprint])? yes/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filterout any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you areprompted now it is to install the new keysroot@10.0.0.7&#x27;s password: #输入远程用户的密码Number of key(s) added: 1Now try logging into the machine, with: &quot;ssh &#x27;10.0.0.7&#x27;&quot;and check to make sure that only the key(s) you wanted were added.#对私钥加密[root@centos8 ~]#ssh-keygen -p ssh服务配置服务器端：sshd服务器端的配置文件: &#x2F;etc&#x2F;ssh&#x2F;sshd_config服务器端的配置文件帮助：man 5 sshd_config常用参数： 123456789101112131415161718192021222324Port 22 #生产建议修改ListenAddress ipLoginGraceTime 2mPermitRootLogin yes #默认ubuntu不允许root远程ssh登录StrictModes yes #检查.ssh/文件的所有者，权限等MaxAuthTries 6 #pecifies the maximum number of authenticationattempts permitted per connection. Once the number of failures reaches half thisvalue, additional failures are logged. The default is 6.MaxSessions 10 #同一个连接最大会话PubkeyAuthentication yes #基于key验证PermitEmptyPasswords no #空密码连接PasswordAuthentication yes #基于用户名和密码连接GatewayPorts noClientAliveInterval 10 #单位:秒ClientAliveCountMax 3 #默认3UseDNS yes #提高速度可改为noGSSAPIAuthentication yes #提高速度可改为noMaxStartups #未认证连接最大值，默认值10Banner /path/file#以下可以限制可登录用户的办法：AllowUsers user1 user2 user3DenyUsers user1 user2 user3AllowGroups g1 g2DenyGroups g1 g2 范例：设置 ssh 空闲60s 自动注销 12345Vim /etc/ssh/sshd_configClientAliveInterval 60ClientAliveCountMax 0Service sshd restart#注意：新开一个连接才有效 范例：解决ssh登录缓慢的问题 1234vim /etc/ssh/sshd_configUseDNS noGSSAPIAuthentication nosystemctl restart sshd","categories":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"Rocky上实现私有CA和证书申请","slug":"Rocky上实现私有CA和证书申请","date":"2022-09-11T13:56:35.000Z","updated":"2022-12-17T04:15:50.954Z","comments":true,"path":"2022/09/11/Rocky上实现私有CA和证书申请/","link":"","permalink":"http://snippet.itshare.work/2022/09/11/Rocky%E4%B8%8A%E5%AE%9E%E7%8E%B0%E7%A7%81%E6%9C%89CA%E5%92%8C%E8%AF%81%E4%B9%A6%E7%94%B3%E8%AF%B7/","excerpt":"OpenSSL计划在1998年开始，其目标是发明一套自由的加密工具，在互联网上使用。OpenSSL以Eric Young以及Tim Hudson两人开发的SSLeay为基础，随着两人前往RSA公司任职，SSLeay在1998年12月停止开发。因此在1998年12月，社群另外分支出OpenSSL，继续开发下去","text":"OpenSSL计划在1998年开始，其目标是发明一套自由的加密工具，在互联网上使用。OpenSSL以Eric Young以及Tim Hudson两人开发的SSLeay为基础，随着两人前往RSA公司任职，SSLeay在1998年12月停止开发。因此在1998年12月，社群另外分支出OpenSSL，继续开发下去 在rocky上实现私有CA和证书申请 创建CA相关目录和文件&#x2F;etc&#x2F;pki&#x2F;CA 1234567[root@rocky pki]# mkdir -pv /etc/pki/CA/&#123;certs,crl,newcerts,private&#125;mkdir: created directory &#x27;/etc/pki/CA&#x27;mkdir: created directory &#x27;/etc/pki/CA/certs&#x27;mkdir: created directory &#x27;/etc/pki/CA/crl&#x27;mkdir: created directory &#x27;/etc/pki/CA/newcerts&#x27;mkdir: created directory &#x27;/etc/pki/CA/private&#x27;[root@rocky pki]# 创建index.txt文件(&#x2F;etc&#x2F;pki&#x2F;CA目录下) 1234567891011121314151617[root@rocky CA]# touch index.txt#指定第一个颁发证书的序列号，为16进制数[root@rocky CA]# echo 01 &gt; /etc/pki/CA/serial0F /etc/pki/CA/certs[root@rocky CA]# [root@rocky CA]# tree.├── certs├── crl├── index.txt├── newcerts└── private4 directories, 1 file[root@rocky CA]# 创建CA的私钥 1234567891011[root@rocky CA]# pwd/etc/pki/CA#因为加了小括号，因此是在子进程中运行的，umask的值不会影响当前进程[root@rocky CA]# (umask 066;openssl genrsa -out private/cakey.pem 2048)Generating RSA private key, 2048 bit long modulus (2 primes).................................................................................................................................+++++.............+++++e is 65537 (0x010001)[root@rocky CA]# 给CA颁发自签名证书 12345678910111213141516[root@rocky pki]# openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 3650 -out /etc/pki/CA/cacert.pemYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &#x27;.&#x27;, the field will be left blank.-----Country Name (2 letter code) [XX]:CN # 指定国家State or Province Name (full name) []:guizhou # 指定省Locality Name (eg, city) [Default City]:duyun # 指定城市Organization Name (eg, company) [Default Company Ltd]:magedu # 公司Organizational Unit Name (eg, section) []:it # 部门Common Name (eg, your name or your server&#x27;s hostname) []:m48 # 指定给颁发者Email Address []: # 邮箱地址 参数说明 123456789-new：生成新证书签署请求；-x509：专用用于CA生成字签证书-key：生成请求时用到的私钥文件-day：证书的有效期限-out：证书的保存路径（在配置文件当中有固定路径，该文件可以自动生成） 用户生成私钥和证书申请 123456789101112131415161718192021222324252627282930313233343536373839[root@rocky CA]# mkdir -pv /data/app1mkdir: created directory &#x27;/data&#x27;mkdir: created directory &#x27;/data/app1&#x27;[root@rocky CA]# # 生成私钥文件 [root@rocky app1]# (umask 066;openssl genrsa -out /data/app1/app1.key 2048)Generating RSA private key, 2048 bit long modulus (2 primes).......................+++++.............+++++e is 65537 (0x010001)[root@rocky app1]# #生成证书申请文件[root@rocky app1]# openssl req -new -key /data/app1/app1.key -out /data/app1/app1.csrYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &#x27;.&#x27;, the field will be left blank.-----Country Name (2 letter code) [XX]:guizhoustring is too long, it needs to be no more than 2 bytes longCountry Name (2 letter code) [XX]:duyun^C[root@rocky app1]# openssl req -new -key /data/app1/app1.key -out /data/app1/app1.csrYou are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &#x27;.&#x27;, the field will be left blank.-----Country Name (2 letter code) [XX]:CNState or Province Name (full name) []:guizhouLocality Name (eg, city) [Default City]:duyunOrganization Name (eg, company) [Default Company Ltd]:mageduOrganizational Unit Name (eg, section) []:itCommon Name (eg, your name or your server&#x27;s hostname) []:m48Email Address []: 注意：默认要求 国家，省，公司名称三项必须和CA一致 CA颁发证书 12345678910111213141516171819202122232425262728293031323334[root@rocky CA]# openssl ca -in /data/app1/app1.csr -out /etc/pki/CA/certs/app1.crt -days 1000Using configuration from /etc/pki/tls/openssl.cnfCheck that the request matches the signatureSignature okCertificate Details: Serial Number: 1 (0x1) Validity Not Before: Sep 12 04:28:42 2022 GMT Not After : Jun 8 04:28:42 2025 GMT Subject: countryName = CN stateOrProvinceName = guizhou organizationName = magedu organizationalUnitName = it commonName = m48 X509v3 extensions: X509v3 Basic Constraints: CA:FALSE Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: F9:E4:5D:C9:C7:70:0C:E9:17:CC:90:88:7E:78:20:57:38:04:EC:69 X509v3 Authority Key Identifier: keyid:EA:34:E4:C1:8C:1B:F2:F9:22:D5:A2:AE:BD:2F:EA:13:28:24:43:60Certificate is to be certified until Jun 8 04:28:42 2025 GMT (1000 days)Sign the certificate? [y/n]:y1 out of 1 certificate requests certified, commit? [y/n]yWrite out database with 1 new entriesData Base Updated[root@rocky CA]# 查看证书 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384[root@rocky CA]# cat /etc/pki/CA/certs/app1.crt Certificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: sha256WithRSAEncryption Issuer: C=CN, ST=guizhou, L=duyun, O=magedu, OU=it, CN=m48 Validity Not Before: Sep 12 04:28:42 2022 GMT Not After : Jun 8 04:28:42 2025 GMT Subject: C=CN, ST=guizhou, O=magedu, OU=it, CN=m48 Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public-Key: (2048 bit) Modulus: 00:b1:d4:eb:6e:8d:32:db:5e:ce:5d:6c:43:73:ef: 28:d3:08:8b:ae:8b:42:bf:6a:57:27:76:03:fe:ac: 55:62:2f:7a:9c:97:37:aa:53:40:df:35:6c:be:28: c1:c2:b5:e0:af:f0:d3:be:40:3c:15:1e:59:47:40: f0:85:20:c2:da:ca:83:a2:6f:7a:89:3d:35:ba:cf: 03:cb:cd:e0:15:96:76:56:23:30:ce:be:c6:1e:d0: a1:fb:27:0c:0f:cf:19:1b:03:9a:08:c8:a2:f1:46: 18:b6:f0:08:ef:10:26:12:2b:de:ba:a3:9b:8e:f5: 13:ab:6a:4d:08:8c:59:30:ef:78:d1:29:6d:3a:4e: df:c0:cc:d8:04:84:e8:3d:5f:90:67:45:b5:a8:22: 8f:6f:ad:83:c9:04:ba:5e:98:3f:f8:2b:49:45:31: 01:0e:7d:60:b3:ad:44:5f:9d:90:6c:34:9d:5c:31: 26:01:d3:75:fe:58:66:81:b5:d9:b3:83:99:e0:10: 62:26:37:62:0e:6c:ea:06:ff:3e:b6:a1:c0:e2:27: 0e:85:4c:44:eb:84:16:b6:36:b9:4f:74:fa:c7:89: 32:a2:c4:e3:d4:11:a2:7c:61:2d:82:a8:3d:2c:e3: 17:c4:ec:de:ae:28:07:07:94:3c:62:1d:49:c0:c0: 12:41 Exponent: 65537 (0x10001) X509v3 extensions: X509v3 Basic Constraints: CA:FALSEs Netscape Comment: OpenSSL Generated Certificate X509v3 Subject Key Identifier: F9:E4:5D:C9:C7:70:0C:E9:17:CC:90:88:7E:78:20:57:38:04:EC:69 X509v3 Authority Key Identifier: keyid:EA:34:E4:C1:8C:1B:F2:F9:22:D5:A2:AE:BD:2F:EA:13:28:24:43:60 Signature Algorithm: sha256WithRSAEncryption 0c:90:51:c2:89:75:d7:e1:92:e7:a3:90:cb:f0:c0:96:a7:0f: 9f:e6:b5:2b:45:ed:be:ee:86:cf:0c:f9:06:9c:21:27:25:f8: 6c:d9:1c:84:87:8f:df:c2:c9:8f:65:7a:e9:84:2c:13:a8:1d: d9:ab:65:02:c4:d5:8f:b3:17:a1:7c:d3:e3:06:83:06:43:5c: f6:a1:1a:b8:f4:98:7c:28:a9:4e:44:f5:82:ac:9f:77:b7:2f: cd:a6:c7:df:8c:24:84:0c:36:ad:2e:69:24:b7:0f:17:80:7d: f5:57:4c:df:8d:fb:7d:9e:27:22:bb:7e:b9:e4:aa:45:63:63: 41:00:64:c6:ff:69:47:1c:b2:ca:49:2a:56:3a:9c:c0:3b:19: 58:64:22:c2:e2:6c:27:bb:c1:d6:8f:55:a0:77:a0:a8:10:6d: 5c:cb:01:50:91:ab:86:ac:88:ee:dc:0e:9d:6c:35:c4:7b:fe: 33:52:a3:f8:a8:25:1d:51:51:ed:2c:25:cf:c7:d3:18:73:81: 42:0f:6f:b7:e6:3f:87:2a:12:4b:71:9c:a1:c2:07:91:a6:10: 5f:5f:c2:28:59:f6:2b:ba:ff:d6:56:69:03:c2:49:36:f0:35: b4:38:70:7c:29:b8:f6:7d:72:c7:6f:cf:23:ef:e2:5f:d3:73: fc:26:9a:ec-----BEGIN CERTIFICATE-----MIIDnDCCAoSgAwIBAgIBATANBgkqhkiG9w0BAQsFADBbMQswCQYDVQQGEwJDTjEQMA4GA1UECAwHZ3VpemhvdTEOMAwGA1UEBwwFZHV5dW4xDzANBgNVBAoMBm1hZ2VkdTELMAkGA1UECwwCaXQxDDAKBgNVBAMMA200ODAeFw0yMjA5MTIwNDI4NDJaFw0yNTA2MDgwNDI4NDJaMEsxCzAJBgNVBAYTAkNOMRAwDgYDVQQIDAdndWl6aG91MQ8wDQYDVQQKDAZtYWdlZHUxCzAJBgNVBAsMAml0MQwwCgYDVQQDDANtNDgwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCx1OtujTLbXs5dbENz7yjTCIuui0K/alcndgP+rFViL3qclzeqU0DfNWy+KMHCteCv8NO+QDwVHllHQPCFIMLayoOib3qJPTW6zwPLzeAVlnZWIzDOvsYe0KH7JwwPzxkbA5oIyKLxRhi28AjvECYSK966o5uO9ROrak0IjFkw73jRKW06Tt/AzNgEhOg9X5BnRbWoIo9vrYPJBLpemD/4K0lFMQEOfWCzrURfnZBsNJ1cMSYB03X+WGaBtdmzg5ngEGImN2IObOoG/z62ocDiJw6FTETrhBa2NrlPdPrHiTKixOPUEaJ8YS2CqD0s4xfE7N6uKAcHlDxiHUnAwBJBAgMBAAGjezB5MAkGA1UdEwQCMAAwLAYJYIZIAYb4QgENBB8WHU9wZW5TU0wgR2VuZXJhdGVkIENlcnRpZmljYXRlMB0GA1UdDgQWBBT55F3Jx3AM6RfMkIh+eCBXOATsaTAfBgNVHSMEGDAWgBTqNOTBjBvy+SLVoq69L+oTKCRDYDANBgkqhkiG9w0BAQsFAAOCAQEADJBRwol11+GS56OQy/DAlqcPn+a1K0Xtvu6Gzwz5BpwhJyX4bNkchIeP38LJj2V66YQsE6gd2atlAsTVj7MXoXzT4waDBkNc9qEauPSYfCipTkT1gqyfd7cvzabH34wkhAw2rS5pJLcPF4B99VdM3437fZ4nIrt+ueSqRWNjQQBkxv9pRxyyykkqVjqcwDsZWGQiwuJsJ7vB1o9VoHegqBBtXMsBUJGrhqyI7twOnWw1xHv+M1Kj+KglHVFR7Swlz8fTGHOBQg9vt+Y/hyoSS3GcocIHkaYQX1/CKFn2K7r/1lZpA8JJNvA1tDhwfCm49n1yx2/PI+/iX9Nz/Caa7A==-----END CERTIFICATE-----[root@rocky CA]# 123[root@rocky CA]# openssl x509 -in /etc/pki/CA/certs/app1.crt -noout -issuerissuer=C = CN, ST = guizhou, L = duyun, O = magedu, OU = it, CN = m48[root@rocky CA]# 12345# 验证指定编号对应证书的有效性[root@rocky CA]# openssl ca -status 01Using configuration from /etc/pki/tls/openssl.cnf01=Valid (V)[root@rocky CA]# 证书的吊销 123456789[root@rocky newcerts]# openssl ca -revoke /etc/pki/CA/newcerts/01.pem Using configuration from /etc/pki/tls/openssl.cnfRevoking Certificate 01.Data Base Updated[root@rocky newcerts]# openssl ca -status 01Using configuration from /etc/pki/tls/openssl.cnf01=Revoked (R)[root@rocky newcerts]# 生成证书吊销列表文件 12[root@rocky newcerts]#echo 01 &gt; /etc/pki/CA/crlnumber[root@rocky newcerts]#openssl ca -gencrl -out /etc/pki/CA/crl.pem","categories":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[{"name":"Linux基础","slug":"Linux基础","permalink":"http://snippet.itshare.work/categories/Linux%E5%9F%BA%E7%A1%80/"}]},{"title":"Linux定时执行任务","slug":"Linux定时执行任务","date":"2022-09-05T15:48:34.000Z","updated":"2022-12-16T14:58:02.333Z","comments":true,"path":"2022/09/05/Linux定时执行任务/","link":"","permalink":"http://snippet.itshare.work/2022/09/05/Linux%E5%AE%9A%E6%97%B6%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1/","excerpt":"定时执行任务：是指在约定好的时间执行已经计划好的工作，如系统周期性所要执行的备份系统数据、清理缓存等。常用与定时执行任务的命令：at命令，batch命令（batch命令的用法和at相似），与周期性任务相关的crontab命令，CentOS7的新特性timer命令。","text":"一、at命令1、at命令的准备工作1）安装 at 软件包 1[root@centos7 ~]# yum install -y at 2）需要 atd 服务的支持。atd 服务是独立的服务 12345查看atd服务状态：# systemctl status atd 开启atd服务：# systemctl start atd关闭atd服务：# systemctl stop atd 3）查看是否开始开机启动服务：如果弹出enabled，说明开机启动此服务 123[root@rocky ~]# systemctl is-enabled atdenabled[root@rocky ~]# 4）安装好 at 软件包并开启 atd 服务之后，at 命令才可以正常使用。 12[root@rocky ~]# systemctl start atd [root@rocky ~]# systemctl status atd 2、at 命令的访问控制访问控制：是指允许哪些用户使用 at 命令设定定时任务，或者不允许哪些用户使用 at 命令。可以将其想象成设定黑名单或白名单。at 命令的访问控制是依靠 &#x2F;etc&#x2F;at.allow（白名单）和 &#x2F;etc&#x2F;at.deny（黑名单）这两个文件来实现的，具体规则如下： 1)如果系统中有 &#x2F;etc&#x2F;at.allow 文件，那么只有写入 &#x2F;etc&#x2F;at.allow 文件（白名单）中的用户可以使用 at 命令，其他用户不能使用 at 命令(（注意，&#x2F;etc&#x2F;at.allow 文件的优先级更高，也就是说，如果同一个用户既写入 &#x2F;etc&#x2F;at.allow 文件，又写入 &#x2F;etc&#x2F;at.deny 文件，那么这个用户是可以使用 at 命令的); 2)如果系统中没有 &#x2F;etc&#x2F;at.allow 文件，只有 &#x2F;etc&#x2F;at.deny 文件，那么写入 &#x2F;etc&#x2F;at.deny 文件（黑名单）中的用户不能使用 at 命令，其他用户可以使用 at 命令。不过这个文件对 root 用户不生效; 3)如果系统中这两个文件都不存在，那么只有 root 用户可以使用 at 命令; 4)系统中默认只有 &#x2F;etc&#x2F;at.deny 文件，而且这个文件是空的，因此，系统中所有的用户都可以使用 at 命令。如果我们打算控制用户的 at 命令权限，那么只需把用户名写入 &#x2F;etc&#x2F;at.deny 文件即可。 3、at 命令语法添加定时执行任务基本格式 1at [选项] [时间] or at [option] TIME 选项 1234567-V 显示版本信息-t time 时间格式 [[CC]YY]MMDDhhmm[.ss]-l 列出指定队列中等待运行的作业；相当于atq-d N 删除指定的N号作业；相当于atrm-c N 查看具体作业N号任务-f file 指定的文件中读取任务-m 当任务被完成之后，将给用户发送邮件，即使没有标准输出 注意： 作业执行命令的结果中的标准输出和错误以执行任务的用户身份发邮件通知给 root 默认CentOS 8 最小化安装没有安装邮件服务,需要自行安装 TIME：定义出什么时候进行 at 这项任务的时间 此命令中关于时间参数可用的以下格式： 格式 用法 HH:MM 比如 04:00 AM。 Midnight（midnight） 代表 12:00 AM Noon（noon） 代表 12:00 PM（相当于 12:00） Teatime（teatime） 代表 4:00 PM（相当于 16:00）。 英文月名 日期 年份 比如 January 15 2018 表示 2018 年 1 月 15 号，年份可有可无。 MMDDYY、MM&#x2F;DD&#x2F;YY、MM.DD.YY 比如 011518 表示 2018 年 1 月 15 号。 now+时间 以 minutes、hours、days 或 weeks 为单位，例如 now+5 days 表示命令在 5 天之后的此时此刻执行。 具体的使用方法： at命令后想要输入执行程序的确切时间，然后回车，接着在 &gt; 后输入想要执行的命令，最后用 Ctrl+d 组合键退出 at 命令。 范例 12[root@centos7 ~]# at now+2 minat&gt; ls ./ &gt; a.log 范例: ubuntu at任务存放路径 123456789101112131415root@ubuntu200404-1:~# ll /var/spool/cron/total 20drwxr-xr-x 5 root root 4096 Feb 23 2022 ./drwxr-xr-x 4 root root 4096 Feb 23 2022 ../drwxrwx--T 2 daemon daemon 4096 Sep 6 13:32 atjobs/drwxrwx--T 2 daemon daemon 4096 Nov 12 2018 atspool/drwx-wx--T 2 root crontab 4096 Feb 13 2020 crontabs/root@ubuntu200404-1:~# ll /var/spool/cron/atjobs/total 16drwxrwx--T 2 daemon daemon 4096 Sep 6 13:32 ./drwxr-xr-x 5 root root 4096 Feb 23 2022 ../-rwx------ 1 root daemon 2838 Sep 6 13:33 a0000101a6c9d1*-rw------- 1 daemon daemon 6 Sep 6 13:32 .SEQroot@ubuntu200404-1:~# 范例：centos at任务存放路径 12345[root@centos7 ~]# ll /var/spool/at/total 4-rwx------. 1 root root 2831 Sep 6 21:37 a0000501a6c9d5drwx------. 2 root root 19 Sep 6 21:31 spool[root@centos7 ~]# 二、 crontab命令 at 命令：是在指定的时间只能执行一次任务。 crontab 命令：可以循环重复的执行定时任务。 1、crontab 命令的准备工作crontab 命令需要 crond 服务支持。crond 是 Linux 下用来周期地执行某种任务或等待处理某些事件的一个守护进程，在安装完成操作系统后，默认会安装 crond 服务工具，且 crond 服务默认就是自启动的。crond 进程每分钟会定期检查是否有要执行的任务，如果有，则会自动执行该任务。 crontab 命令和 at 命令类似，也是通过 &#x2F;etc&#x2F;cron.allow 和 &#x2F;etc&#x2F;cron.deny 文件来限制某些用户是否可以使用 crontab 命令的。 启动crond服务之后才能使用crontab 命令： 1# systemctl start crond 或者 # systemctl enable crond 2、 crontab 命令语法命令格式 1crontab [-u user] [-l | -r | -e] [-i] 常用选项 12345-l 列出所有任务-e 编辑任务-r 移除所有任务-i 同-r一同使用，以交互式模式移除指定任务-u user 指定用户管理cron任务,仅root可运行 crontab 定时任务非常简单，只需执“crontab -e”命令，然后输入想要定时执行的任务即可。注意文件格式如下： 123[root@centos7 ~]## crontab -e#进入 crontab 编辑界面。会打开Vim编辑你的任务* * * * * 执行的任务 &#x2F;etc&#x2F;crontab 格式说明，详情参见 man 5 crontab注释行以 # 开头 123456789101112131415161718[root@centos7 ~]# cat /etc/crontab SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executedYou have mail in /var/spool/mail/root[root@centos7 ~]# 项目 含义 范围 第一个”*” 一小时当中的第几分钟（minute） 0~59 第二个”*” 一天当中的第几小时（hour） 0~23 第三个”*” 一个月当中的第几天（day） 1~31 第四个”*” 一年当中的第几个月（month） 1~12 第五个”*” 一周当中的星期几（week） 0~7（0和7都代表星期日） **在这个时间的表达式中，还有一些特殊符号如下： ** 特殊符号 含义 *（星号） 代表任何时间。比如第一个”*”就代表一小时种每分钟都执行一次的意思。 ,（逗号） 代表不连续的时间。比如”0 8，12，16***命令”就代表在每天的 8 点 0 分、12 点 0 分、16 点 0 分都执行一次命令。 -（中杠） 代表连续的时间范围。比如”0 5 ** 1-6命令”，代表在周一到周六的凌晨 5 点 0 分执行命令。 &#x2F;（正斜线） 代表每隔多久执行一次。比如”&#x2F;10***命令”，代表每隔 10 分钟就执行一次命令。 当“crontab -e”编辑完成之后，一旦保存退出，那么这个定时任务实际就会写入 &#x2F;var&#x2F;spool&#x2F;cron&#x2F; 目录中，每个用户的定时任务用自己的用户名进行区分。而且 crontab 命令只要保存就会生效，只要 crond 服务是启动的。 这里举几个时间的例子来熟悉一下时间字段（星期几和几日最好不要同时出现，非常容易让管理员混淆）： 时间 含义 1 2 * * * 在每天凌晨 2 点 1 分执行命令 0 17 * * 1 在每周一的 17 点 0 分执行命令 0 5 1,15 * * 在每月 1 日和 15 日的凌晨 5 点 0 分执行命令 40 4 * * 1-5 在每周一到周五的凌晨 4 点 40 分执行命令 *&#x2F;10 4 * * * 在每天的凌晨 4 点，每隔 10 分钟执行命令 3,15 8-11 *&#x2F;2 * * 在每隔两天的上午 8 点到 11 点的第 3 和第 15 分钟执行命令。","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"进程和线程相关概念","slug":"进程和线程相关概念","date":"2022-09-04T06:18:58.000Z","updated":"2022-12-16T14:56:07.665Z","comments":true,"path":"2022/09/04/进程和线程相关概念/","link":"","permalink":"http://snippet.itshare.work/2022/09/04/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5/","excerpt":"Process运行中的程序的一个副本，是被载入内存的一个指令集合，是资源分配的单位","text":"Linux系统状态的查看及管理工具： 12345678910111213141516pstreepspidofpgreptophtopglancepmapvmstatdstatkillpkilljobbgfgnohup 1 进程管理和性能相关工具1.1 进程树pstreepstree 可以用来显示进程的父子关系，以树形结构显示格式： 1pstree [OPTION] [ PID | USER ] 常用选项 1234-p 显示PID-T 不显示线程thread,默认显示线程-u 显示用户切换-H pid 高亮显示指定进程及其前辈进程 1.2 进程信息PSps 即 process state，可以进程当前状态的快照，默认显示当前终端中的进程，Linux系统各进程的相关信息均保存在&#x2F;proc&#x2F;PID目录下的各文件中ps格式： 1ps [OPTION]... 常用选项 123456789101112131415161718192021a 选项包括所有终端中的进程x 选项包括不链接终端的进程u 选项显示进程所有者的信息f 选项显示进程树,相当于 --forestk|--sort 属性 对属性排序,属性前加 - 表示倒序o 属性… 选项显示定制的信息 pid、cmd、%cpu、%memL 显示支持的属性列表-C cmdlist 指定命令，多个命令用，分隔-L 显示线程-e 显示所有进程，相当于-A-f 显示完整格式程序信息-F 显示更完整格式的进程信息-H 以进程层级格式显示进程相关信息-u userlist 指定有效的用户ID或名称-U userlist 指定真正的用户ID或名称-g gid或groupname 指定有效的gid或组名称-G gid或groupname 指定真正的gid或组名称-p pid 显示指pid的进程--ppid pid 显示属于pid的子进程-t ttylist 指定tty,相当于 t-M 显示SELinux信息，相当于Z","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"Linux运维工程师面试题汇总(2022)","slug":"Linux运维工程师面试题汇总(2022)","date":"2022-09-02T12:08:44.000Z","updated":"2022-12-16T14:58:16.426Z","comments":true,"path":"2022/09/02/Linux运维工程师面试题汇总(2022)/","link":"","permalink":"http://snippet.itshare.work/2022/09/02/Linux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB(2022)/","excerpt":"“机会总是留给有准备的人的”，Linux运维工程师必备的基础知识可谓是由点及面、由浅入深。尤其是在云原生潮流趋势下，我们需要持续拥抱新技术、新思想，而不是在自己的舒适区原地踏步。","text":"一、linux1.linux系统启动流程 第一步：开机自检，加载BIOS 第二步：读取ＭＢＲ 第三步：Boot Loader grub引导菜单 第四步：加载kernel内核 第五步：init进程依据inittab文件夹来设定运行级别 第六步：init进程执行rc.sysinit 第七步：启动内核模块 第八步：执行不同运行级别的脚本程序 第九步：执行&#x2F;etc&#x2F;rc.d&#x2F;rc.lo 2.linux文件类型 文件属性 文件类型 - 常规文件，即file d 目录文件 b block device 即块设备文件，如硬盘;支持以block为单位进行随机访问 c character device 即字符设备文件，如键盘支持以character为单位进行线性访问 l symbolic link 即符号链接文件，又称软链接文件 p pipe 即命名管道文件 s socket 即套接字文件，用于实现两个进程进行通信 3.centos6和7怎么将源码安装的程序添加到开机自启动？ 通用方法：编辑&#x2F;etc&#x2F;rc.d&#x2F;rc.local文件，在文件末尾添加启动服务命令 centos6①进入到&#x2F;etc&#x2F;rc.d&#x2F;init.d目录下；②新建一个服务启动脚本，脚本中指定chkconfig参数；③添加执行权限；④执行chkconfig –add 添加服务自启动； centos7①进入到&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system目录下；②新建自定义服务文件，文件中包含[Unit] [Service] [Install]相关配置，然后添加下执行权限；③执行systemctl enable 服务名称； 4.简述lvm，如何给使用lvm的&#x2F;分区扩容？ 功能：可以对磁盘进行动态管理。动态按需调整大小 概念： ①PV - 物理卷：物理卷在逻辑卷管理中处于最底层，它可以是实际物理硬盘上的分区，也可以是整个物理硬盘，也可以是raid设备。②VG - 卷组：卷组建立在物理卷之上，一个卷组中至少要包括一个物理卷，在卷组建立之后可动态添加物理卷到卷组中。一个逻辑卷管理系统工程中可以只有一个卷组，也可以拥有多个卷组。③LV - 逻辑卷：逻辑卷建立在卷组之上，卷组中的未分配空间可以用于建立新的逻辑卷，逻辑卷建立后可以动态地扩展和缩小空间。系统中的多个逻辑卷可以属于同一个卷组，也可以属于不同的多个卷组。 给&#x2F;分区扩容步骤： ①添加磁盘②使用fdisk命令对新增加的磁盘进行分区③分区完成后修改分区类型为lvm④使用pvcreate创建物理卷⑤使用vgextend命令将新增加的分区加入到根目录分区中⑥使用lvextend命令进行扩容⑦使用xfs_growfs调整卷分区大小 5.为何du和df统计结果不一致？ 用户删除了大量的文件被删除后，在文件系统目录中已经不可见了，所以du就不会再统计它。 然而如果此时还有运行的进程持有这个已经被删除的文件句柄，那么这个文件就不会真正在磁盘中被删除，分区超级块中的信息也就不会更改，df仍会统计这个被删除的文件。 可通过 lsof命令查询处于deleted状态的文件，被删除的文件在系统中被标记为deleted。如果系统有大量deleted状态的文件，会导致du和df统计结果不一致。 6.如何升级内核？ 方法一 123456789# 添加第三方yum源进行下载安装。Centos 6 YUM源：http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpmCentos 7 YUM源：http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm# 先导入elrepo的key，然后安装elrepo的yum源：rpm -import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgrpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm# 查看可用的内核相关包yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available yum -y --enablerepo=elrepo-kernel install 方法二 123456789101112131415161718# 通过下载kernel image的rpm包进行安装。官方 Centos 6: http://elrepo.org/linux/kernel/el6/x86_64/RPMS/官方 Centos 7: http://elrepo.org/linux/kernel/el7/x86_64/RPMS/# 获取下载链接进行下载安装即可wget https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-lt-4.4.185-1.el7.elrepo.x86_64.rpmrpm -ivh kernel-lt-4.4.185-1.el7.elrepo.x86_64.rp# 查看默认启动顺序[root@localhost ~]# awk -F\\&#x27; &#x27;$1==&quot;menuentry &quot; &#123;print $2&#125;&#x27; /etc/grub2.cfgCentOS Linux (5.2.2-1.el7.elrepo.x86_64) 7 (Core)CentOS Linux (4.4.182-1.el7.elrepo.x86_64) 7 (Core)CentOS Linux (3.10.0-957.21.3.el7.x86_64) 7 (Core)CentOS Linux (3.10.0-957.10.1.el7.x86_64) 7 (Core)CentOS Linux (3.10.0-327.el7.x86_64) 7 (Core)CentOS Linux (0-rescue-e34fb4f1527b4f2d9fc75b77c016b6e7) 7 (Core)由上面可以看出新内核(4.12.4)目前位置在0，原来的内核(3.10.0)目前位置在1# 设置默认启动[root@localhost ~]# grub2-set-default 0 // 0代表当前第一行，也就是4.12.4版本# 重启验证 7.nginx日志访问量前十的ip怎么统计？ 1awk &#x27;&#123;array[$1]++&#125;END&#123;for (ip in array)print ip,array[ip]&#125;&#x27; access.log |sort -k2 -rn|head 8.如何删除&#x2F;var&#x2F;log&#x2F;下.log结尾的30天前的日志？ 1find /var/log/ -type f -name .*.log -mtime 30|xargs rm -f 9.ansible有哪些模块？功能是什么？ 模块 功能 copy 拷贝文件到被控端 cron 定时任务 fetch 拷贝被控端文件到本地 file 文件模块 group 用户组模块 user 用户模块 hostname 主机名模块 script 脚本模块 service 服务启动模块 command 远程执行命令模块 shell 远程执行命令模块，command高级用法 yum 安装包组模块 setup 查看主机系统信息 10.nginx为什么比apache快？ nginx采用epoll模型 apache采用select模型 11. 四层负载和七层负载区别是什么？ 四层基于IP+端口进行转发 七层就是基于URL等应用层信息的负载均衡 12. lvs有哪些工作模式？哪个性能高？ dr：直接路由模式，请求由 LVS 接受，由真实提供服务的服务器直接返回给用户，返回的时候不经过 LVS。（性能最高） tun：隧道模式，客户端将访问vip报文发送给LVS服务器。LVS服务器将请求报文重新封装，发送给后端真实服务器。后端真实服务器将请求报文解封，在确认自身有vip之后进行请求处理。后端真实服务器在处理完数据请求后，直接响应客户端。 nat：网络报的进出都要经过 LVS 的处理。LVS 需要作为 RS 的网关。当包到达 LVS 时，LVS 做目标地址转换（DNAT），将目标 IP 改为 RS 的 IP。RS 接收到包以后，仿佛是客户端直接发给它的一样。RS 处理完，返回响应时，源 IP 是 RS IP，目标 IP 是客户端的 IP。这时 RS 的包通过网关（LVS）中转，LVS 会做源地址转换（SNAT），将包的源地址改为 VIP，这样，这个包对客户端看起来就仿佛是 LVS 直接返回给它的。客户端无法感知到后端 RS 的存在。 fullnat模式：fullnat模式和nat模式相似，但是与nat不同的是nat模式只做了两次地址转换，fullnat模式却做了四次。 13. tomcat各个目录含义，如何修改端口，如何修改内存数？ bin 存放tomcat命令 conf 存放tomcat配置文件 lib 存放tomcat运行需要加载的jar包 log 存在Tomcat运行产生的日志 temp 运行过程中产生的临时文件 webapps 站点目录 work 存放tomcat运行时的编译后的文件 conf&#x2F;server.xml 修改端口号 bin&#x2F;catalina.sh 修改jvm内存 14. nginx反向代理时，如何使后端获取真正的访问来源ip？ 12345# 在location配置段添加以下内容：proxy_set_header Host $http_host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header X-Forwarded-Proto $scheme; 15. nginx负载均衡算法有哪些？ rr 轮训 weight 加权轮训 ip_hash 静态调度算法 fair 动态调度算法 url_hash url哈希 leat_conn 最小连接数 16. 如何进行压力测试？ 例如：模拟10个用户，对百度首页发起总共100次请求。 12# 测试命令：ab -n 100 -c 10 https://www.baidu.com/index.htm 17. curl命令如何发送https请求？如何查看response头信息？如何发送get和post表单信息？ 发送https请求： 1curl --tlsv1 &#x27;https://www.bitstamp.net/api/v2/transactions/btcusd/&#x27; response头信息 ：curl -I get：curl 请求地址?key1&#x3D;value1&amp;key2&#x3D;value2&amp;key3&#x3D;value3 post：curl -d “key1&#x3D;value1&amp;key2&#x3D;value2&amp;key3&#x3D;value3” 二、mysql1. 索引的为什么使查询加快？有啥缺点？默认的方式是根据搜索条件进行全表扫描，遇到匹配条件的就加入搜索结果集合。如果我们对某一字段增加索引，查询时就会先去索引列表中一次定位到特定值的行数，大大减少遍历匹配的行数，所以能明显增加查询的速度缺点： 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加 索引需要占物理空间，除了数据表占用数据空间之外，每一个索引还要占用一定的物理空间，如果需要建立聚簇索引，那么需要占用的空间会更大 以表中的数据进行增、删、改的时候，索引也要动态的维护，这就降低了整数的维护速度 2. sql语句左外连接 右外连接 内连接 全连接区别 3. mysql数据备份方式，如何恢复？你们的备份策略是什么？ 物理完全备份 123备份所有数据库文件：/var/lib/mysql/*备份所有binlog文件: /var/lib/mysql/mysql-bin.*备份选项文件: /etc/my.cnf mysqldump逻辑备份 1mysqldump -uroot -p --all-databases &gt; /backup/mysqldump/all.db 物理备份恢复 123#先把原来的数据目录改名mv /var/lib/mysql /var/lib/mysql.old cp -a /backups/mysql /var/lib 逻辑备份数据恢复 12mysql &gt; use db_namemysql &gt; source /backup/mysqldump/db_name.db 4. 如何配置数据库主从同步，实际工作中是否遇到数据不一致问题？如何解决？为每个服务器配置唯一值的server-id 主库 123开启binlog日志创建主从复制用户查看master的状态 从库 12change master to设置主库信息start slave开始复制 5. mysql约束有哪些？ 非空约束 唯一约束 主键约束 外键约束 6. 二进制日志（binlog）用途？BINLOG记录数据库的变更过程。例如创建数据库、建表、修改表等DDL操作、以及数据表的相关DML操作，这些操作会导致数据库产生变化，开启binlog以后导致数据库产生变化的操作会按照时间顺序以“事件”的形式记录到binlog二进制文件中。 7. mysql数据引擎有哪些？ 常用的 myisam、innodb 区别： （1）InnoDB 支持事务，MyISAM 不支持，这一点是非常之重要。事务是一种高级的处理方式，如在一些列增删改中只要哪个出错还可以回滚还原，而 MyISAM就不可以了；（2）MyISAM 适合查询以及插入为主的应用，InnoDB 适合频繁修改以及涉及到安全性较高的应用；（3）InnoDB 支持外键，MyISAM 不支持；（4）MyISAM 是默认引擎，InnoDB 需要指定；（5）InnoDB 不支持 FULLTEXT 类型的索引；（6）InnoDB 中不保存表的行数，如 select count(*) from table 时，InnoDB；需要扫描一遍整个表来计算有多少行，但是 MyISAM 只要简单的读出保存好的行数即可。注意的是，当 count()*语句包含 where 条件时 MyISAM 也需要扫描整个表；（7）对于自增长的字段，InnoDB 中必须包含只有该字段的索引，但是在 MyISAM表中可以和其他字段一起建立联合索引；（8）清空整个表时，InnoDB 是一行一行的删除，效率非常慢。MyISAM 则会重建表；（9）InnoDB 支持行锁（某些情况下还是锁整表，如 update table set a&#x3D;1 where user like ‘%lee%’ 8. 如何查询mysql数据库存放路径？ myisam 123.frm文件：保护表的定义.myd：保存表的数据.myi：表的索引文件 9. mysql数据库文件后缀名有哪些？用途什么？ myisam 123.frm文件：保护表的定义.myd：保存表的数据.myi：表的索引文件 innodb 12.frm：保存表的定义.ibd：表空间 10. 如何修改数据库用户的密码？ mysql8之前 123set password for 用户名@localhost = password(&#x27;新密码&#x27;); mysqladmin -u用户名 -p旧密码 password 新密码 update user set password=password(&#x27;123&#x27;) where user=&#x27;root&#x27; and host=&#x27;localhost&#x27;; mysql8之后 1234567# mysql8初始对密码要求高，简单的字符串不让改。先改成:MyNewPass@123;alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;MyNewPass@123&#x27;;# 降低密码难度set global validate_password.policy=0;set global validate_password.length=4;# 修改成简易密码alter user &#x27;root&#x27;@&#x27;localhost&#x27;IDENTIFIED BY &#x27;1111&#x27;; 11. 如何修改用户权限？如何查看？ 授权： 1grant all on *.* to user@&#x27;%&#x27; identified by &#x27;passwd&#x27; 查看权限 1show grants for user@&#x27;%&#x27;; 三、nosql1. redis数据持久化有哪些方式？ rdb aof 2. redis集群方案有哪些？ 官方cluster方案 twemproxy代理方案 哨兵模式 codis客户端分片 3. redis如何进行数据备份与恢复？ 备份 12redis 127.0.0.1:6379&gt; SAVE创建 redis 备份文件也可以使用命令 BGSAVE，该命令在后台执行。 还原 12只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可redis 127.0.0.1:6379&gt; CONFIG GET dir 4. MongoDB如何进行数据备份？12mongoexport / mongoimportmongodump / mongorestore 5. kafka为何比redis rabbitmq快？ https://www.zhihu.com/question/22480085 四、docker1. dockerfile有哪些关键字？用途是什么？ 2.如何减小dockerfile生成镜像体积？ 尽量选取满足需求但较小的基础系统镜像，例如大部分时候可以选择debian:wheezy或debian:jessie镜像，仅有不足百兆大小； 清理编译生成文件、安装包的缓存等临时文件； 安装各个软件时候要指定准确的版本号，并避免引入不需要的依赖； 从安全角度考虑，应用要尽量使用系统的库和依赖； 如果安装应用时候需要配置一些特殊的环境变量，在安装后要还原不需要保持的变量值； 3. dockerfile中CMD与ENTRYPOINT区别是什么？ CMD 和 ENTRYPOINT 指令都是用来指定容器启动时运行的命令。 指定 ENTRYPOINT 指令为 exec 模式时，CMD指定的参数会作为参数添加到 ENTRYPOINT 指定命令的参数列表中。 4. dockerfile中COPY和ADD区别是什么？ COPY指令和ADD指令都可以将主机上的资源复制或加入到容器镜像中 区别是ADD可以从 远程URL中的资源不会被解压缩。 如果是本地的压缩包ADD进去会被解压缩 5. docker的cs架构组件有哪些？ 6. docker网络类型有哪些？ host模式 container模式 none模式 bridge模式 7. 如何配置docker远程访问？ vim &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service 在ExecStart&#x3D;后添加配置，注意，需要先空格后，再输入 -H tcp:&#x2F;&#x2F;0.0.0.0:2375 -H unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock 8. docker核心namespace CGroups 联合文件系统功能是什么？ namespace：资源隔离 cgroup：资源控制 联合文件系统：支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下 9. 命令相关：导入导出镜像，进入容器，设置重启容器策略，查看镜像环境变量，查看容器占用资源 导入镜像 docker load -i xx.tar 导出镜像docker save -o xx.tar image_name 进入容器docker exec -it 容器命令 &#x2F;bin&#x2F;bash 设置容器重启策略启动时 –restart选项 查看容器环境变量 docker exec {containerID} env 查看容器资源占用docker stats test2 10. 构建镜像有哪些方式？ dockerfile 容器提交为镜像 11. docker和vmware虚拟化区别？","categories":[{"name":"运维工程师面经","slug":"运维工程师面经","permalink":"http://snippet.itshare.work/categories/%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E7%BB%8F/"}],"tags":[{"name":"运维工程师基础面试题目","slug":"运维工程师基础面试题目","permalink":"http://snippet.itshare.work/tags/%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE/"}],"keywords":[{"name":"运维工程师面经","slug":"运维工程师面经","permalink":"http://snippet.itshare.work/categories/%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E7%BB%8F/"}]},{"title":"网络管理配置","slug":"network","date":"2022-08-21T13:33:05.000Z","updated":"2022-12-16T14:58:56.658Z","comments":true,"path":"2022/08/21/network/","link":"","permalink":"http://snippet.itshare.work/2022/08/21/network/","excerpt":"计算机网络是一组计算机或网络设备通过有形的线缆或者无形的媒介如无线，按照一定的规则，进行通信的集合。","text":"1、网络配置基本网络配置将Linux主机接入到网络，需要配置网络相关设置一般包括如下内容： 主机名 IP&#x2F;netmask 路由：默认网关 DNS服务器 主DNS服务器 次DNS服务器 第三个DNS服务器 1.1 修改主机名称 CentOs6 及之前的版本 12345678910111213141516171819# 修改 /etc/sysconfig/network文件HOSTNAME的值[root@centos6 sysconfig]# cat /etc/sysconfig/networkNETWORKING=yesHOSTNAME=centos6[root@centos6 sysconfig]# # 修改hostname的值为centos6.mg.du[root@centos6 sysconfig]# vi /etc/sysconfig/network# 修改后不会马上生效,需要使用hostname命令重写一下[root@centos6 sysconfig]# hostname centos6.mg.du# 重启一下看主机名称是否修改成功[root@centos6 sysconfig]# reboot# hostname命令查看主机名称[root@centos6 ~]# hostnamecentos6.mg.du[root@centos6 ~]# CentOs7 及之后的版本 12345678910# centos7 之后的版本主机名称文件 /etc/hostname[root@centos7 ~]# cat /etc/hostname centos7[root@centos7 ~]# # centos7 之后的版本直接使用命令修改主机名称[root@centos7 ~]# hostnamectl set-hostname centos7.mg[root@centos7 ~]# hostnamecentos7.mg[root@centos7 ~]# ubuntu修改主机名称 1234567# 查看主机名称配置文件root@ubuntu200404-1:~# cat /etc/hostname ubuntu200404-1root@ubuntu200404-1:~# # 修改主机名称可以直接修改/etc/hostname文件，也可以直接使用命令修改hostnamectl set-hostname 主机名 1.2 网卡名称1.2.1 centos 6之前版本的网卡名称接口命名方式：CentOS 6 12以太网： eth[0,1,2,···]ppp: ppp[0,1,2,···] 网络接口识别并命名相关的udev配置文件 1/etc/udev/rules.d/70-persistent-net.rules 查看网卡 12dmesg |grep –i ethethtool -i eth0 卸载网卡驱动 12modprobe -r e1000rmmod e1000 装载网卡驱动 1modprobe e1000 范例：临时修改网卡名称 123[root@centos6 ~]#ip link set eth0 down[root@centos6 ~]#ip link set eth0 name abc[root@centos6 ~]#ip link set abc up 1.2.2 Centos7 版本之后的网卡配置参考文档 123https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/consistent-network-interface-device-naming_configuring-and-managing-networking CentOS 6之前，网络接口使用连续号码命名：eth0、eth1等,当增加或删除网卡时，名称可能会发生变化CentOS 7 以上版使用基于硬件，设备拓扑和设置类型命名,可以保持网卡名称的稳定CentOS 8 中已弃用network.service，采用NetworkManager（NM）为网卡启用命令。CentOS 8 仍可以安装network.service作为网卡服务，只是默认没有安装，具体方法为： dnf install network-scripts ，不过官方已明确在下一个大版本中，将彻底放弃network.service，不建议继续使用network.service管理网络。 systemd对网络设备的命名方式 如果Firmware或BIOS为主板上集成的设备提供的索引信息可用，且可预测则根据此索引进行命 名，如：eno1 如果Firmware或BIOS为PCI-E扩展槽所提供的索引信息可用，且可预测，则根据此索引进行命名， 如：ens1 如果硬件接口的物理位置信息可用，则根据此信息命名，如：enp2s0 如果用户显式启动，也可根据MAC地址进行命名，如：enx2387a1dc56 上述均不可用时，则使用传统命名机制 基于BIOS支持启用biosdevname软件 12内置网卡：em1,em2pci卡：pYpX Y：slot ,X:port 网卡组成格式 1234567en: Ethernet 有线局域网wl: wlan 无线局域网ww: wwan无线广域网o&lt;index&gt;: 集成设备的设备索引号s&lt;slot&gt;: 扩展槽的索引号x&lt;MAC&gt;: 基于MAC地址的命名p&lt;bus&gt;s&lt;slot&gt;: enp2s1 使用传统方式命名 （1）编辑&#x2F;etc&#x2F;default&#x2F;grub配置文件 centos7 1GRUB_CMDLINE_LINUX=&quot;net.ifnames=0 biosdevname=0&quot; ubuntu (2) 为grub2生成其配置文件 centos7 1[root@centos7 ~]# grub2-mkconfig -o /boot/grub2/grub.cfg ubuntu 1grub-mkconfig -o /boot/grub/grub.cfg (3) 重启 1reboot 自定义网卡名称 123456[root@centos8 ~]# vi /etc/default/grubGRUB_CMDLINE_LINUX=&quot;net.ifnames.prefix=yuankun&quot;[root@centos8 ~]# grub2-mkconfig -o /boot/grub2/grub.cfg[root@centos8 ~]# reboot 1.3 网络配置文件网络基本配置文件 IP、MASK、GW、DNS相关的配置文件： 1/etc/sysconfig/network-scripts/ifcfg-IFACE 配置参考文件 1/usr/share/doc/initcripts-*/sysconfig.txt 常用配置 设置 说明 TYPE 接口类型；常见有的Ethernet, Bridge NAME 此配置文件应用到的设备 DEVICE 设备名 HWADDR 对应的设备的MAC地址 UUID 设备的唯一标识 BOOTPROTO 激活此设备时使用的地址配置协议，常用的dhcp，static, none, bootp IPADDR 指明IP地址 NETMASK 子网掩码,如:255.255.255.0 PREFIX 网络ID的位数, 如:24 GATEWAY 默认网关 DNS1 第一个DNS服务器地址 DNS2 第二个DNS服务器地址 DOMAIN 主机不完整时，自动搜索的域名后缀 ONBOOT 在系统引导时是否激活此设备 USERCTL 普通用户是否可控制此设备 PEERDNS 如果BOOTPROTO的值为“dhcp”，YES将允许dhcp server分配的dns服务器信息直接覆盖至&#x2F;etc&#x2F;resolv.conf文件，NO不允许修改resolv.conf NM_CONTROLLED NM是NetworkManager的简写，此网卡是否接受NM控制 范例 修改&#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-IFACE 必须以ifcfg-开头，为了规范一般后面跟网卡名 配置文件写入内容 1234567891011121314# 动态获取ip地址DEVICE=eth0NAME=eth0BOOTPROTO=dhcp# 静态获取IP地址DEVICE=eth0NAME=eth0BOOTPROTO=staticIPADDR=192.168.179.129PREFIX=24GATEWAY=192.168.179.1DNS1=192.168.179.1DNS2=180.76.76.76 centos8还需要执行以下两条命令才会生效 123CentOS8和rockynmcli connnection reloadnmcli connnettion up eth0 扩展：CentOS网卡配置文件生效方法 1234567CentOS6service network restartCentOS7systemctl restart network# 通用方法 重启reboot 1.4 ifconfig命令来自于net-tools包，建议使用 ip 代替 1234567#清除eth0上面的IP地址[root@centos8 ~]#ifconfig eth0 0.0.0.0#启用和禁用网卡[root@centos8 ~]#ifconfig eth0 down[root@centos8 ~]#ifconfig eth0 up#对一个网卡设置多个IP地址[root@centos8 ~]#ifconfig eth0:1 172.16.0.8/24 1.5 route命令路由表管理命令路由表主要构成: Destination: 目标网络ID,表示可以到达的目标网络ID,0.0.0.0&#x2F;0 表示所有未知网络,又称为默认路由,优先级最低 Genmask:目标网络对应的netmask Iface: 到达对应网络,应该从当前主机哪个网卡发送出来 Gateway: 到达非直连的网络,将数据发送到临近(下一个)路由器的临近本主机的接口的IP地址,如果是直连网络,gateway是0.0.0.0 Metric: 开销cost,值越小,路由记录的优先级最高 查看路由表： 12345[root@rocky ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.179.1 0.0.0.0 UG 100 0 0 eth0192.168.179.0 0.0.0.0 255.255.255.0 U 100 0 0 eth0 添加路由：route add 1route add [-net|-host|default] target [netmask Nm] [gw GW] [[dev] If] 删除路由route del 1route del [-net|-host] target [gw Gw] [netmask Nm] [[dev] If] 1.6 ubuntu网络配置1.6.1 修改主机名 方法一 修改配置文件 1# /etc/hostname 方法二 1hostnamectl set-hostname 主机名 1.6.2 网卡名称默认ubuntu的网卡名称和 CentOS 7 类似，如：ens33，ens38等修改网卡名称为传统命名方式： 12# 修改配置文件 /etc/default/grubGRUB_CMDLINE_LINUX=&quot;net.ifnames=0&quot; 生成新的grub.cfg文件 1234567grub-mkconfig -o /boot/grub/grub.cfg#或者update-grubgrep net.ifnames /boot/grub/grub.cfg# 重启生效reboot 1.6.3 ubuntu网卡配置 配置自动获取IP 网卡配置文件采用YAML格式,必须以 &#x2F;etc&#x2F;netplan&#x2F;XXX.yaml 文件命名方式存放可以每个网卡对应一个单独的配置文件,也可以将所有网卡都放在一个配置文件里 范例 12345678910root@ubuntu200404-1:~# cat /etc/netplan/eth0.yaml # This is the network config written by &#x27;subiquity&#x27;network: ethernets: eth0: dhcp4: true version: 2 # 修改网卡配置文件后需要执行命令生效 netplan apply 配置静态IP 1234567891011121314151617root@ubuntu200404-1:/etc/netplan# cat eth1.yaml # This is the network config written by &#x27;subiquity&#x27;network: ethernets: eth1: addresses: - 192.168.179.139/24 gateway4: 192.168.0.2 nameservers: search: [baidu.com] # DNS addresses: [180.76.76.76] version: 2 # 修改网卡配置文件后需要执行命令生效 netplan apply 查看ip和网关 12345678910111213141516171819202122232425262728293031# 查看IProot@ubuntu200404-1:/etc/netplan# ip address1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:79:b0:80 brd ff:ff:ff:ff:ff:ff inet 192.168.179.138/24 brd 192.168.179.255 scope global dynamic eth0 valid_lft 1698sec preferred_lft 1698sec inet6 fe80::20c:29ff:fe79:b080/64 scope link valid_lft forever preferred_lft forever3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 00:0c:29:79:b0:8a brd ff:ff:ff:ff:ff:ff inet 192.168.179.139/24 brd 192.168.179.255 scope global eth1 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe79:b08a/64 scope link valid_lft forever preferred_lft foreverroot@ubuntu200404-1:/etc/netplan# # 查看网关root@ubuntu200404-1:/etc/netplan# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 192.168.179.2 0.0.0.0 UG 100 0 0 eth0192.168.179.0 0.0.0.0 255.255.255.0 U 0 0 0 eth1192.168.179.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0192.168.179.2 0.0.0.0 255.255.255.255 UH 100 0 0 eth0root@ubuntu200404-1:/etc/netplan# 查看DNS 12root@ubuntu2004:~# resolvectl status #Ubuntu 20.04新命令root@ubuntu1804:~# systemd-resolve --status","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"软件管理","slug":"软件管理","date":"2022-08-08T13:05:59.000Z","updated":"2022-12-16T14:56:58.112Z","comments":true,"path":"2022/08/08/软件管理/","link":"","permalink":"http://snippet.itshare.work/2022/08/08/%E8%BD%AF%E4%BB%B6%E7%AE%A1%E7%90%86/","excerpt":"Redhat和Centos中软件管理是依靠软件包管理器(RPM)来实现的;RPM(Redhat Package Manager)软件包管理器提供了在Linux操作系统中安装、升级、卸载的方法，并提供对系统中的软件状态信息的查询；除了这些功能外，RPM软件包管理器还提供了制作软件包的功能。","text":"1、软件管理简介Redhat和Centos中软件管理是依靠软件包管理器(RPM)来实现的 RPM(Redhat Package Manager)软件包管理器提供了在Linux操作系统中安装、升级、卸载的方法，并提供对系统中的软件状态信息的查询；除了这些功能外，RPM软件包管理器还提供了制作软件包的功能 2、软件包管理器简介2.1 软件包管理器的职责 将二进制文件、库文件、配置文件、帮助文件打包成一个文件 安装软件时按需将二进制、库文件、配置文件、帮助文件放到相应的位置 生成数据库，追踪所安装的每一个文件 软件卸载时根据安装时生成的数据库将相应的文件删除 2.2 软件包管理器的核心功能 制作软件包 安装软件 卸载软件 升级软件 查询软件 校验软件 3、软件包简介3.1 软件包组成 软件包的组成清单 文件清单 安装或卸载的运行脚本 数据库 程序包名称及版本 依赖关系 功能说明 安装生成的各个文件的路径及校验码信息 3.2 软件包分类源码格式特点：需要编译成二进制格式才能进行 命名方式：name-VERSION.tar.gz VERSION：主版本号.次版本号.系统发行版本 二进制格式特点：编译好的，安装之后可以直接运行 软件的作者下载软件的源码，编译配置为二进制软件包 Redhat和Centos中使用的二进制包为rpm包 源码格式和二进制格式的区别 源码格式的包编译为二进制包时可以选择需要的特性，如果未选择，则编译后安装后的软件就不会有相应的功能 源码包在编译成为二进制包时可以实现软件功能的定制 二进制包的本版落后于源码包。 4、rpm简介Redhat和Centos中二进制包的扩展包为.rpm，这是由红帽公司最先发布的一种用来打包软件的文件格式，我们叫做rpm包；RPM软件包管理器就是管理rpm包 4.1 rpm包命名规范 5、软件包的获取途径5.1 系统发行的光盘Linux的IOS镜像文件自带了非常多的系统扩展RPM安装包，且这些软件版本最适合当前Linux系统IOS镜像文件自带的扩展RPM安装包的存放目录为：Packages使用IOS镜像文件自带的扩展RPM安装包前必须先挂载ISO镜像，挂在方法如下： 123456789101112131415161718192021# 创建挂载点，挂载光盘镜像到挂载点[root@jlin ~]# mkdir /mnt/cdrom[root@jlin ~]# mount /dev/sr0 /mnt/cdrom/# 复制挂载点里面所有的文件到/media/目录，避免光盘断开连接就读取不到扩展RPM安装包[root@jlin ~]# cp -r /mnt/cdrom/ /media/[root@jlin ~]# cd /media/cdrom/[root@jlin cdrom]# ll总用量 320-rw-r--r-- 1 root root 14 7月 10 08:27 CentOS_BuildTagdrwxr-xr-x 3 root root 35 7月 10 08:27 EFI-rw-r--r-- 1 root root 227 7月 10 08:27 EULA-rw-r--r-- 1 root root 18009 7月 10 08:27 GPLdrwxr-xr-x 3 root root 57 7月 10 08:27 imagesdrwxr-xr-x 2 root root 198 7月 10 08:27 isolinuxdrwxr-xr-x 2 root root 43 7月 10 08:27 LiveOSdrwxr-xr-x 2 root root 221184 7月 10 08:29 Packagesdrwxr-xr-x 2 root root 4096 7月 10 08:29 repodata-rw-r--r-- 1 root root 1690 7月 10 08:29 RPM-GPG-KEY-CentOS-7-rw-r--r-- 1 root root 1690 7月 10 08:29 RPM-GPG-KEY-CentOS-Testing-7-r--r--r-- 1 root root 2883 7月 10 08:29 TRANS.TBL 5.2 开源镜像站开源镜像站上会存放RPM安装包 阿里巴巴开源镜像站 http://mirrors.aliyun.com 网易开源镜像站 http://mirrors.163.com 清华大学开源镜像站 https://mirrors.tuna.tsinghua.edu.cn 5.3 搜索引擎有一些搜索引擎直接提供rpm包搜索功能 rpmfind http://rpmfind.net rpm pbone http://rpm.pbone.net pkgs http://pkgs.org/ 6、rpm包管理6.1 RPM包安装12345678910111213141516171819202122232425262728293031323334353637// 语法：rpm -ivh /PATH/TO/PACKAGE_FILE ...// 选项：-i：安装-v：显示详细信息-h：显示安装进度条--test：测试安装，但不真正执行安装过程--nodeps：忽略依赖关系--force：强行安装，可以实现重装或降级--replacepkgs：重新安装，替换原有安装--oldpackage：降级--nodigest：不检查包的完整性--nosignature：不检查报的来源合法性--noscripts：不执行rpm包自带的四类脚本： --nopre：不执行rpm包自带的preinstall脚本 --nopost：不执行rpm包自带的postinstall脚本 --nopreun：不执行rpm包自带的preuninstall脚本 --nopostun：不执行rpm包自带的postuninstall脚本 preinstall：安装过程开始之前运行的脚本，标记为%pre：--nopre postinstall：安装过程完成之后运行的脚本，标记为%post：--nopost preuninstall：卸载过程开始执行之前运行的脚本，标记为%preun：--nopreun postunistall：写在过程完成之后运行的脚本，标记为%postrun：--nopostun// 安装软件包，需要指定软件包绝对路径[root@jlin ~]# rpm -ivh /mnt/cdrom/Packages/tree-1.6.0-10.el7.x86_64.rpm// 在软件包所在目录下可以不指定绝对路径[root@jlin ~]# cd /mnt/cdrom/Packages/[root@jlin Packages]# rpm -ivh tree-1.6.0-10.el7.x86_64.rpm// 测试一个软件包是否能在该系统上安装[root@jlin ~]# rpm -ivh --test /mnt/cdrom/Packages/tree-1.6.0-10.el7.x86_64.rpm// 如果软件包已经安装，强制再次安装[root@jlin ~]# rpm -ivh --force /mnt/cdrom/Packages/tree-1.6.0-10.el7.x86_64.rpm// 安装httpd服务需要依赖其他组件，使用--nodeps可忽略以来强制安装[root@jlin ~]# rpm -ivh --nodeps /mnt/cdrom/Packages/httpd-2.4.6-80.el7.centos.x86_64.rpm 6.2 RPM包查询12345678910111213141516171819202122232425// 查询httpd的rpm包是否安装[root@jlin ~]# rpm -q httpd// 模糊查找系统已安装的rpm包[root@jlin ~]# rpm -qa | grep ftp// 查询已安装的httpd软件包相关信息[root@jlin ~]# rpm -qi httpd// 查询已安装的rpm包生成的文件[root@jlin ~]# rpm -ql httpd// 查询已安装的rpm包生成的配置文件所有[root@jlin ~]# rpm -qc httpd// 查询配置文件或命令来自于哪个rpm包[root@jlin ~]# rpm -qf /etc/httpd/httpd.conf[root@jlin ~]# rpm -qf /usr/sbin/httpd// 查询未安装的软件包会产生哪些文件[root@jlin ~]# rpm -qpl / mnt/Packages/httpd-2.4.6-80.el7.centos.x86_64.rpm// 查询未安装的软件包的说明信息[root@jlin ~]# rpm -qpi /mnt/Packages/httpd-2.4.6-80.el7.centos.x86_64.rpm 6.4 RPM包升级12// 升级tree软件包[root@jlin ~]# rpm -Uvh /mnt/Packages/httpd-2.4.6-80.el7.centos.x86_64.rpm 6.5 RPM包卸载123// 先查询，然后卸载[root@jlin ~]# rpm -qa lgrep httpd[root@jlin ~]# rpm -e httpd 6.6 RPM包校验1234567891011// 校验已经安装的软件包的文件是否被修改；如果执行以下命令无内容输出说明安装的软件[root@jlin ~]# rpm -v vsftpdS #文件的容量大小是否被改变M #文件的类型或者文件的属性是否被修改5 #MD5加密的内容已经不同D #装置的主/次代码已经改变L #路径已经被改变U #文件的所属主已被修改G #文件的所属组已被修改T #文件的创建时间已被改变 6.7 RPM重建数据库1234567// 数据库信息在/var/lib/rpm目录// 重建数据库，重建Packages数据库，一定会重建rpm --rebuilddb// 初始化数据库，重建所有数据库，没有才建立，有就不建立rpm --initdb 6.8 检查软件包来源合法性123456789101112131415加密类型: 对称加密 #加密解密使用同一个密钥 公钥加密 #一对密钥，公钥和私钥。公钥隐含于私钥中，可以提取出来并公布出去 单向加密 #只能加密不能解密// 红帽官方公钥存放位置/etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release// 检查指定rpm包合法性，出现oK字样表示包没问题rpm -K PACKAGE_FILE// 导入密钥文件rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release1Centos 7发行版光盘提供的密钥文件名为:RPM-GPG-KEY-Centos-7 7、yum和dnfCentOS 使用 yum, dnf 解决rpm的包依赖关系YUM: Yellowdog Update Modifier，rpm的前端程序，可解决软件包相关依赖性，可在多个库之间定位软件包，up2date的替代工具，CentOS 8 用dnf 代替了yum ,不过保留了和yum的兼容性，配置也是通用的 7.1 yum&#x2F;dnf 工作原理yum&#x2F;dnf 是基于C&#x2F;S 模式yum 服务器存放rpm包和相关包的元数据库yum 客户端访问yum服务器进行安装或查询等yum 实现过程先在yum服务器上创建 yum repository（仓库），在仓库中事先存储了众多rpm包，以及包的相关的元数据文件（放置于特定目录repodata下），当yum客户端利用yum&#x2F;dnf工具进行安装时包时，会自动下载repodata中的元数据，查询远数据是否存在相关的包及依赖关系，自动从仓库中找到相关包下载并安装。 7.2 yum客户端配置yum客户端配置文件 12/etc/yum.conf #为所有仓库提供公共配置/etc/yum.repos.d/*.repo： #为每个仓库的提供配置文件 帮助参考： man 5 yum.confrepo仓库配置文件指向的定义： 1234567891011[repositoryID]name=Some name for this repositorybaseurl=url://path/to/repository/enabled=&#123;1|0&#125;gpgcheck=&#123;1|0&#125;gpgkey=URLenablegroups=&#123;1|0&#125;failovermethod=&#123;roundrobin|priority&#125;roundrobin：意为随机挑选，默认值priority:按顺序访问cost= 默认为1000 yum服务器的baseurl形式 1234file:// 本地路径http://https://ftp:// 注意：yum仓库指向的路径一定必须是repodata目录所在目录相关变量 123456yum的repo配置文件中可用的变量：$releasever: 当前OS的发行版的主版本号，如：8，7，6$arch: CPU架构，如：aarch64, i586, i686，x86_64等$basearch：系统基础平台；i386, x86_64$contentdir：表示目录，比如：centos-8，centos-7$YUM0-$YUM9:自定义变量 7.3 yum命令yum命令的用法 1yum [options] [command] [package ...] yum的命令行选项 12345-y #自动回答为&quot;yes&quot;-q #静默模式--nogpgcheck #禁止进行gpg check--enablerepo=repoidglob #临时启用此处指定的repo，支持通配符，如：&quot;*&quot;--disablerepo=repoidglob #临时禁用此处指定的repo,和上面语句同时使用，放在后面的生效 7.3.1 显示仓库列表1yum repolist [all|enabled|disabled] 范例 7.3.2 显示程序包123yum listyum list [all | glob_exp1] [glob_exp2] [...]yum list &#123;available|installed|updates&#125; [glob_exp1] [...] 范例 123yum listyum list [all | glob_exp1] [glob_exp2] [...]yum list &#123;available|installed|updates&#125; [glob_exp1] [...] 范例：只查看安装的包 123456789101112[root@rocky ~]# yum list installed|headInstalled PackagesNetworkManager.x86_64 1:1.32.10-4.el8 @anacondaNetworkManager-config-server.noarch 1:1.32.10-4.el8 @anacondaNetworkManager-libnm.x86_64 1:1.32.10-4.el8 @anacondaNetworkManager-team.x86_64 1:1.32.10-4.el8 @anacondaNetworkManager-tui.x86_64 1:1.32.10-4.el8 @anacondaacl.x86_64 2.2.53-1.el8.1 @anacondaadcli.x86_64 0.8.2-12.el8 @anacondaalsa-sof-firmware.noarch 1.8-1.el8 @anacondaat.x86_64 3.1.20-11.el8 @anaconda[root@rocky ~]# 范例：查看可以安装的包 12345678910111213[root@rocky ~]# yum list available | headLast metadata expiration check: 2:21:04 ago on Tue 09 Aug 2022 09:50:19 AM CST.Available PackagesCUnit.i686 2.1.3-17.el8 appstreamCUnit.x86_64 2.1.3-17.el8 appstreamGConf2.i686 3.2.6-22.el8 appstreamGConf2.x86_64 3.2.6-22.el8 appstreamHdrHistogram.noarch 2.1.11-3.module+el8.4.0+405+66dfe7da appstreamHdrHistogram-javadoc.noarch 2.1.11-3.module+el8.4.0+405+66dfe7da appstreamHdrHistogram_c.i686 0.9.13-2.el8 appstreamHdrHistogram_c.x86_64 0.9.13-2.el8 appstream[root@rocky ~]# 范例：查看可以升级的包 1yum list updates 范例：查看指定的包 1[root@centos8 ~]#yum list exim","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"Sre云计算作业","slug":"homework","date":"2022-08-07T16:12:00.000Z","updated":"2022-12-16T14:57:52.257Z","comments":true,"path":"2022/08/08/homework/","link":"","permalink":"http://snippet.itshare.work/2022/08/08/homework/","excerpt":"村舍外，古城旁。杖藜徐步转斜阳。殷勤昨夜三更雨，又得浮生一日凉。","text":"第二周作业 运行脚本可以显示出本机的ip地址 如果ip地址中有3这个数字，那么就打印出当前的系统时间 如果ip地址中不含3这个数字，就批量建立用户magedu_00, magedu_01, … magedu_100并且所有用户同属于magedu组 打印出&#x2F;etc&#x2F;passwd这个文件中可以登陆的用户（非&#x2F;usr&#x2F;sbin&#x2F;nologin） yum安装nginx服务，并且启动该服务 12345678910111213141516171819202122232425262728293031323334#!/bin/bash#--------------------#filename:#author:袁坤#data:2022-08-07#--------------------set -e -uIP=`ifconfig -a |grep inet |grep -v inet6 | grep -v 127.0.0.1 | tr -s &quot; &quot; | cut -d &quot; &quot; -f3`echo 本机IP地址为:$&#123;IP&#125;if echo $&#123;I&#125; | grep &#x27;3&#x27;;then echo `date +%Y-%m-%d-%T`else groupadd magedu for i in magedu_&#123;0..100&#125;;do useradd $&#123;i&#125; -g magedu donefi;NOLOGIN=`grep -v &#x27;/usr/sbin/nologin&#x27; /etc/passwd | cut -d &quot;:&quot; -f1`echo $&#123;NOLOGIN&#125;. /etc/os-releaseif [ $ID = &quot;rocky&quot; -o $ID = &quot;centos&quot; ];then echo os is version $&#123;ID&#125; yum -y install nginx &amp;&amp; systemctl start nginxelse [ $ID = &quot;ubuntu&quot; ]; echo os is version $ID apt update &amp;&amp; apt -y install nginx &amp;&amp; systemctl start nginxfi;","categories":[],"tags":[],"keywords":[]},{"title":"磁盘存储和文件系统管理","slug":"Disk","date":"2022-08-07T00:40:59.000Z","updated":"2022-12-16T14:57:27.573Z","comments":true,"path":"2022/08/07/Disk/","link":"","permalink":"http://snippet.itshare.work/2022/08/07/Disk/","excerpt":"磁盘是计算机主要的存储介质，可以存储大量的二进制数据，并且断电后也能保持数据不丢失，使用磁盘存储数据的时候我们可以将磁盘划分成我们所需要的格式来进行使用。","text":"磁盘管理与文件系统前言磁盘是计算机主要的存储介质，可以存储大量的二进制数据，并且断电后也能保持数据不丢失，使用磁盘存储数据的时候我们可以将磁盘划分成我们所需要的格式来进行使用 1. 磁盘结构1、硬盘的物理结构盘片：硬盘有多个盘片，每个盘片有2面磁头：每面有一个磁头 2.硬盘数据结构扇区：磁盘上的每个磁道被等分为若干个弧段，这些弧段便是硬盘的扇区。硬盘的第一个扇区，叫做引导扇区 ，盘片被分为多个扇形区域，每个扇区存放512字节的数据，是硬盘最小的存储单元磁道：当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹就叫做磁道柱面：在有多个盘片构成的盘组中，由不同盘片的面，但处于同一半径圆的多个磁道组成的一个圆柱面 3、磁盘结构硬盘存储容量 &#x3D; 磁头数 x 磁道（柱面）数 x 每道扇区数 x 每扇区字节数（512字节）可以用柱面&#x2F;磁头&#x2F;扇区来唯一定位磁盘上的每一个区域磁盘的接口类型：IDE、SATA、SCSI、SAS、光纤通道用 fdisk -l 查看分区信息 2. 管理存储2.1 磁盘分区2.1.1 为什么分区 优化I&#x2F;O性能 实现磁盘空间配额限制 提高修复速度 隔离系统和程序 安装多个OS 采用不同文件系统 2.1.2 分区方式两种分区方式：MBR，GPT MBR分区 MBR：Master Boot Record，1982年，使用32位表示扇区数，分区不超过2T划分分区的单位：CentOS 5 之前按整柱面划分CentOS 6 版本后可以按Sector划分0磁道0扇区：512bytes446bytes: boot loader 启动相关64bytes：分区表，其中每16bytes标识一个分区2bytes: 55AA，标识位MBR分区中一块硬盘最多有4个主分区，也可以3主分区+1扩展(N个逻辑分区)MBR分区：主和扩展分区对应的1–4，&#x2F;dev&#x2F;sda3，逻辑分区从5开始，&#x2F;dev&#x2F;sda5 问题：利用分区策略相同的另一台主机的分区表来还原和恢复当前主机破环的分区表？ GPT分区GPT：GUID（Globals Unique Identifiers） partition table 支持128个分区，使用64位，支持8Z（512Byte&#x2F;block ）64Z （ 4096Byte&#x2F;block）使用128位UUID(Universally Unique Identifier) 表示磁盘和分区 GPT分区表自动备份在头和尾两份，并有CRC校验位UEFI (Unified Extensible Firmware Interface 统一可扩展固件接口)硬件支持GPT，使得操作系统可以启动 GPT分区结构分为4个区域： GPT头 分区表 GPT分区 备份区域 2.2 管理分区列出块设备 1lsblk 创建分区命令 123fdisk 管理MBR分区gdisk 管理GPT分区parted 高级分区操作，可以是交互或非交互方式 重新设置内存中的内核分区表版本，适合于除了CentOS 6 以外的其它版本 5，7，8 1partprobe 2.2.1 添加并检测新硬盘1、添加新硬盘使用lsblk命令显示出块设备 1234567891011121314root@ubuntu200404:~# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTloop0 7:0 0 61.9M 1 loop /snap/core20/1328loop1 7:1 0 67.2M 1 loop /snap/lxd/21835loop2 7:2 0 62M 1 loop /snap/core20/1587loop3 7:3 0 43.6M 1 loop /snap/snapd/14978loop4 7:4 0 47M 1 loop /snap/snapd/16292loop5 7:5 0 67.8M 1 loop /snap/lxd/22753sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1M 0 part ├─sda2 8:2 0 1.5G 0 part /boot└─sda3 8:3 0 18.5G 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 10G 0 lvm /sr0 11:0 1 1.2G 0 rom 发现并没有检测出来新添加的硬盘 2、检测新硬盘 方法1：可以重启电脑 方法2： 重新扫描存储设备的scsi总线 12# host后面的数字不是固定的，以实际为准root@ubuntu200404:~# echo &#x27;- - -&#x27; &gt; /sys/class/scsi_host/host32/scan 再次使用lsblk命令查看发现已经多了sda的硬盘，说明成功了 123456789101112131415root@ubuntu200404:~# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTloop0 7:0 0 61.9M 1 loop /snap/core20/1328loop1 7:1 0 67.2M 1 loop /snap/lxd/21835loop2 7:2 0 62M 1 loop /snap/core20/1587loop3 7:3 0 43.6M 1 loop /snap/snapd/14978loop4 7:4 0 47M 1 loop /snap/snapd/16292loop5 7:5 0 67.8M 1 loop /snap/lxd/22753sda 8:0 0 20G 0 disk ├─sda1 8:1 0 1M 0 part ├─sda2 8:2 0 1.5G 0 part /boot└─sda3 8:3 0 18.5G 0 part └─ubuntu--vg-ubuntu--lv 253:0 0 10G 0 lvm /sdb 8:16 0 20G 0 disk # 新添加的硬盘 sr0 11:0 1 1.2G 0 rom 2.2.2 partend命令注意：parted的操作都是实时生效的，小心使用 格式: 1parted [选项]... [设备 [命令 [参数]...]...] 范例： 12345parted /dev/sdb mklabel gpt|msdosparted /dev/sdb printparted /dev/sdb mkpart primary 1 200 （默认M）parted /dev/sdb rm 1parted -l 列出所有硬盘分区信息 2.2.3 分区工具fdisk和gdisk123456fdisk -l [-u] [device...] 查看分区fdisk [device...] 管理MBR分区gdisk [device...] 类fdisk 的GPT分区工具# 范例：fdisk /dev/sdb 子命令： 12345678p 分区列表t 更改分区类型n 创建新分区d 删除分区v 校验分区u 转换单位w 保存并退出q 不保存并退出 查看内核是否已经识别新的分区 1cat /proc/partitions CentOS 7,8 同步分区表: 1partprobe 2.3 文件系统2.3.1 文件系统概念文件系统是操作系统用于明确存储设备或分区上的文件的方法和数据结构；即在存储设备上组织文件的方法。操作系统中负责管理和存储文件信息的软件结构称为文件管理系统，简称文件系统从系统角度来看，文件系统是对文件存储设备的空间进行组织和分配，负责文件存储并对存入的文件进行保护和检索的系统。具体地说，它负责为用户建立文件，存入、读出、修改、转储文件，控制文件的存取，安全控制，日志，压缩，加密等支持的文件系统： 1/lib/modules/`uname -r`/kernel/fs (各种文件系统)[https://en.wikipedia.org/wiki/Comparison_of_file_systems] 帮助：man 5 fs 2.3.2 文件系统类型Linux常用文件系统 ext2：Extended file system 适用于那些分区容量不是太大，更新也不频繁的情况，例如 &#x2F;boot 分区 ext3：是 ext2 的改进版本，其支持日志功能，能够帮助系统从非正常关机导致的异常中恢复 ext4：是 ext 文件系统的最新版。提供了很多新的特性，包括纳秒级时间戳、创建和使用巨型文件(16TB)、最大1EB的文件系统，以及速度的提升 xfs：SGI，支持最大8EB的文件系统 swap iso9660 光盘 btrfs（Oracle） reiserfs Windows 常用文件系统 FAT32 NTFS exFAT Unix： FFS（fast） UFS（unix） JFS2 网络文件系统： NFS CIFS 集群文件系统： GFS2 OCFS2（oracle） 分布式文件系统： fastdfs ceph moosefs mogilefs glusterfs Lustre RAW： 裸文件系统,未经处理或者未经格式化产生的文件系统常用的文件系统特性： FAT32 最多只能支持16TB的文件系统和4GB的文件 NTFS 最多只能支持16EB的文件系统和16EB的文件 EXT3 最多只能支持32TB的文件系统和2TB的文件，实际只能容纳2TB的文件系统和16GB的文件 Ext3目前只支持32000个子目录 Ext3文件系统使用32位空间记录块数量和 inode数量 当数据写入到Ext3文件系统中时，Ext3的数据块分配器每次只能分配一个4KB的块 EXT4： EXT4是Linux系统下的日志文件系统，是EXT3文件系统的后继版本 Ext4的文件系统容量达到1EB，而支持单个文件则达到16TB 理论上支持无限数量的子目录 Ext4文件系统使用64位空间记录块数量和 inode数量 Ext4的多块分配器支持一次调用分配多个数据块 修复速度更快 XFS 根据所记录的日志在很短的时间内迅速恢复磁盘文件内容 用优化算法，日志记录对整体文件操作影响非常小 是一个全64-bit的文件系统，最大可以支持8EB的文件系统，而支持单个文件则达到8EB 能以接近裸设备I&#x2F;O的性能存储数据 查前支持的文件系统： 1cat /proc/filesystems 2.3.3 文件系统的组成部分内核中的模块：ext4, xfs, vfatLinux的虚拟文件系统：VFS用户空间的管理工具：mkfs.ext4, mkfs.xfs,mkfs.vfat 2.3.4 文件系统选择管理2.3.4.1 创建文件系统创建文件管理工具 123456789mkfs命令：(1) mkfs.FS_TYPE /dev/DEVICEext4xfsbtrfsvfat(2) mkfs -t FS_TYPE /dev/DEVICE-L &#x27;LABEL&#x27; 设定卷标mke2fs：ext系列文件系统专用管理工具 常用选项： 1234567891011-t &#123;ext2|ext3|ext4|xfs&#125; 指定文件系统类型-b &#123;1024|2048|4096&#125; 指定块 block 大小-L ‘LABEL’ 设置卷标-j 相当于 -t ext3， mkfs.ext3 = mkfs -t ext3 = mke2fs -j = mke2fs -t ext3-i # 为数据空间中每多少个字节创建一个inode；不应该小于block大小-N # 指定分区中创建多少个inode-I 一个inode记录占用的磁盘空间大小，128---4096-m # 默认5%,为管理人员预留空间占总空间的百分比-O FEATURE[,...] 启用指定特性-O ^FEATURE 案例：mkfs.ext4 &#x2F;dev&#x2F;sdb1 12345678910111213root@ubuntu200404:~# mkfs.ext4 /dev/sdb1mke2fs 1.45.5 (07-Jan-2020)Creating filesystem with 2621440 4k blocks and 655360 inodesFilesystem UUID: a7ef4142-26e5-43dd-b9d0-24c4d09155a1Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632Allocating group tables: done Writing inode tables: done Creating journal (16384 blocks): doneWriting superblocks and filesystem accounting information: done root@ubuntu200404:~# 2.3.4.2 查看和管理分区信息blkid 可以查看块设备属性信息格式： 1blkid [OPTION]... [DEVICE] 常用选项： 123-U UUID 根据指定的UUID来查找对应的设备-L LABEL 根据指定的LABEL来查找对应的设备e2label：管理ext系列文件系统的LABEL 1e2label DEVICE [LABEL] 范例 123root@ubuntu200404:~# blkid /dev/sdb1/dev/sdb1: UUID=&quot;a7ef4142-26e5-43dd-b9d0-24c4d09155a1&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;db60ac71-01&quot;root@ubuntu200404:~# 查找分区 12findfs [options] LABEL=&lt;label&gt;findfs [options] UUID=&lt;uuid&gt; tune2fs：重新设定ext系列文件系统可调整参数的值 1234567-l 查看指定文件系统超级块信息；super block-L &#x27;LABEL’ 修改卷标-m # 修预留给管理员的空间百分比-j 将ext2升级为ext3-O 文件系统属性启用或禁用, -O ^has_journal-o 调整文件系统的默认挂载选项，-o ^acl-U UUID 修改UUID号 dumpe2fs：显示ext文件系统信息，将磁盘块分组管理-h：查看超级块信息，不显示分组信息 范例：查看ext文件系统的元数据和块组信息 12345678910111213141516171819202122root@ubuntu200404:~# dumpe2fs /dev/sdb1dumpe2fs 1.45.5 (07-Jan-2020)Filesystem volume name: &lt;none&gt;Last mounted on: &lt;not available&gt;Filesystem UUID: a7ef4142-26e5-43dd-b9d0-24c4d09155a1Filesystem magic number: 0xEF53Filesystem revision #: 1 (dynamic)Filesystem features: has_journal ext_attr resize_inode dir_index filetype extent 64bit flex_bg sparse_super large_file huge_file dir_nlink extra_isize metadata_csumFilesystem flags: signed_directory_hash Default mount options: user_xattr aclFilesystem state: cleanErrors behavior: ContinueFilesystem OS type: LinuxInode count: 655360Block count: 2621440Reserved block count: 131072Free blocks: 2554687Free inodes: 655349First block: 0.................. xfs_info：显示示挂载或已挂载的 xfs 文件系统信息 1xfs_info mountpoint|devname 范例 1xfs_info /dev/sda1 2.3.4.3 文件系统检测和修复文件系统夹故障常发生于死机或者非正常关机之后，挂载为文件系统标记为“no clean”注意：一定不要在挂载状态下执行下面命令修复 fsck: File System Check 12fsck.FS_TYPEfsck -t FS_TYPE 注意：FS_TYPE 一定要与分区上已经文件类型相同 常用选项 12-a 自动修复-r 交互式修复错误 e2fsck：ext系列文件专用的检测修复工具 123-y 自动回答为yes-f 强制修复-p 自动进行安全的修复文件系统问题 用法： 1e2fsck /dev/sdb2 xfs_repair：xfs文件系统专用检测修复工具常用选项： 123-f 修复文件，而设备-n 只检查-d 允许修复只读的挂载设备，在单用户下修复 / 时使用，然后立即reboot 用法： 1xfs_repair /dev/sda1 2.4 挂载挂载:将额外文件系统与根文件系统某现存的目录建立起关联关系，进而使得此目录做为其它文件访问入口的行为卸载:为解除此关联关系的过程把设备关联挂载点：mount Point挂载点下原有文件在挂载完成后会被临时隐藏，因此，挂载点目录一般为空进程正在使用中的设备无法被卸载 2.4.1 挂载文件系统 mount格式 1mount [-fnrsvw] [-t vfstype] [-o options] device mountpoint device：指明要挂载的设备 设备文件：例如:&#x2F;dev&#x2F;sda5 卷标：-L ‘LABEL’, 例如 -L ‘MYDATA’ UUID： -U ‘UUID’：例如 -U ‘0c50523c-43f1-45e7-85c0-a126711d406e’ 伪文件系统名称：proc, sysfs, devtmpfs, configfs mountpoint：挂载点目录必须事先存在，建议使用空目录mount 常用命令选项 12345678910111213141516171819202122232425-t fstype 指定要挂载的设备上的文件系统类型,如:ext4,xfs-r readonly，只读挂载-w read and write, 读写挂载,此为默认设置,可省略-n 不更新/etc/mtab，mount不可见-a 自动挂载所有支持自动挂载的设备(定义在了/etc/fstab文件中，且挂载选项中有auto功能)-L &#x27;LABEL&#x27; 以卷标指定挂载设备-U &#x27;UUID&#x27; 以UUID指定要挂载的设备-B, --bind 绑定目录到另一个目录上-o options：(挂载文件系统的选项)，多个选项使用逗号分隔async 异步模式,内存更改时,写入缓存区buffer,过一段时间再写到磁盘中，效率高，但不安全sync 同步模式,内存更改时，同时写磁盘，安全，但效率低下atime/noatime 包含目录和文件diratime/nodiratime 目录的访问时间戳auto/noauto 是否支持开机自动挂载，是否支持-a选项exec/noexec 是否支持将文件系统上运行应用程序dev/nodev 是否支持在此文件系统上使用设备文件suid/nosuid 是否支持suid和sgid权限remount 重新挂载ro/rw 只读、读写user/nouser 是否允许普通用户挂载此设备，/etc/fstab使用acl/noacl 启用此文件系统上的acl功能loop 使用loop设备_netdev 当网络可用时才对网络资源进行挂载，如：NFS文件系统defaults 相当于rw, suid, dev, exec, auto, nouser, async 挂载规则: 一个挂载点同一时间只能挂载一个设备 一个挂载点同一时间挂载了多个设备，只能看到最后一个设备的数据，其它设备上的数据将被隐藏 一个设备可以同时挂载到多个挂载点 通常挂载点一般是已存在空的目录 范例:挂载案例 12root@ubuntu200404:/data# mount /dev/sdb1 /data/mysql_mount/root@ubuntu200404:/data# df 2.4.2 卸载文件系统 umount卸载时：可使用设备，也可以使用挂载点 1umount 设备名|挂载点 2.4.3 查看挂载情况查看挂载 1234#通过查看/etc/mtab文件显示当前已挂载的所有设备mount#查看内核追踪到的已挂载的所有设备cat /proc/mounts 查看挂载点情况 1findmnt MOUNT_POINT|device 查看正在访问指定文件系统的进程 12lsof MOUNT_POINTfuser -v MOUNT_POINT 终止所有在正访问指定的文件系统的进程 1fuser -km MOUNT_POINT 2.4.4 持久挂载将挂载保存到 &#x2F;etc&#x2F;fstab 中可以下次开机时，自动启用挂载&#x2F;etc&#x2F;fstab格式帮助： 1man 5 fstab 每行定义一个要挂载的文件系统,，其中包括共 6 项 要挂载的设备或伪文件系统设备文件LABEL：LABEL&#x3D;””UUID：UUID&#x3D;””伪文件系统名称：proc, sysfs 挂载点：必须是事先存在的目录 文件系统类型：ext4，xfs，iso9660，nfs，none 挂载选项：defaults ，acl，bind 转储频率：0：不做备份 1：每天转储 2：每隔一天转储 fsck检查的文件系统的顺序：允许的数字是0 1 20：不自检 ，1：首先自检；一般只有rootfs才用 2：非rootfs使用 添加新的挂载项，需要执行下面命令生效 1mount -a 范例：centos7, 8 &#x2F;etc&#x2F;fstab 的分区UUID错误，无法启动* 1234自动进入emergency mode,输入root 密码#cat /proc/mounts 可以查看到/ 以rw方式挂载#vim /etc/fstab#reboot 范例：centos 6 &#x2F;etc&#x2F;fstab 的分区UUID错误，无法启动 1234567如果/etc/fstab 的挂载设备出错，比如文件系统故障，并且文件系统检测项（即第6项为非0），将导致无法启动自动进入emergency mode,输入root 密码#cat /proc/mounts 可以查看到/ 以ro方式挂载，无法直接修改配置文件#mount -o remount,rw /#vim /etc/fstab将故障行的最后1项，即第6项修改为0，开机不检测此项挂载设备的健康性，从而忽略错误，能实现启动 范例：&#x2F;etc&#x2F;fstab格式 1234567891011121314root@ubuntu200404:/data# cat /etc/fstab # /etc/fstab: static file system information.## Use &#x27;blkid&#x27; to print the universally unique identifier for a# device; this may be used with UUID= as a more robust way to name devices# that works even if disks are added and removed. See fstab(5).## &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt;# / was on /dev/ubuntu-vg/ubuntu-lv during curtin installation/dev/disk/by-id/dm-uuid-LVM-3aQ0WgB04ZXwNPYVAYy9ssb3Wd06E34ggUUxCcYQaVwAb0L03K40wpOxbnqqqa3f / ext4 defaults 0 1# /boot was on /dev/sda2 during curtin installation/dev/disk/by-uuid/5e8f9763-2db8-48d0-85e2-a26d76521e2f /boot ext4 defaults 0 1/swap.img none swap sw 0 0root@ubuntu200404:/data# 范例：添加新的挂载点后修改&#x2F;etc&#x2F;fstab文件 123456789101112131415# /etc/fstab: static file system information.# # Use &#x27;blkid&#x27; to print the universally unique identifier for a# device; this may be used with UUID= as a more robust way to name devices# that works even if disks are added and removed. See fstab(5).## &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt;# / was on /dev/ubuntu-vg/ubuntu-lv during curtin installation/dev/disk/by-id/dm-uuid-LVM-3aQ0WgB04ZXwNPYVAYy9ssb3Wd06E34ggUUxCcYQaVwAb0L03K40wpOxbnqqqa3f / ext4 defaults 0 1# /boot was on /dev/sda2 during curtin installation/dev/disk/by-uuid/5e8f9763-2db8-48d0-85e2-a26d76521e2f /boot ext4 defaults 0 1/swap.img none swap sw 0 0# 添加该行后、重启系统UUID=0e850a4a-028d-48b2-aa18-dd8b16090aa6 /data/mysql_mount ext4 defaults 0 0 2.5 处理交换文件和分区2.5.1 swap分区swap交换分区是系统RAM的补充，swap 分区支持虚拟内存。当没有足够的 RAM 保存系统处理的数据时会将数据写入 swap 分区，当系统缺乏 swap 空间时，内核会因 RAM 内存耗尽而终止进程。配置过多 swap 空间会造成存储设备处于分配状态但闲置，造成浪费，过多 swap 空间还会掩盖内存泄露注意：为优化性能，可以将swap 分布存放，或高性能磁盘存放 2.5.2 交换分区实现过程 创建交换分区或者文件 使用mkswap写入特殊签名 在&#x2F;etc&#x2F;fstab文件中添加适当的条目 使用swapon -a 激活交换空间 启用swap分区 1swapon [OPTION]... [DEVICE] 常用选项 123-a #激活所有的交换分区-p PRIORITY #指定优先级(-1到32767之间)，值越大,优先级越高.也可在/etc/fstab文件中的第4列指定：pri=value 范例:创建swap分区 1[root@centos8 ~]#mkswap /dev/sdc1 禁用swap分区 1swapoff [OPTION]... [DEVICE] 范例:禁用swap分区 12[root@centos8 ~]#sed -i.bak &#x27;/swap/d&#x27; /etc/fstab[root@centos8 ~]#swapoff -a 2.5.3 swap的使用策略&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;swappiness 的值决定了当内存占用达到一定的百分比时，会启用swap分区的空间使用规则 123当内存使用率达到100-swappiness时,会启用交换分区简单地说这个参数定义了系统对swap的使用倾向，此值越大表示越倾向于使用swap。可以设为0，这样做并不会禁止对swap的使用，只是最大限度地降低了使用swap的可能性 范例 12#说明：CentOS7和8默认值为30，内存在使用到100-30=70%的时候，就开始出现有交换分区的使用。[root@centos8 ~]# cat /proc/sys/vm/swappiness 2.6 磁盘常见工具2.6.1 df文件系统空间实际真正占用等信息的查看工具 df 1df [OPTION]... [FILE]... 常用选项 12345-H 以10为单位-T 文件系统类型-h human-readable-i inodes instead of blocks-P 以Posix兼容的格式输出 2.6.3 du查看某目录总体空间实际占用状态 du 显示指定目录下面各个子目录的大小,单位为KB 常用选项 12345-a --all 显示所有文件和目录的大小,默认只显示目录大小-h human-readable-s summary--max-depth=# 指定最大目录层级-x, --one-file-system #忽略不在同一个文件系统的目录 面试题 1.df 和 du 区别?什么时候df &gt;du（空分区的时候)df 查看是文件系统的空间使用，包括元数据和数据，删除文件后，如果此文件正在使用，不会立即释放空间;du 查看是文件数据空间使用，不包括元数据，删除文件后空间立即释放。 2.什么时候df &lt; du?目录内挂载有其它分区时的情况 3.当删除文件但不释放空间时,有什么不同?du 查看文件空间释放,df不释放 3. RAID","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"shell编程","slug":"shell编程","date":"2022-08-03T14:23:02.000Z","updated":"2022-12-16T14:59:07.603Z","comments":true,"path":"2022/08/03/shell编程/","link":"","permalink":"http://snippet.itshare.work/2022/08/03/shell%E7%BC%96%E7%A8%8B/","excerpt":"shell 是操作系统的最外层。shell 合并编程语言以控制进程和文件，以及启动和控制其它程序。shell 通过提示您输入，向操作系统解释该输入，然后处理来自操作系统的任何结果输出来管理您与操作系统之间的交互。","text":"内容简述shell 是操作系统的最外层。shell 合并编程语言以控制进程和文件，以及启动和控制其它程序。shell 通过提示您输入，向操作系统解释该输入，然后处理来自操作系统的任何结果输出来管理您与操作系统之间的交互。 1.编程基础Linus：Talk is cheap, show me the code 1.1 程序组成 程序：算法+数据结构 算法：处理数据的方式 数据结构：数据在计算机中的类型和组织方式 数据：是程序的核心，程序为数据提供服务 1.2 程序编程风格 面向过程语言 做一件事情，排出个步骤，第一步干什么，第二步干什么，如果出现情况A，做什么处理，如果出现了情况B，做什么处理 问题规模小，可以步骤化，按部就班处理 以指令为中心，数据服务于指令 C，shell 面向对象语言 将编程看成是一个事物，对外界来说，事物是直接使用的,不用关心事物内部的情况。而编程就是设置事物能够完成功能。 一种认识世界、分析世界的方法论。将万事万物抽象为各种对象 类是抽象的概念，是万事万物的抽象，是一类事物的共同特征的集合 对象是类的具体实现，是一个实体 问题规模大，复杂系统 以数据为中心，指令服务于数据 java，C#，python，golang等 1.3 编程语言编程语言排行榜链接 1https://www.tiobe.com/tiobe-index/ 计算机：运行二进制指令编程语言：人与计算机之间交互的语言。分为两种：低级语言和高级语言 低级编程语言： 机器：二进制的0和1的序列，称为机器指令。与自然语言差异太大，难懂、难写 汇编：用一些助记符号替代机器指令，称为汇编语言如：ADD A,B 将寄存器A的数与寄存器B的数相加得到的数放到寄存器A中汇编语言写好的程序需要汇编程序转换成机器指令汇编语言稍微好理解，即机器指令对应的助记符，助记符更接近自然语言 高级编程语言： 编译：高级语言–&gt;编译器–&gt;机器代码文件–&gt;执行，如：C，C++ 解释：高级语言–&gt;执行–&gt;解释器–&gt;机器代码，如：shell，python，php，JavaScript，perl 编译和解释型语言 1.4 编程逻辑处理方式 三种处理逻辑 顺序执行：程序按从上到下顺序执行 选择执行：程序执行过程中，根据条件的不同，进行选择不同分支继续执行 循环执行：程序执行过程中需要重复执行多次某段语句 2.shell 脚本语言的基本用法2.1 shell 脚本的用途 将简单的命令组合完成复杂的工作,自动化执行命令,提高工作效率 减少手工命令的输入，一定程度上避免人为错误 将软件或应用的安装及配置实现标准化 用于实现日常性的,重复性的,非交互式的运维工作,如:文件打包压缩备份,监控系统运行状态并实现告警等 2.2 shell脚本基本结构shell脚本编程：是基于过程式、解释执行的语言 编程语言的基本结构： 各种系统命令的组合 数据存储：变量、数组 表达式：a + b 控制语句：if shell脚本：包含一些命令或声明，并符合一定格式的文本文件格式要求：首行shebang机制 12345#!/bin/bash#!/usr/bin/python#!/usr/bin/perl#!/usr/bin/ruby#!/usr/bin/lua 2.3 shell脚本创建过程第一步：使用文本编编辑器来创建文本文件 第一行必须包括shell声明序列：#!示例： 1#!/bin/bash # 使用bash，添加注释,注释以#开头 第二步：加执行权限给予执行权限，在命令行上指定脚本的绝对或相对路径第三步：运行脚本直接运行解释器，将脚本作为解释器程序的参数运行 扩展：查看当前使用的是何种shell，终端输入：echo $SHELL 123root@ubuntu200404:~# echo $SHELL/bin/bashroot@ubuntu200404:~# 2.4 shell脚本注释规范 第一行一般为调用使用的语言 程序名，避免更改文件名为无法找到正确的文件 版本号 更改后的时间 作者相关信息 该程序的作用，及注意事项 最后是各版本的更新简要说明 2.5 第一个shell脚本范例：第一个shell脚本hello world 参考文档： 12https://zh.wikipedia.org/wiki/Hello_Worldhttps://zh.wikipedia.org/wiki/Hello_World%E7%A8%8B%E5%BA%8F%E6%A0%B7%E4%BE%8B (程序样例)[https://zh.wikipedia.org/wiki/Hello_World] 第一步：vim创建hello.sh文本 1root@ubuntu200404:~# vim hello.sh 第二步：声明序列和添加脚本名称、日期等 123456#!/bin/bash#******************#filename:hello.sh#Data:2022-08-06#author:admin#****************** 第三步：编写代码 1234#经典写法echo &quot;hello, world&quot;#流行写法echo &#x27;Hello, world!&#x27; 第四步：执行shell脚本 方法一： 12345root@ubuntu200404:~# bash hello.sh hello world!******************hello world!root@ubuntu200404:~# 方法二： 12345root@ubuntu200404:/data/scripts# cat /data/scripts/hello.sh | bashhello world!******************hello world!root@ubuntu200404:/data/scripts# 方法三： 12345root@ubuntu200404:/data/scripts# bash &lt; /data/scripts/hello.sh hello world!******************hello world!root@ubuntu200404:/data/scripts# 方法四：添加执行权限使用绝对路径和相对路径 123456789101112131415# 绝对路径root@ubuntu200404:/data/scripts# /data/scripts/hello.sh hello world!******************hello world!root@ubuntu200404:/data/scripts# # 相对路径root@ubuntu200404:/data/scripts# pwd/data/scriptsroot@ubuntu200404:/data/scripts# ./hello.sh hello world!******************hello world!root@ubuntu200404:/data/scripts# 方法五：将脚本添加到path变量中 1234567891011121314151617# 当前path位置root@ubuntu200404:/data/scripts# echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/binroot@ubuntu200404:/data/scripts## 给hello.sh文件创建软链接放到/usr/local/bin目录下root@ubuntu200404:/data/scripts# ln -s /data/scripts/hello.sh /usr/local/bin/ root@ubuntu200404:/data/scripts# ls /usr/local/bin/ hello.shroot@ubuntu200404:/data/scripts## 执行shell脚本root@ubuntu200404:/data/scripts# hello.sh hello world!******************hello world!root@ubuntu200404:/data/scripts# 方法六：本方法可以实现执行远程主机的shell脚本 12345# 扩展：curl加-s选项不显示下载信息root@ubuntu200404:/data# curl -s http://wangxiaochun.com/testdir/hello.sh |bashhello, worldHello, world!root@ubuntu200404:/data# 案例：备份脚本 12345678910111213141516# 脚本内容root@ubuntu200404:/data/scripts# cat -n bacup.sh 1 #!/bin/bash 2 #------------------ 3 #filename:bacup.sh 4 #备份脚本 5 #------------------ 6 7 8 tar zcf /data/scripts-`date +%F_%s`.tar.gz /data/ &amp;&gt; /dev/null 9 10 echo -e &quot;\\E[1;32mbacup is success!\\E[0m&quot;# 执行脚本root@ubuntu200404:/data/scripts# bash bacup.sh bacup is success!root@ubuntu200404:/data/scripts# 2.6 shell脚本调试只检测脚本中的语法错误，但无法检查出命令错误，但不真正执行脚本 1bash -n /path/to/some_script 调试并执行 1bash -x /path/to/some_script 案例1： 12345678root@ubuntu200404:/data/scripts# bash -x hello.sh + echo &#x27;hello world!&#x27;hello world!+ echo &#x27;******************&#x27;******************+ echo &#x27;hello world!&#x27;hello world!root@ubuntu200404:/data/scripts# 案例2:多行重定向 脚本内容： 12345678910111213141516#!/bin/bash# 多行重定向#data:2022-08-06#author:admin#--------------------------------------------echo startcat &gt;/data/demo.conf &lt;&lt;EOFline 1line 2line 3EOF echo endroot@ubuntu200404:/data/scripts# 检查错误： 123root@ubuntu200404:/data/scripts# bash -n demo1.sh demo1.sh: line 17: warning: here-document at line 11 delimited by end-of-file (wanted `EOF&#x27;)root@ubuntu200404:/data/scripts# 检查出第十七行有错误，肉眼观察没有错误，这是因为有些错误不显示在屏幕上的，可以通过cat -A filename或者在vi命令行模式下输入：set list 使用cat -A filename命令后发现EOF后面多了个空格导致错误。删除掉空格脚本即可成功运行。 在vi命令行模式下输入set list 总结：脚本错误常见的有三种 语法错误，会导致后续的命令不继续执行，可以用bash -n 检查错误，提示的出错行数不一定是准确的 命令错误，默认后续的命令还会继续执行，用bash -n 无法检查出来 ，可以使用 bash -x 进行观察 逻辑错误：只能使用 bash -x 进行观察 2.7 变量2.7.1 变量变量表示命名的内存空间，将数据放在内存空间中，通过变量名引用，获取数据 2.7.2 变量类型变量类型： 内置变量，如：PS1，PATH，UID，HOSTNAME，$$，BASHPID，PPID，$?，HISTSIZE 用户自定义变量 不同的变量存放的数据不同，决定了以下 数据存储方式 参与的运算 表示的数据范围 变量数据类型： 字符 数值：整型、浮点型,bash 不支持浮点数 2.7.3 shell中变量命令规则2.7.3.1 命名要求 区分大小写 不能使程序中的保留字和内置变量：如：if, for只能使用数字、字母及下划线，且不能以数字开头，注意：不支持短横线 “ - ”，和主机名相反 只能使用数字、字母及下划线，且不能以数字开头，注意：不支持短横线 “ - ”，和主机名相反 2.7.3.2 命令习惯 见名知义，用英文单词命名，并体现出实际作用，不要用简写，如：ATM 变量名大写 局部变量小写 函数名小写 大驼峰StudentFirstName,由多个单词组成，且每个单词的首字母是大写，其它小写 小驼峰studentFirstName ,由多个单词组成，第一个单词的首字母小写，后续每个单词的首字母是大写，其它小写 下划线: student_name 2.7.4 变量定义和引用变量的生效范围等标准划分变量类型 普通变量：生效范围为当前shell进程；对当前shell之外的其它shell进程，包括当前shell的子shell进程均无效 环境变量：生效范围为当前shell进程及其子进程 本地变量：生效范围为当前shell进程中某代码片断，通常指函数 变量赋值： 1name=&#x27;value&#x27; value 可以是以下多种形式 123直接字串：name=&#x27;root&#x27;变量引用：name=&quot;$USER&quot;命令引用：name=`COMMAND` 或者 name=$(COMMAND) 注意：变量赋值是临时生效，当退出终端后，变量会自动删除，无法持久保存，脚本中的变量会随着脚本结束，也会自动删除 变量引用： 12$name$&#123;name&#125; 弱引用和强引用 “$name” 弱引用，其中的变量引用会被替换为变量值 ‘$name’ 强引用，其中的变量引用不会被替换为变量值，而保持原字符串 范例：变量的各种赋值方式和引用 123456789101112131415161718192021222324252627282930313233343536373839404142434445方式1：root@ubuntu200404:/data/scripts# TITLE=ctoroot@ubuntu200404:/data/scripts# echo $TITLEctoroot@ubuntu200404:/data/scripts#方式二：root@ubuntu200404:/data/scripts# T=ceoroot@ubuntu200404:/data/scripts# NAME=$Troot@ubuntu200404:/data/scripts# echo $NAMEceoroot@ubuntu200404:/data/scripts#方式三：root@ubuntu200404:/data/scripts# NAME=`whoami`root@ubuntu200404:/data/scripts# echo $NAMErootroot@ubuntu200404:/data/scripts#方式四：root@ubuntu200404:/data/scripts# seq 1012345678910root@ubuntu200404:/data/scripts## 弱引用root@ubuntu200404:/data/scripts# echo &quot;$NUM&quot;12345678910root@ubuntu200404:/data/scripts# 删除变量： unset name 123456789unset &lt;name&gt;案例：root@ubuntu200404:/data/scripts# NUM=`seq 10`root@ubuntu200404:/data/scripts# echo $NUM1 2 3 4 5 6 7 8 9 10root@ubuntu200404:/data/scripts# unset NUMroot@ubuntu200404:/data/scripts# echo $NUMroot@ubuntu200404:/data/scripts# 显示已有的变量 1set 2.7.5 环境变量环境变量： 可以使子进程（包括孙子进程）继承父进程的变量，但是无法让父进程使用子进程的变量 一旦子进程修改从父进程继承的变量，将会新的值传递给孙子进 一般只在系统配置文件中使用，在脚本中较少使用 变量声明和赋值： 123456#声明并赋值export name=VALUEdeclare -x name=VALUE#或者分两步实现name=VALUEexport name 变量引用： 12$name$&#123;name&#125; 显示所有环境变量： 1234envprintenvexportdeclare -x 查看指定进程的环境变量 1cat /proc/$PID/environ 删除变量 1unset name bash内建的环境变量 123456789101112PATHSHELLUSERUIDHOMEPWDSHLVL #shell的嵌套层数，即深度LANGMAILHOSTNAMEHISTSIZE_ #下划线,表示前一命令的最后一个参数 扩展：pstree -p 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950root@ubuntu200404:/data/scripts# pstree -psystemd(1)─┬─VGAuthService(757) ├─accounts-daemon(811)─┬─&#123;accounts-daemon&#125;(818) │ └─&#123;accounts-daemon&#125;(864) ├─atd(837) ├─cron(815) ├─dbus-daemon(817) ├─irqbalance(824)───&#123;irqbalance&#125;(853) ├─login(1206)───bash(1402)───sudo(1413)───bash(1420) ├─multipathd(702)─┬─&#123;multipathd&#125;(703) │ ├─&#123;multipathd&#125;(704) │ ├─&#123;multipathd&#125;(705) │ ├─&#123;multipathd&#125;(706) │ ├─&#123;multipathd&#125;(707) │ └─&#123;multipathd&#125;(708) ├─networkd-dispat(825) ├─polkitd(872)─┬─&#123;polkitd&#125;(875) │ └─&#123;polkitd&#125;(877) ├─rsyslogd(826)─┬─&#123;rsyslogd&#125;(839) │ ├─&#123;rsyslogd&#125;(840) │ └─&#123;rsyslogd&#125;(841) ├─snapd(828)─┬─&#123;snapd&#125;(915) │ ├─&#123;snapd&#125;(916) │ ├─&#123;snapd&#125;(917) │ ├─&#123;snapd&#125;(918) │ ├─&#123;snapd&#125;(919) │ ├─&#123;snapd&#125;(945) │ ├─&#123;snapd&#125;(946) │ ├─&#123;snapd&#125;(952) │ ├─&#123;snapd&#125;(954) │ └─&#123;snapd&#125;(975) ├─sshd(859)─┬─sshd(3292)───bash(3421)───pstree(13708) │ └─sshd(6603)───bash(6736) ├─systemd(1477)───(sd-pam)(1478) ├─systemd(1392)───(sd-pam)(1393) ├─systemd-journal(495) ├─systemd-logind(830) ├─systemd-network(2826) ├─systemd-resolve(799) ├─systemd-timesyn(746)───&#123;systemd-timesyn&#125;(778) ├─systemd-udevd(525) ├─udisksd(836)─┬─&#123;udisksd&#125;(863) │ ├─&#123;udisksd&#125;(866) │ ├─&#123;udisksd&#125;(883) │ └─&#123;udisksd&#125;(906) ├─unattended-upgr(878)───&#123;unattended-upgr&#125;(908) ├─upowerd(2940)─┬─&#123;upowerd&#125;(2942) │ └─&#123;upowerd&#125;(2943) └─vmtoolsd(758)─┬─&#123;vmtoolsd&#125;(781) └─&#123;vmtoolsd&#125;(2774) 2.7.6 只读变量只读变量：只能声明定义，但后续不能修改和删除，即常量声明只读变量： 12readonly namedeclare -r name 查看只读变量： 12readonly [-p]declare -r 范例： 123456root@ubuntu200404:/data/scripts# readonly PI=3.14159root@ubuntu200404:/data/scripts# echo $PI3.14159root@ubuntu200404:/data/scripts# PI=3.14-bash: PI: readonly variableroot@ubuntu200404:/data/scripts# 2.7.7 位置变量位置变量：在bash shell中内置的变量, 在脚本代码中调用通过命令行传递给脚本的参数 123456$1, $2, ... 对应第1个、第2个等参数，shift [n]换位置$0 命令本身,包括路径$* 传递给脚本的所有参数，全部参数合为一个字符串$@ 传递给脚本的所有参数，每个参数为独立字符串$# 传递给脚本的参数的个数注意：$@ $* 只在被双引号包起来的时候才会有差异 清空所有位置变量 1set -- 范例： 123456789101112131415161718192021#!/bin/bashecho &quot;1st arg is $1&quot;echo &quot;2st arg is $2&quot;echo &quot;3st arg is $3&quot;echo &quot;10st arg is $&#123;10&#125;&quot;echo &quot;11st arg is $&#123;11&#125;&quot;echo &quot;The number of arg is $#&quot;echo &quot;All args are $*&quot;echo &quot;All args are $@&quot;echo &quot;The scriptname is `basename $0`&quot;root@ubuntu200404:/data/scripts# bash args.sh &#123;a..z&#125;1st arg is a2st arg is b3st arg is c10st arg is j11st arg is kThe number of arg is 26All args are a b c d e f g h i j k l m n o p q r s t u v w x y zAll args are a b c d e f g h i j k l m n o p q r s t u v w x y zThe scriptname is args.shroot@ubuntu200404:/data/scripts# 范例：删库跑路之安全命令 123456789101112131415161718192021222324252627282930313233# 查看命令root@ubuntu200404:/data/scripts# cat /data/scripts/rm.sh#!/bin/bash#-----------------#删库跑路之安全命令#-----------------#filename:rm.sh#data:2022-08-06#author:admin#-----------------WARNING_COLOR=&quot;echo -e \\E[1;31m&quot;END=&quot;\\E[0m&quot;DIR=/tmp/`date +%F_%H-%M-%S`mkdir $&#123;DIR&#125;mv $* $&#123;DIR&#125;$&#123;WARNING_COLOR&#125;Move $* to $&#123;END&#125;root@ubuntu200404:/data/scripts# # 给/data/scripts/rm.sh添加执行权限root@ubuntu200404:/data/scripts# chmod a+x /data/scripts/rm.sh# 添加别名root@ubuntu200404:/data/scripts#alias rm=&#x27;/data/scripts/rm.sh&#x27;root@ubuntu200404:/data/scripts# touch &#123;1..9&#125;.TXTroot@ubuntu200404:/data/scripts# rm *.TXTMove 1.TXT 2.TXT 3.TXT 4.TXT 5.TXT 6.TXT 7.TXT 8.TXT 9.TXT to *范例：$和$@的区别 当 $* 和 $@ 不带双引号时它们两个是没有区别的，都是接收所有参数然后分别单独处理每个参数！而当$*带双引号的时候，会把接收的所有参数当成一个字段处理 将$@与$* 赋值给变量之后，结果跟不带引号是一样的！这是我们需要注意的地方，当$* 赋值给变量的时候还是跟不带引号的作用是一样的！ 2.7.8 利用软链接实现同一个脚本不同功能范例： 12345678910[root@centos8 ~]#cat test.sh#!/bin/bash#********************************************************************echo $0[root@centos8 ~]#ln -s test.sh a.sh[root@centos8 ~]#ln -s test.sh b.sh[root@centos8 ~]#./a.sh./a.sh[root@centos8 ~]#./b.sh./b.sh 2.7.9 退出状态码变量进程执行后，将使用变量 $? 保存状态码的相关数字，不同的值反应成功或失败，$?取值范例 0-255 12$?的值为0 #代表成功$?的值是1到255 #代表失败 范例：状态码为0 123456789101112131415root@ubuntu200404:/data/scripts# lltotal 40drwxr-xr-x 2 root root 4096 Aug 6 07:29 ./drwxr-xr-x 3 root root 4096 Aug 6 02:41 ../-rw-r--r-- 1 root root 241 Aug 6 06:48 args.sh-rw-r--r-- 1 root root 192 Aug 6 02:40 bacup.sh-rw-r--r-- 1 root root 185 Aug 6 03:38 demo1.sh-rw-r--r-- 1 root root 85 Aug 6 07:26 f1.sh-rw-r--r-- 1 root root 41 Aug 6 07:29 file.sh-rwxr-xr-x 1 root root 208 Aug 6 01:42 hello.sh*-rwxr-xr-x 1 root root 285 Aug 6 07:20 rm.sh*-rwxr-xr-x 1 root root 284 Aug 6 07:01 rm.sh.bak*root@ubuntu200404:/data/scripts# echo $?0root@ubuntu200404:/data/scripts# 范例：状态码不是0 12345root@ubuntu200404:/data/scripts# ls ajdkshls: cannot access &#x27;ajdksh&#x27;: No such file or directoryroot@ubuntu200404:/data/scripts# echo $?2root@ubuntu200404:/data/scripts# 用户可以在脚本中使用以下命令自定义退出状态码 1exit [n] 案例： 123456789101112root@ubuntu200404:/data/scripts# cat exit.sh #!/bin/bashecho -e `hostname`exit 200echo -e &#x27;success&#x27;root@ubuntu200404:/data/scripts# root@ubuntu200404:/data/scripts# bash exit.sh ubuntu200404exit.sh: line 4: exit: 200: numeric argument requiredroot@ubuntu200404:/data/scripts# 注意： 脚本中一旦遇到exit命令，脚本会立即终止；终止退出状态取决于exit命令后面的数字 如果exit后面无数字,终止退出状态取决于exit命令前面命令执行结果 如果没有exit命令, 即未给脚本指定退出状态码，整个脚本的退出状态码取决于脚本中执行的最后一条命令的状态码 2.7.10 脚本安全和 setset 命令：可以用来定制 shell 环境$- 变量h：hashall，打开选项后，Shell 会将命令所在的路径hash下来，避免每次都要查询。通过set +h将h选项关闭i：interactive-comments，包含这个选项说明当前的 shell 是一个交互式的 shell。所谓的交互式shell,在脚本中，i选项是关闭的m：monitor，打开监控模式，就可以通过Job control来控制进程的停止、继续，后台或者前台执行等B：braceexpand，大括号扩展H：history，H选项打开，可以展开历史列表中的命令，可以通过!感叹号来完成，例如“!!”返回上最近的一个历史命令，“!n”返回第 n 个历史命令 set 命令实现脚本安全-u 在扩展一个没有设置的变量时，显示错误信息， 等同set -o nounset-e 如果一个命令返回一个非0退出状态值(失败)就退出， 等同set -o errexit-o option 显示，打开或者关闭选项显示选项：set -o打开选项：set -o 选项关闭选项：set +o 选项-x 当执行命令时，打印命令及其参数,类似 bash -x范例：-e -u 1234567891011121314151617#!/bin/bash#******************#filename:hello.sh#Data:2022-08-06#author:admin#******************set -e -u#echo &quot;经典写法&quot;echo &quot;hello world!&quot;echo &#x27;******************&#x27;# 流行写法echo &#x27;hello world!&#x27; 2.8 算术运算Shell允许在某些情况下对算术表达式进行求值，比如：let和declare 内置命令，(( ))复合命令和算术扩展。求值以固定宽度的整数进行，不检查溢出，尽管除以0 被困并标记为错误。运算符及其优先级，关联性和值与C语言相同。以下运算符列表分组为等优先级运算符级别。级别按降序排列优先。注意：bash 只支持整数，不支持小数 123456789101112131415161718+ - addition, subtraction* / % multiplication, division, remainder, %表示取模，即取余数，示例：9%4=1，5%3=2i++ i-- variable post-increment and post-decrement++i --i variable pre-increment and pre-decrement= *= /= %= += -= &lt;&lt;= &gt;&gt;= &amp;= ^= |= assignment- + unary minus and plus! ~ logical and bitwise negation** exponentiation 乘方,即指数运算&lt;&lt; &gt;&gt; left and right bitwise shifts&lt;= &gt;= &lt; &gt; comparison== != equality and inequality&amp; bitwise AND| bitwise OR^ bitwise exclusive OR&amp;&amp; logical AND|| logical ORexpr?expr:expr conditional operatorexpr1 , expr2 comma 乘法符号有些场景中需要转义实现算术运算： 1234567(1) let var=算术表达式(2) ((var=算术表达式)) 和上面等价(3) var=$[算术表达式](4) var=$((算术表达式))(5) var=$(expr arg1 arg2 arg3 ...)(6) declare -i var = 数值(7) echo &#x27;算术表达式&#x27; | bc 内建的随机数生成器变量： 1$RANDOM 取值范围：0-32767 范例： 12345#生成 0 - 49 之间随机数echo $[$RANDOM%50]#随机字体颜色[root@centos8 ~]#echo -e &quot;\\033[1;$[RANDOM%7+31]mhello\\033[0m&quot;magedu 2.9 逻辑运算 1231,真0,假#注意,以上为二进制 与或非符号：&amp; | ！ 异或：^ **异或：^ **异或的两个值，相同为假，不同为真。两个数字X,Y异或得到结果Z，Z再和任意两者之一X异或，将得出另一个值Y 12340 ^ 0 = 00 ^ 1 = 11 ^ 0 = 11 ^ 1 = 0 2.10 条件测试命令条件测试：判断某需求是否满足，需要由测试机制来实现，专用的测试表达式需要由测试命令辅助完成测试过程，实现评估布尔声明，以便用在条件性环境下进行执行若真，则状态码变量 $? 返回0若假，则状态码变量 $? 返回1条件测试命令 test EXPRESSIO [ EXPRESSION ] #和test 等价，建议使用 [ ] [[ EXPRESSION ]] 相关于增强版的 [ ], 支持[]的用法,且支持扩展正则表达式和通配 注意：EXPRESSION前后必须有空白字符 帮助： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091root@ubuntu200404:/data/scripts# type [[ is a shell builtinroot@ubuntu200404:/data/scripts# root@ubuntu200404:/data/scripts# help testtest: test [expr] Evaluate conditional expression. Exits with a status of 0 (true) or 1 (false) depending on the evaluation of EXPR. Expressions may be unary or binary. Unary expressions are often used to examine the status of a file. There are string operators and numeric comparison operators as well. The behavior of test depends on the number of arguments. Read the bash manual page for the complete specification. File operators: -a FILE True if file exists. -b FILE True if file is block special. -c FILE True if file is character special. -d FILE True if file is a directory. -e FILE True if file exists. -f FILE True if file exists and is a regular file. -g FILE True if file is set-group-id. -h FILE True if file is a symbolic link. -L FILE True if file is a symbolic link. -k FILE True if file has its `sticky&#x27; bit set. -p FILE True if file is a named pipe. -r FILE True if file is readable by you. -s FILE True if file exists and is not empty. -S FILE True if file is a socket. -t FD True if FD is opened on a terminal. -u FILE True if the file is set-user-id. -w FILE True if the file is writable by you. -x FILE True if the file is executable by you. -O FILE True if the file is effectively owned by you. -G FILE True if the file is effectively owned by your group. -N FILE True if the file has been modified since it was last read. FILE1 -nt FILE2 True if file1 is newer than file2 (according to modification date). FILE1 -ot FILE2 True if file1 is older than file2. FILE1 -ef FILE2 True if file1 is a hard link to file2. All file operators except -h and -L are acting on the target of a symbolic link, not on the symlink itself, if FILE is a symbolic link. String operators: -z STRING True if string is empty. -n STRING STRING True if string is not empty. STRING1 = STRING2 True if the strings are equal. STRING1 != STRING2 True if the strings are not equal. STRING1 &lt; STRING2 True if STRING1 sorts before STRING2 lexicographically. STRING1 &gt; STRING2 True if STRING1 sorts after STRING2 lexicographically. Other operators: -o OPTION True if the shell option OPTION is enabled. -v VAR True if the shell variable VAR is set. -R VAR True if the shell variable VAR is set and is a name reference. ! EXPR True if expr is false. EXPR1 -a EXPR2 True if both expr1 AND expr2 are true. EXPR1 -o EXPR2 True if either expr1 OR expr2 is true. arg1 OP arg2 Arithmetic tests. OP is one of -eq, -ne, -lt, -le, -gt, or -ge. Arithmetic binary operators return true if ARG1 is equal, not-equal, less-than, less-than-or-equal, greater-than, or greater-than-or-equal than ARG2. See the bash manual page bash(1) for the handling of parameters (i.e. missing parameters). Exit Status: Returns success if EXPR evaluates to true; fails if EXPR evaluates to false or an invalid argument is given.root@ubuntu200404:/data/scripts# 2.10.1 变量测试12#判断 NAME 变量是否定义[ -v NAME ] 范例： 12345678root@ubuntu200404:/data/scripts# NAME=&#x27;tom&#x27;root@ubuntu200404:/data/scripts# [ -v NAME ]root@ubuntu200404:/data/scripts# echo $?0root@ubuntu200404:/data/scripts# [ -v AGE ]root@ubuntu200404:/data/scripts# echo $?1root@ubuntu200404:/data/scripts# 2.10.2 数值测试123456-eq 是否等于-ne 是否不等于-gt 是否大于-ge 是否大于等于-lt 是否小于-le 是否小于等于 范例： 12345[root@centos8 ~]#i=10[root@centos8 ~]#j=8[root@centos8 ~]#[ $i -lt $j ][root@centos8 ~]#echo $?1 2.10.3 算术表达式比较123456== 相等!= 不相等&lt;=&gt;=&lt;&gt; 范例： 12345678[root@centos8 ~]#x=10;y=10;(( x == y ));echo $?0[root@centos8 ~]#x=10;y=20;(( x == y ));echo $?1[root@centos8 ~]#x=10;y=20;(( x != y ));echo $?0[root@centos8 ~]#x=10;y=10;(( x != y ));echo $?1 2.10.4 字符窜测试test和 [ ] 字符串测试用法 1234567-z STRING 字符串是否为空，没定义或空为真，不空为假，-n STRING 字符串是否不空，不空为真，空为假STRING 同上STRING1 = STRING2 是否等于，注意 = 前后有空格STRING1 != STRING2 是否不等于&gt; ascii码是否大于ascii码&lt; 是否小于 [[]] 字符串测试用法 12345[[ expression ]] 用法== 左侧字符串是否和右侧的PATTERN相同注意:此表达式用于[[ ]]中，PATTERN为通配符=~ 左侧字符串是否能够被右侧的正则表达式的PATTERN所匹配注意: 此表达式用于[[ ]]中为扩展的正则表达式 建议：当使用正则表达式或通配符使用[[ ]]，其它情况一般使用 [ ] 范例：使用 [ ] 1234[root@centos8 ~]#unset str[root@centos8 ~]#[ -z &quot;$str&quot; ][root@centos8 ~]#echo $?0 范例：在比较字符串时，建议变量放在“ ”中 1234567[root@centos8 ~]#[ &quot;$NAME&quot; ][root@centos8 ~]#NAME=&quot;I love linux&quot;[root@centos8 ~]#[ $NAME ]-bash: [: love: binary operator expected[root@centos8 ~]#[ &quot;$NAME&quot; ][root@centos8 ~]#echo $?0 [[]]中如果不想使用通配符*,只想表达*本身,可以用” “引起来 #[[]]中如果不想使用通配符,只想表达*本身,也可以使用转义符* 2.10.5 文件测试存在性测试 123456789-a FILE：同 -e-e FILE: 文件存在性测试，存在为真，否则为假-b FILE：是否存在且为块设备文件-c FILE：是否存在且为字符设备文件-d FILE：是否存在且为目录文件-f FILE：是否存在且为普通文件-h FILE 或 -L FILE：存在且为符号链接文件-p FILE：是否存在且为命名管道文件-S FILE：是否存在且为套接字文件 案例： 1234root@ubuntu200404:/data/scripts# [ -e /data/scripts/rm.sh ]root@ubuntu200404:/data/scripts# echo $?0root@ubuntu200404:/data/scripts# 文件权限测试 123456-r FILE：是否存在且可读-w FILE: 是否存在且可写-x FILE: 是否存在且可执行-u FILE：是否存在且拥有suid权限-g FILE：是否存在且拥有sgid权限-k FILE：是否存在且拥有sticky权限 注意：最终结果由用户对文件的实际权限决定，而非文件属性决定 范例: 1234root@ubuntu200404:/data/scripts# [ -w /data/scripts/rm.sh ]root@ubuntu200404:/data/scripts# echo $?0root@ubuntu200404:/data/scripts# 文件属性测试 12345678-s FILE #是否存在且非空-t fd #fd 文件描述符是否在某终端已经打开-N FILE #文件自从上一次被读取之后是否被修改过-O FILE #当前有效用户是否为文件属主-G FILE #当前有效用户是否为文件属组FILE1 -ef FILE2 #FILE1是否是FILE2的硬链接FILE1 -nt FILE2 #FILE1是否新于FILE2（mtime）FILE1 -ot FILE2 #FILE1是否旧于FILE2 案例： 1234root@ubuntu200404:/data/scripts# [ -s /data/scripts/rm.sh ]root@ubuntu200404:/data/scripts# echo $?0root@ubuntu200404:/data/scripts# 2.11 关于（）和{}（CMD1;CMD2;…）和 { CMD1;CMD2;…; } 都可以将多个命令组合在一起，批量执行** 1234567891011121314151617181920( list ) 会开启子shell,并且list中变量赋值及内部命令执行后,将不再影响后续的环境帮助参看:man bash 搜索(list)&#123; list; &#125; 不会启子shell, 在当前shell中运行,会影响当前shell环境帮助参看:man bash 搜索&#123; list; &#125;( list ) 会开启子shell,并且list中变量赋值及内部命令执行后,将不再影响后续的环境帮助参看:man bash 搜索(list)&#123; list; &#125; 不会启子shell, 在当前shell中运行,会影响当前shell环境帮助参看:man bash 搜索&#123; list; &#125;#（）会开启子shell[root@centos8 ~]#echo $BASHPID1920[root@centos8 ~]#( echo $BASHPID;sleep 100)1979[root@centos8 ~]#pstree -p├─sshd(719)───sshd(1906)───sshd(1919)─┬─bash(1920)───bash(1979)───sleep(1980)#&#123; &#125; 不会开启子shell[root@centos8 ~]#echo $BASHPID1920 2.12 组合测试2.12.1 第一种方式1234[ EXPRESSION1 -a EXPRESSION2 ] #并且，EXPRESSION1和EXPRESSION2都是真，结果才为真[ EXPRESSION1 -o EXPRESSION2 ] #或者，EXPRESSION1和EXPRESSION2只要有一个真，结果就为真[ ! EXPRESSION ] #取反 说明： -a 和 -o 需要使用测试命令进行，[[ ]] 不支持 2.12.2 第二种方式12345COMMAND1 &amp;&amp; COMMAND2 #并且，短路与，代表条件性的AND THEN如果COMMAND1 成功,将执行COMMAND2,否则,将不执行COMMAND2COMMAND1 || COMMAND2 #或者，短路或，代表条件性的OR ELSE如果COMMAND1 成功,将不执行COMMAND2,否则,将执行COMMAND2! COMMAND #非,取反 如果&amp;&amp; 和 || 混合使用，&amp;&amp; 要在前，|| 放在后 练习1、编写脚本 argsnum.sh，接受一个文件路径作为参数；如果参数个数小于1，则提示用户“至少应该给一个参数”，并立即退出；如果参数个数不小于1，则显示第一个参数所指向的文件中的空白行数2、编写脚本 hostping.sh，接受一个主机的IPv4地址做为参数，测试是否可连通。如果能ping通，则提示用户“该IP地址可访问”；如果不可ping通，则提示用户“该IP地址不可访问”3、编写脚本 checkdisk.sh，检查磁盘分区空间和inode使用率，如果超过80%，就发广播警告空间将满4、编写脚本 per.sh，判断当前用户对指定参数文件，是否不可读并且不可写5、编写脚本 excute.sh ，判断参数文件是否为sh后缀的普通文件，如果是，添加所有人可执行权限，否则提示用户非脚本文件6、编写脚本 nologin.sh和 login.sh，实现禁止和允许普通用户登录系统 2.13 使用read命令来接受输入使用read来把输入值分配给一个或多个shell变量，read从标准输入中读取值，给每个单词分配一个变量，所有剩余单词都被分配给最后一个变量，如果变量名没有指定，默认标准输入的值赋值给系统内置变量REPLY格式： 1read [options] [name ...] 常用选项： 12345-p 指定要显示的提示-s 静默输入，一般用于密码-n N 指定输入的字符长度N-d &#x27;字符&#x27; 输入结束符-t N TIMEOUT为N秒 范例： 12345[root@rocky ~]# read -p &#x27;请输入任意内容&#x27; NAME请输入任意内容yuan[root@rocky ~]# echo $&#123;NAME&#125;yuan[root@rocky ~]# 3 条件选择if格式： 12if COMMANDS; then COMMANDS; [ elif COMMANDS; then COMMANDS; ]... [ elseCOMMANDS; ] fi 单分支： 123if 判断条件;then条件为真的分支代码fi 双分支： 12345if 判断条件; then条件为真的分支代码else条件为假的分支代码fi 多分支： 12345678910if 判断条件1; then条件1为真的分支代码elif 判断条件2; then条件2为真的分支代码elif 判断条件3; then条件3为真的分支代码...else以上条件都为假的分支代码fi 4 循环4.1 for循环帮助： 1help for 格式： 12345678910for NAME [in WORDS ... ] ; do COMMANDS; done#方式1for 变量名 in 列表;do循环体done#方式2for 变量名 in 列表do循环体done 执行机制： 依次将列表中的元素赋值给“变量名”; 每次赋值后即执行一次循环体; 直到列表中的元素耗尽，循环结束 如果省略 [in WORDS … ] ，此时使用位置参数变量 in “$@” for 循环列表生成方式： 直接给出列表 整数列表： 12&#123;start..end&#125;$(seq [start [step]] end) 返回列表的命令 1$(COMMAND) 使用glob，如：*.sh* *变量引用，如：$@，$*，$# 范例：计算1+···+100的值 12345678[root@centos8 ~]#sum=0;for i in &#123;1..100&#125;;do let sum+=i;done ;echo sum=$sumsum=5050[root@centos8 ~]#seq -s+ 100|bc50505050[root@centos8 ~]#echo &#123;1..100&#125;|tr &#x27; &#x27; +|bc5050[root@centos8 ~]#seq 100|paste -sd +|bc5050 4.2 while循环格式 1234while COMMANDS; do COMMANDS; donewhile CONDITION; do循环体done 扩展:nc命令 nc命令 全称netcat，用于设置路由器。它能通过 TCP 和 UDP 在网络中读写数据。通过与其他工具结合和重定向，你可以在脚本中以多种方式使用它。使用 netcat 命令所能完成的事情令人惊讶。 选项 1234567891011121314-g&lt;网关&gt; 设置路由器跃程通信网关，最多可设置8个。-G&lt;指向器数目&gt; 设置来源路由指向器，其数值为4的倍数。-h 在线帮助。-i&lt;延迟秒数&gt; 设置时间间隔，以便传送信息及扫描通信端口。-l 使用监听模式，管控传入的资料。-n 直接使用IP地址，而不通过域名服务器。-o&lt;输出文件&gt; 指定文件名称，把往来传输的数据以16进制字码倾倒成该文件保存。-p&lt;通信端口&gt; 设置本地主机使用的通信端口。-r 乱数指定本地与远端主机的通信端口。-s&lt;来源位址&gt; 设置本地主机送出数据包的IP地址。-u 使用UDP传输协议。-v 显示指令执行过程。-w&lt;超时秒数&gt; 设置等待连线的时间。-z 使用0输入/输出模式，只在扫描通信端口时使用。 范例 123456# TCP端口扫描[root@rocky ~]# nc -zv 192.168.179.129 80Ncat: Version 7.70 ( https://nmap.org/ncat )Ncat: Connected to 192.168.179.129:80.Ncat: 0 bytes sent, 0 bytes received in 0.01 seconds.[root@rocky ~]# 范例:写一个扫描某个主机端口的状态的脚本 1234567891011121314151617#!/bin/bash# 变量i=1# 主机IPhost=192.168.179.138# 清空文件内容cat /dev/null &gt;port.TXT# 循环端口1-100while [ $i -le 100 ];do # 扫描端口并将信息放入垃圾箱 if nc -z $&#123;host&#125; $&#123;i&#125; &amp;&gt; /dev/null;then # 屏幕打印IP+port,输出重定向到port.TXT echo $&#123;host&#125;:$&#123;i&#125; | tee -a port.TXT fi # i++ let i++done 5 其他脚本相关工具5.1 trap命令trap命令可以捕捉信号，修改信号原有的功能，实现自定义功能 12345678910111213141516# 查看信号trap -l 或者kill -lroot@ubuntu200404-1:/data/scripts# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX root@ubuntu200404-1:/data/scripts# 1234567891011121314# 进程收到系统发出的制定信号后，将执行自定义指令，而不会执原操作trap &#x27;触发指令&#x27; 信号# 忽略信号的操作trap &#x27;&#x27; 信号# 恢复原信号的操作trap &#x27;-&#x27; 信号# 列出自定义的操作trap -p# 当脚本退出时，执行finish函数trap finish exit 范例 123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/bash# 打印press ctrl+c or ctrl+\\ replace int quittrap &quot;echo &#x27;press ctrl+c or ctrl+\\ &#x27;&quot; 2 3# 列出 自定义的操作 trap -p# 循环并打印1-10# 打印1-10键盘按ctrl+c打印press ctrl+c or ctrlfor ((i=1;i&lt;=10;i++))do sleep 1 echo $&#123;i&#125;done# 忽略2 3信号操作trap &#x27;&#x27; 2 3# 打印出自定义操作trap -p# 打印11-20# 打印11-20的时候键盘按ctrl+c没有任何操作for((i=11;i&lt;=20;i++))do sleep 1 echo $&#123;i&#125;done# 恢复原信号操作trap &#x27;-&#x27; int# 列出信号操作trap -p# 打印21-30键盘按ctrl+c 退出for((i=21;i&lt;=30;i++))do sleep 1 echo $&#123;i&#125;done 范例 12345678910111213#!/bin/bashfinsh()&#123; echo `date +%F-%T`-finsh | tee -a /data/finsh.log&#125;# 捕捉到退出执行finsh trap或者exittrap finsh exitwhile true;do echo running sleep 1done 创建临时文件 123456789# mktemp testXXXXroot@ubuntu200404-1:/data/scripts# mktemp testXXXXXX.logtestdnlqM9.logroot@ubuntu200404-1:/data/scripts# # 创建临时目录root@ubuntu200404-1:/data/scripts# mktemp -d testXXXtestGioroot@ubuntu200404-1:/data/scripts# 5. 2 except实现自动化的非交互操作expect 是由Don Libes基于 Tcl（ Tool Command Language ）语言开发的，主要应用于自动化交互式操作的场景，借助 expect 处理交互的命令，可以将交互过程如：ssh登录，ftp登录等写在一个脚本上，使之自动化完成。尤其适用于需要对多台服务器执行相同操作的环境中，可以大大提高系统管理人员的工作效率。 expect语法 1expect [选项] [ -c cmds ] [ [ -[f|b] ] cmdfile ] [ args ] 常见选项 12-c：从命令行执行expect脚本，默认expect是交互地执行的-d：可以调试信息 expect中相关命令 spawn 启动新的进程 expect 从进程接收字符串 send 用于向进程发送字符串 interact 允许用户交互 exp_continue 匹配多个字符串在执行动作后加此命令 范例1:自动登录 12345678910111213141516# 创建文件vim filename# 脚本内容#!/usr/bin/expect# 启动新的进程spawn ssh 192.168.179.138# 从进程接收字符串expect &#123; # 匹配到yse/no，输入yes &quot;yes/no&quot; &#123;send &quot;yes\\n&quot;;exp_continue &#125; &quot;password&quot; &#123; send &quot;123456\\n&quot; &#125;&#125;# 允许用户交互interact 1234# 添加可执行权限chmod +x filename# 执行./filename 扩展：scp命令 语法 1scp 选项 参数 选项 1234567891011121314-1：使用ssh协议版本1；-2：使用ssh协议版本2；-4：使用ipv4；-6：使用ipv6；-B：以批处理模式运行；-C：使用压缩；-F：指定ssh配置文件；-i：identity_file 从指定文件中读取传输时使用的密钥文件（例如亚马逊云pem），此参数直接传递给ssh；-l：指定宽带限制；-o：指定使用的ssh选项；-P：指定远程主机的端口号；-p：保留文件的最后修改时间，最后访问时间和权限模式；-q：不显示复制进度；-r：以递归方式复制。 实例从远程复制到本地的scp命令与上面的命令雷同，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。 从远程机器复制文件到本地目录 1scp root@10.10.10.10:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ 从10.10.10.10机器上的&#x2F;opt&#x2F;soft&#x2F;的目录中下载nginx-0.5.38.tar.gz 文件到本地&#x2F;opt&#x2F;soft&#x2F;目录中。 从远程机器复制目录到本地 1scp -r root@10.10.10.10:/opt/soft/mongodb /opt/soft/ 从10.10.10.10机器上的&#x2F;opt&#x2F;soft&#x2F;中下载mongodb目录到本地的&#x2F;opt&#x2F;soft&#x2F;目录来。 上传本地文件到远程机器指定目录 123scp /opt/soft/nginx-0.5.38.tar.gz root@10.10.10.10:/opt/soft/scptest# 指定端口 2222scp -rp -P 2222 /opt/soft/nginx-0.5.38.tar.gz root@10.10.10.10:/opt/soft/scptest 复制本地&#x2F;opt&#x2F;soft&#x2F;目录下的文件nginx-0.5.38.tar.gz到远程机器10.10.10.10的opt&#x2F;soft&#x2F;scptest目录。 上传本地目录到远程机器指定目录 1scp -r /opt/soft/mongodb root@10.10.10.10:/opt/soft/scptest 上传本地目录&#x2F;opt&#x2F;soft&#x2F;mongodb到远程机器10.10.10.10上&#x2F;opt&#x2F;soft&#x2F;scptest的目录中去。 范例2:非交互式复制文件 1234567891011#!/usr/bin/expect# 开启新的进程,复制当前主机下的/root/hello.sh到远程主机spawn scp /root/hello.sh root@192.168.179.129:/rootexpect &#123; # 匹配到yes/no，输入yes &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue&#125; &quot;password&quot; &#123; send &quot;123456\\n&quot;&#125; &#125;expect eof 范例3:变量 123456789101112131415161718#!/usr/bin/expect# 添加变量set ip 192.168.179.138set user rootset passwd 123456set timeout 10# 启动新的进程spawn ssh $&#123;user&#125;@$&#123;ip&#125;expect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue&#125; &quot;password&quot; &#123; send &quot;$passwd\\n&quot; &#125;&#125;# 允许交互式操作interact 范例4:位置参数 12345678910111213141516171819#!/usr/bin/expect# 添加变量set ip [lindex $argv 0]set user [lindex $argv 1]set passwd [lindex $argv 2]set timeout 10# 启动新的进程spawn ssh $&#123;user&#125;@$&#123;ip&#125;expect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue&#125; &quot;password&quot; &#123; send &quot;$passwd\\n&quot; &#125;&#125;# 允许交互式操作interact 1234# 添加执行权限[root@centos7 ~]# chmmod +x expect3# 后面跟三个参数[root@centos7 ~]# ./expect3 192.168.179.138 root 123456 范例5:执行多个命令 12345678910111213141516171819202122232425#!/usr/bin/expect# 添加变量set ip [lindex $argv 0]set user [lindex $argv 1]set passwd [lindex $argv 2]set timeout 10# 启动新的进程spawn ssh $&#123;user&#125;@$&#123;ip&#125;expect &#123; &quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue&#125; &quot;password&quot; &#123; send &quot;$passwd\\n&quot; &#125;&#125;# adduser hahaexpect &quot;]#&quot; &#123; send &quot;useradd haha\\n&quot; &#125;# passwd set 123456expect &quot;]#&quot; &#123; send &quot;echo 123456 |passwd --stdin haha\\n&quot; &#125;# logoutsend &quot;exit\\n&quot;expect eof[root@centos7 ~]# ./expect4 192.168.179.141 root 123456 范例6:shell脚本调用expect 123456789101112131415161718192021#!/bin/baship=$1user=$2password=$3expect &lt;&lt;EOFset timeout 20# 开启新的进程，登录远程主机spawn ssh $user@$ipexpect &#123;&quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125;&quot;password&quot; &#123; send &quot;$password\\n&quot; &#125;&#125;# 添加新的用户expect &quot;]#&quot; &#123; send &quot;useradd hehe\\n&quot; &#125;# 设置新密码expect &quot;]#&quot; &#123; send &quot;echo 123456 |passwd --stdin hehe\\n&quot; &#125;# logoutexpect &quot;]#&quot; &#123; send &quot;exit\\n&quot; &#125;expect eofEOF 1[root@centos7 ~]# bash expect5.sh 192.168.179.141 root 123456 范例7: shell脚本利用循环调用expect在CentOS和Ubuntu上批量创建用户 12345678910111213141516171819202122NET=10.0.0user=rootpassword=mageduIPLIST=&quot;718101&quot;for ID in $IPLIST;doip=$NET.$IDexpect &lt;&lt;EOFset timeout 20spawn ssh $user@$ipexpect &#123;&quot;yes/no&quot; &#123; send &quot;yes\\n&quot;;exp_continue &#125;&quot;password&quot; &#123; send &quot;$password\\n&quot; &#125;&#125;expect &quot;#&quot; &#123; send &quot;useradd test\\n&quot; &#125;expect &quot;#&quot; &#123; send &quot;exit\\n&quot; &#125;expect eofEOFdone 6 数组6.1 数组介绍变量：存储单个元素的内存空间数组：存储多个元素的连续的内存空间，相当于多个变量的集合数组名和索引 索引的编号从0开始，属于数值索引 索引可支持使用自定义的格式，而不仅是数值格式，即为关联索引，bash 4.0版本之后开始支持 bash的数组支持稀疏格式（索引不连续） 6.2 声明数组1234#普通数组可以不事先声明,直接使用declare -a ARRAY_NAME#关联数组必须先声明,再使用declare -A ARRAY_NAME 注:两者不可相互转换 6.3 数组赋值数组元素的赋值**(1) 一次只赋值一个元素 ** 1ARRAY_NAME[INDEX]=VALUE 范例： 12weekdays[0]=&quot;Sunday&quot;weekdays[4]=&quot;Thursday&quot; (2) 一次赋值全部元素 1ARRAY_NAME=(&quot;VAL1&quot; &quot;VAL2&quot; &quot;VAL3&quot; ...) 范例: 1234title=(&quot;ceo&quot; &quot;coo&quot; &quot;cto&quot;)num=(&#123;0..10&#125;)alpha=(&#123;a..g&#125;)file=( *.sh ) (3)只赋值特定元素 1ARRAY_NAME=([0]=&quot;VAL1&quot; [3]=&quot;VAL2&quot; ...) (4)交互式赋值元素 1read -a ARRAY 6.4 显示所有数组显示所有数组 1declare -a 范例 123456789101112[root@centos7 ~]# declare -adeclare -a BASH_ARGC=&#x27;()&#x27;declare -a BASH_ARGV=&#x27;()&#x27;declare -a BASH_LINENO=&#x27;()&#x27;declare -a BASH_SOURCE=&#x27;()&#x27;declare -ar BASH_VERSINFO=&#x27;([0]=&quot;4&quot; [1]=&quot;2&quot; [2]=&quot;46&quot; [3]=&quot;2&quot; [4]=&quot;release&quot; [5]=&quot;x86_64-redhat-linux-gnu&quot;)&#x27;declare -a DIRSTACK=&#x27;()&#x27;declare -a FUNCNAME=&#x27;()&#x27;declare -a GROUPS=&#x27;()&#x27;declare -a PIPESTATUS=&#x27;([0]=&quot;0&quot;)&#x27;[root@centos7 ~]# 6.5 引用数组引用特定的数组元素 12$&#123;ARRAY_NAME[INDEX]&#125;#如果省略[INDEX]表示引用下标为0的元素 引用所有数组元素 12$&#123;ARRAY_NAME[*]&#125;$&#123;ARRAY_NAME[@]&#125; 数组的长度，即数组的元素的个数 12$&#123;#ARRAY_NAME[*]&#125;$&#123;#ARRAY_NAME[@]&#125; 范例 123456[root@centos7 ~]# title[0]=1[root@centos7 ~]# title[1]=1[root@centos7 ~]# title[2]=1[root@centos7 ~]# echo $&#123;#title[*]&#125;3[root@centos7 ~]# 数组的所有下标 12$&#123;!ARRAY_NAME[*]&#125;$&#123;!ARRAY_NAME[@]&#125; 范例 123456[root@centos7 ~]# title[0]=1[root@centos7 ~]# title[1]=1[root@centos7 ~]# title[2]=1[root@centos7 ~]# echo $&#123;!title[*]&#125;0 1 2[root@centos7 ~]# 6.6 删除数组删除数组中的某个元素 1unset ARRAY[INDEX] 删除整个数组 1unset ARRAY 6.7 数组数据处理数据切片 1234567$&#123;ARRAY[@]:offset:number&#125;$&#123;ARRAY[*]:offset:number&#125;offset #要跳过的元素个数number #要取出的元素个数#取偏移量之后的所有元素&#123;ARRAY[@]:offset&#125;&#123;ARRAY[*]:offset&#125; 范例 12345[root@centos8 ~]#num=(&#123;0..10&#125;)[root@centos8 ~]#echo $&#123;num[*]:2:3&#125;2 3 4[root@centos8 ~]#echo $&#123;num[*]:6&#125;6 7 8 9 10 向数组中追加元素 12ARRAY[$&#123;#ARRAY[*]&#125;]=valueARRAY[$&#123;#ARRAY[@]&#125;]=value 范例 12345[root@centos8 ~]#num[$&#123;#num[@]&#125;]=11[root@centos8 ~]#echo $&#123;#num[@]&#125;12[root@centos8 ~]#echo $&#123;num[@]&#125;0 1 2 3 4 5 6 7 8 9 10 11 范例：生成10个随机数保存于数组中，并找出其最大值和最小值 123456789101112#!/bin/bashdeclare -i min maxdeclare -a numsfor ((i=0;i&lt;10;i++));donums[$i]=$RANDOM[ $i -eq 0 ] &amp;&amp; min=$&#123;nums[0]&#125; &amp;&amp; max=$&#123;nums[0]&#125;&amp;&amp; continue[ $&#123;nums[$i]&#125; -gt $max ] &amp;&amp; max=$&#123;nums[$i]&#125; &amp;&amp; continue[ $&#123;nums[$i]&#125; -lt $min ] &amp;&amp; min=$&#123;nums[$i]&#125;doneecho &quot;All numbers are $&#123;nums[*]&#125;&quot;echo Max is $maxecho Min is $min 7 字符串处理7.1 字符串切片1234567891011121314#返回字符串变量var的字符的长度,一个汉字算一个字符$&#123;#var&#125;#返回字符串变量var中从第offset个字符后（不包括第offset个字符）的字符开始，到最后的部分，offset的取值在0 到 $&#123;#var&#125;-1 之间(bash4.2后，允许为负值)$&#123;var:offset&#125;#返回字符串变量var中从第offset个字符后（不包括第offset个字符）的字符开始，长度为number的部分$&#123;var:offset:number&#125;#取字符串的最右侧几个字符,取字符串的最右侧几个字符, 注意：冒号后必须有一空白字符$&#123;var: -length&#125;#从最左侧跳过offset字符，一直向右取到距离最右侧lengh个字符之前的内容,即:掐头去尾$&#123;var:offset:-length&#125;#先从最右侧向左取到length个字符开始，再向右取到距离最右侧offset个字符之间的内容,注意：-length前空格,并且length必须大于offset$&#123;var: -length:-offset&#125; 范例 1234567891011121314151617181920212223[root@centos8 script40]#str=abcdef我你他[root@centos8 script40]#echo $&#123;#str&#125;9[root@centos8 script40]#echo $&#123;str:2&#125;cdef我你他[root@centos8 script40]#echo $&#123;str:2:3&#125;cde[root@centos8 script40]#echo $&#123;str:-3&#125;abcdef我你他[root@centos8 script40]#echo $&#123;str: -3&#125;我你他[root@centos8 script40]#echo $&#123;str:2:-3&#125;cdef[root@centos8 script40]#echo $&#123;str: -2:-3&#125;-bash: -3: substring expression &lt; 0[root@centos8 script40]#echo $&#123;str: -3:-2&#125;我[root@centos8 script40]#echo $&#123;str:-3:-2&#125;abcdef我你他[root@centos8 script40]#echo $&#123;str: -3:-2&#125;我[root@centos8 script40]#echo $&#123;str: -5:-2&#125;ef我 7.2 基于模式取子串123456789#其中word可以是指定的任意字符,自左而右，查找var变量所存储的字符串中，第一次出现的word, 删除字符串开头至第一次出现word字符串（含）之间的所有字符,即懒惰模式,以第一个word为界删左留右$&#123;var#*word&#125;#从var变量的值中删除以word开头的部分$&#123;var#word&#125;#同上，贪婪模式，不同的是，删除的是字符串开头至最后一次由word指定的字符之间的所有内容,即贪婪模式,以最后一个word为界删左留右$&#123;var##*word&#125;$&#123;var##word&#125; 范例 12345[root@centos8 ~]#file=&quot;var/log/messages&quot;[root@centos8 ~]#echo $&#123;file#*/&#125;log/messages[root@centos8 ~]#echo $&#123;file##*/&#125;messages 123456789#其中word可以是指定的任意字符,功能：自右而左，查找var变量所存储的字符串中，第一次出现的word,删除字符串最后一个字符向左至第一次出现word字符串（含）之间的所有字符,即懒惰模式,以从右向左的第一个word为界删右留左$&#123;var%word*&#125;$&#123;var%word&#125;#同上，只不过删除字符串最右侧的字符向左至最后一次出现word字符之间的所有字符,即贪婪模式,以从右向左的最后一个word为界删右留左$&#123;var%%word*&#125;$&#123;var%%word&#125; 7.3 查找和替换12345678#查找var所表示的字符串中，第一次被pattern所匹配到的字符串，以substr替换之$&#123;var/pattern/substr&#125;#查找var所表示的字符串中，所有能被pattern所匹配到的字符串，以substr替换之$&#123;var//pattern/substr&#125;#查找var所表示的字符串中，行首被pattern所匹配到的字符串，以substr替换之$&#123;var/#pattern/substr&#125;#查找var所表示的字符串中，行尾被pattern所匹配到的字符串，以substr替换之$&#123;var/%pattern/substr&#125; 7.4 查找和删除12345678#删除var表示的字符串中第一次被pattern匹配到的字符串$&#123;var/pattern&#125;#删除var表示的字符串中所有被pattern匹配到的字符串$&#123;var//pattern&#125;#删除var表示的字符串中所有以pattern为行首匹配到的字符串$&#123;var/#pattern&#125;#删除var所表示的字符串中所有以pattern为行尾所匹配到的字符串$&#123;var/%pattern&#125; 7.5 字符大小写转换1234#把var中的所有小写字母转换为大写$&#123;var^^&#125;#把var中的所有大写字母转换为小写$&#123;var,,&#125;","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"文件查找和打包压缩","slug":"文件查找和打包压缩","date":"2022-08-01T13:31:38.000Z","updated":"2022-12-16T14:57:16.988Z","comments":true,"path":"2022/08/01/文件查找和打包压缩/","link":"","permalink":"http://snippet.itshare.work/2022/08/01/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%92%8C%E6%89%93%E5%8C%85%E5%8E%8B%E7%BC%A9/","excerpt":"Linux find 命令用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名;tar命令是Unix/Linux系统中备份文件的可靠方法，几乎可以工作于任何环境中，它的使用权限是所有用户，建议针对目录。","text":"文件查找和打包压缩 内容概述 123456789- locate - find - xargs - compress和uncompress - gzip和gunzip - bzip2和bunzip2 - xz和unxz - zip和unzip - tar 1 查找工具在文件系统上查找符合条件的文件文件查找： 非实时查找(数据库查找)：locate 实时查找：find 1.1 locatelocate 查询系统上预建的文件索引数据库&#x2F;var&#x2F;lib&#x2F;mlocate&#x2F;mlocate.db索引的构建是在系统较为空闲时自动进行(周期性任务)，执行updatedb可以更新数据库索引构建过程需要遍历整个根文件系统，很消耗资源locate和updatedb命令来自于mlocate包工作特点: 查找速度快 模糊查找 非实时查找 搜索的是文件的全路径，不仅仅是文件名 可能只搜索用户具备读取和执行权限的目录 格式： 1locate [OPTION]... [PATTERN]... 常用选项： 123-i 不区分大小写的搜索-n N 只列举前N个匹配项目-r 使用基本正则表达式 范例： 1234#搜索名称或路径中包含“conf&quot;的文件locate conf#使用Regex来搜索以“.conf&quot;结尾的文件locate -r &#x27;\\.conf$&#x27; 范例：创建locatedb数据库 123456[root@rocky8 data]# updatedb[root@rocky8 data]# locate -n 3 conf/boot/config-4.18.0-372.13.1.el8_6.x86_64/boot/config-4.18.0-372.9.1.el8.x86_64/boot/grub2/i386-pc/configfile.mod[root@rocky8 data]# 范例: 文件新创建和删除,无法马上更新locate数据库 1234567891011121314151617181920212223242526272829303132333435# 创建yuankun.txt文件查找没有结果[root@rocky8 data]# touch yuankun.txt[root@rocky8 data]# locate yuankun.txt [root@rocky8 data]# # 已经删除/data/a.txt文件，查找a.txt文件还能找到[root@rocky8 data]# lltotal 8-rw-r--r-- 1 root root 22 Jul 30 04:07 a.txt-rw-r--r-- 1 root root 1511 Jul 30 05:11 passwd-rw-r--r-- 1 root root 0 Aug 1 22:06 yuankun.txt[root@rocky8 data]# rm -rf a.txt [root@rocky8 data]# locate a.txt/data/a.txt/home/yuankun/a.txt/root/a.txt/root/data.txt/usr/lib/firmware/brcm/brcmfmac43340-sdio.pov-tab-p1006w-data.txt/usr/lib/firmware/brcm/brcmfmac43430-sdio.sinovoip,bpi-m2-ultra.txt/usr/share/crypto-policies/DEFAULT/java.txt/usr/share/crypto-policies/EMPTY/java.txt/usr/share/crypto-policies/FIPS/java.txt/usr/share/crypto-policies/FUTURE/java.txt/usr/share/crypto-policies/LEGACY/java.txt/usr/share/doc/perl-CPAN-Meta/t/README-data.txt/usr/share/doc/vim-common/README_extra.txt/usr/share/gnupg/help.ca.txt/usr/share/gnupg/help.da.txt/usr/share/gnupg/help.ja.txt/usr/share/vim/vim80/doc/ft_ada.txt/usr/share/vim/vim80/doc/if_lua.txt/usr/share/vim/vim80/doc/os_amiga.txt/usr/share/vim/vim80/doc/uganda.txt/www/server/panel/pyenv/lib/python3.7/test/test_email/data/msg_12a.txt[root@rocky8 data]# 1.2 findfind 是实时查找工具，通过遍历指定路径完成文件查找。工作特点： 查找速度略慢 精确查找 实时查找 查找条件丰富 可能只搜索用户具备读取和执行权限的目录 格式： 1find [OPTION]... [查找路径] [查找条件] [处理动作] 查找路径：指定具体目标路径；默认为当前目录查找条件：指定的查找标准，可以文件名、大小、类型、权限等标准进行；默认为找出指定路径下的所有文件处理动作：对符合条件的文件做操作，默认输出至屏幕 1.2.1 指定搜索目录层级12-maxdepth level 最大搜索目录深度,指定目录下的文件为第1级-mindepth level 最小搜索目录深度 范例： 1find /etc -maxdepth 2 -mindepth 2 1.2.2 对每个目录先处理目录内的文件，再处理目录本身12-depth-d #warning: the -d option is deprecated; please use -depth instead, because the latter is a POSIX-compliant feature 范例： 12345678910111213141516171819202122232425[root@centos8 data]#tree /data/test/data/test├── f1.txt├── f2.txt└── test2└── test3├── f3.txt└── f4.txt4 directories, 2 files[root@centos8 data]#find /data/test/data/test/data/test/f1.txt/data/test/f2.txt/data/test/test2/data/test/test2/test3/data/test/test2/test3/f3.txt/data/test/test2/test3/f4.txt[root@centos8 data]#find /data/test -depth/data/test/f1.txt/data/test/f2.txt/data/test/test2/test3/f3.txt/data/test/test2/test3/f4.txt/data/test/test2/test3/data/test/test2/data/test 1.2.3 根据文件名和inode查找123456-name &quot;文件名称&quot; #支持使用glob，如：*, ?, [], [^],通配符要加双引号引起来-iname &quot;文件名称&quot; #不区分字母大小写-inum n #按inode号查找-samefile name #相同inode号的文件-links n #链接数为n的文件-regex “PATTERN&quot; #以PATTERN匹配整个文件路径，而非文件名称 1.2.4 根据属主、属组查找123456-user USERNAME #查找属主为指定用户(UID)的文件-group GRPNAME #查找属组为指定组(GID)的文件-uid UserID #查找属主为指定的UID号的文件-gid GroupID #查找属组为指定的GID号的文件-nouser #查找没有属主的文件-nogroup #查找没有属组的文件 1.2.5 根据文件类型查找123456789-type TYPETYPE可以是以下形式：f: 普通文件d: 目录文件l: 符号链接文件s：套接字文件b: 块设备文件c: 字符设备文件p: 管道文件 范例： 12#查看/home的目录find /home –type d -ls 1.2.6 空文件或目录1-empty 范例： 1[root@centos8 ~]#find /app -type d -empty 1.2.7 组合条件123与：-a ，默认多个条件是与关系，所以可以省略-a或：-o非：-not ! 范例： 123456[root@centos8 ~]#find /etc/ -type d -o -type l |wc -l307[root@centos8 ~]#find /etc/ -type d -o -type l -ls |wc -l101[root@centos8 ~]#find /etc/ \\( -type d -o -type l \\) -ls |wc -l30 德·摩根定律： 非 A) 且 (非 B) &#x3D; 非(A 或 B) (非 A) 或 (非 B) &#x3D; 非(A 且 B) 示例： 12!A -a !B = !(A -o B)!A -o !B = !(A -a B) 范例： 123#找出/tmp目录下，属主不是root，且文件名不以f开头的文件find /tmp \\( -not -user root -a -not -name &#x27;f*&#x27; \\) -lsfind /tmp -not \\( -user root -o -name &#x27;f*&#x27; \\) –ls 1.2.8 排除目录1234567#查找/etc/下，除/etc/security目录的其它所有.conf后缀的文件find /etc -path &#x27;/etc/security&#x27; -a -prune -o -name &quot;*.conf&quot;#查找/etc/下，除/etc/security和/etc/systemd,/etc/dbus-1三个目录的所有.conf后缀的文件find /etc \\( -path &quot;/etc/security&quot; -o -path &quot;/etc/systemd&quot; -o -path &quot;/etc/dbus-1&quot; \\) -a -prune -o -name &quot;*.conf&quot;#排除/proc和/sys目录find / \\( -path &quot;/sys&quot; -o -path &quot;/proc&quot; \\) -a -prune -o -type f -a -mmin -1 范例: 1234567891011find / -size +10G[root@centos8 ~]#find / -size +10G/proc/kcorefind: ‘/proc/25229/task/25229/fd/6’: No such file or directoryfind: ‘/proc/25229/task/25229/fdinfo/6’: No such file or directoryfind: ‘/proc/25229/fd/5’: No such file or directoryfind: ‘/proc/25229/fdinfo/5’: No such file or directory[root@centos8 ~]#ll -h /proc/kcore-r-------- 1 root root 128T Dec 14 2020 /proc/kcore[root@centos8 ~]#du -sh /proc/kcore0 /proc/kcore 1.2.9 根据时间戳1234567891011#以“天&quot;为单位-atime [+|-]## #表示[#,#+1)+# #表示[#+1,∞]-# #表示[0,#)-mtime-ctime#以“分钟&quot;为单位-amin-mmin-cmin 1.2.10 根据权限查找12345-perm [/|-]MODEMODE #精确权限匹配/MODE #任何一类(u,g,o)对象的权限中只要有一位匹配即可，或关系，+ 从CentOS 7开始淘汰-MODE #每一类对象都必须同时拥有指定权限，与关系0 表示不关注 说明：find -perm 755 会匹配权限模式恰好是755的文件只要当任意人有写权限时，find -perm &#x2F;222就会匹配只有当每个人都有写权限时，find -perm -222才会匹配只有当其它人（other）有写权限时，find -perm -002才会匹配 1.2.11 处理动作12345678-print：默认的处理动作，显示至屏幕-ls：类似于对查找到的文件执行&quot;ls -dils&quot;命令格式输出-fls file：查找到的所有文件的长格式信息保存至指定文件中，相当于 -ls &gt; file-delete：删除查找到的文件，慎用！-ok COMMAND &#123;&#125; \\; 对查找到的每个文件执行由COMMAND指定的命令，对于每个文件执行命令之前，都会交互式要求用户确认-exec COMMAND &#123;&#125; \\; 对查找到的每个文件执行由COMMAND指定的命令&#123;&#125;: 用于引用查找到的文件名称自身 关于 {} ; 1https://askubuntu.com/questions/339015/what-does-mean-in-the-find-command 范例： 12345678910111213141516171819202122232425262728#备份配置文件，添加.orig这个扩展名[root@rocky8 data]# lltotal 4-rw-r--r-- 1 root root 0 Aug 2 21:02 file1.conf-rw-r--r-- 1 root root 0 Aug 2 21:02 file2.conf-rw-r--r-- 1 root root 0 Aug 2 21:02 file3.conf-rw-r--r-- 1 root root 0 Aug 2 21:02 file4.conf-rw-r--r-- 1 root root 1511 Jul 30 05:11 passwd-rw-r--r-- 1 root root 0 Aug 1 22:06 yuankun.txt[root@rocky8 data]# find ./ -name &#x27;file*.conf&#x27;./file1.conf./file2.conf./file3.conf./file4.conf[root@rocky8 data]# find ./ -name &#x27;file*.conf&#x27; -exec cp &#123;&#125; &#123;&#125;.orig \\;[root@rocky8 data]# lltotal 4-rw-r--r-- 1 root root 0 Aug 2 21:02 file1.conf-rw-r--r-- 1 root root 0 Aug 2 21:07 file1.conf.orig-rw-r--r-- 1 root root 0 Aug 2 21:02 file2.conf-rw-r--r-- 1 root root 0 Aug 2 21:07 file2.conf.orig-rw-r--r-- 1 root root 0 Aug 2 21:02 file3.conf-rw-r--r-- 1 root root 0 Aug 2 21:07 file3.conf.orig-rw-r--r-- 1 root root 0 Aug 2 21:02 file4.conf-rw-r--r-- 1 root root 0 Aug 2 21:07 file4.conf.orig-rw-r--r-- 1 root root 1511 Jul 30 05:11 passwd-rw-r--r-- 1 root root 0 Aug 1 22:06 yuankun.txt[root@rocky8 data]# 123456#提示删除存在时间超过３天以上的joe的临时文件find /tmp -ctime +3 -user joe -ok rm &#123;&#125; \\;#在主目录中寻找可被其它用户写入的文件find ~ -perm -002 -exec chmod o-w &#123;&#125; \\;#查找/data下的权限为644，后缀为sh的普通文件，增加执行权限find /data –type f -perm 644 -name &quot;*.sh&quot; –exec chmod 755 &#123;&#125; \\; 1.3 参数替换xargs由于很多命令不支持管道|来传递参数，xargs用于产生某个命令的参数，xargs 可以读入 stdin 的数据，并且以空格符或回车符将 stdin 的数据分隔成为参数另外，许多命令不能接受过多参数，命令执行可能会失败，xargs 可以解决注意：文件名或者是其他意义的名词内含有空格符的情况find 经常和 xargs 命令进行组合,形式如下： 1find | xargs COMMAND 范例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#显示10个数字[root@centos8 ~]#seq 10 | xargs1 2 3 4 5 6 7 8 9 10#删除当前目录下的大量文件ls | xargs rm#find -name &quot;*.sh&quot; | xargs ls -Sl[root@centos8 data]#echo &#123;1..10&#125; |xargs1 2 3 4 5 6 7 8 9 10[root@centos8 data]#echo &#123;1..10&#125; |xargs -n112345678910[root@centos8 data]#echo &#123;1..10&#125; |xargs -n21 23 45 67 89 10#批量创建和删除用户echo user&#123;1..10&#125; |xargs -n1 useraddecho user&#123;1..100&#125; | xargs -n1 userdel -r#这个命令是错误的find /sbin/ -perm /700 | ls -l#查找有特殊权限的文件，并排序find /bin/ -perm /7000 | xargs ls -Sl#此命令和上面有何区别？find /bin/ -perm -7000 | xargs ls -Sl#以字符nul分隔find -type f -name &quot;*.txt&quot; -print0 | xargs -0 rm#并发执行多个进程seq 100 |xargs -i -P10 wget -P /data http://10.0.0.8/&#123;&#125;.html#并行下载bilibili视频yum install python3-pip -ypip3 install you-getseq 60 | xargs -i -P3 you-get https://www.bilibili.com/video/BV14K411W7UF?p=&#123;&#125; 练习1、查找&#x2F;var目录下属主为root，且属组为mail的所有文件2、查找&#x2F;var目录下不属于root、lp、gdm的所有文件3、查找&#x2F;var目录下最近一周内其内容修改过，同时属主不为root，也不是postfix的文件4、查找当前系统上没有属主或属组，且最近一个周内曾被访问过的文件5、查找&#x2F;etc目录下大于1M且类型为普通文件的所有文件6、查找&#x2F;etc目录下所有用户都没有写权限的文件7、查找&#x2F;etc目录下至少有一类用户没有执行权限的文件8、查找&#x2F;etc&#x2F;init.d目录下，所有用户都有执行权限，且其它用户有写权限的文件 2 压缩和解压缩主要针对单个文件压缩，而非目录 2.1 compress和uncompress此工具来自于ncompress包,此工具目前已经很少使用对应的文件是 .Z 后缀 常用选项 123-d 解压缩，相当于uncompress-c 结果输出至标准输出,不删除原文件-v 显示详情 范例： 12compress filename #压缩uncompress filename # 解压缩 zcat file.Z 不显式解压缩的前提下查看文本文件内容 1zcat file.Z &gt;file 2.2 gzip和gunzip来自于 gzip 包对应的文件是 .gz 后缀格式： 1gzip [OPTION] ···file··· 常用选项： 1234-k keep, 保留原文件,CentOS 8 新特性-d 解压缩，相当于gunzip-c 结果输出至标准输出，保留原文件不改变-# 指定压缩比，#取值为1-9，值越大压缩比越大 范例： 12345678# 压缩gzip filename# 解压缩gunzip file.gz#不显式解压缩的前提下查看文本文件内容zcat file.gz 范例: 1234gzip -c messages &gt;messages.gzgzip -c -d messages.gz &gt; messageszcat messages.gz &gt; messagescat messages | gzip &gt; m.gz 2.3 bzip2和bunzip2来自于 bzip2 包对应的文件是 .bz2 后缀格式： 1bzip2 [OPTION]... FILE ... 常用选项： 1234-k keep, 保留原文件-d 解压缩-c 结果输出至标准输出，保留原文件不改变-# 1-9，压缩比，默认为9 范例： 123bzip2 file # 压缩bunzip2 file.bz2 解压缩bzcat file.bz2 不显式解压缩的前提下查看文本文件内容 2.4 xz和unxz来自于 xz 包对应的文件是 .xz 后缀格式: 1xz [OPTION]... FILE ... 常用选项： 1234-k keep, 保留原文件-d 解压缩-c 结果输出至标准输出，保留原文件不改变-# 压缩比，取值1-9，默认为6 范例： 12unxz file.xz #解压缩xzcat file.xz #不显式解压缩的前提下查看文本文件内容 2.5 zip和unzipzip 可以实现打包目录和多个文件成一个文件并压缩，但可能会丢失文件属性信息，如：所有者和组信息，一般建议使用 tar 代替分别来自于 zip 和 unzip 包对应的文件是 .zip 后缀范例: zip帮助 1234567891011#打包并压缩zip -r /backup/sysconfig.zip /etc/sysconfig/#不包括目录本身，只打包目录内的文件和子目录cd /etc/sysconfig; zip -r /root/sysconfig.zip *#默认解压缩至当前目录unzip /backup/sysconfig.zip#解压缩至指定目录,如果指定目录不存在，会在其父目录（必须事先存在）下自动生成unzip /backup/sysconfig.zip -d /tmp/configcat /var/log/messages | zip messages -#-p 表示管道unzip -p message.zip &gt; message 范例: 交互式加密和解密 1234567891011121314151617181920212223[root@rocky8 data]# zip -e file1.conf.zip file1.confEnter password: Verify password: adding: file1.conf (stored 0%)[root@rocky8 data]# unzip file1.conf.zip Archive: file1.conf.zip[file1.conf.zip] file1.conf password: replace file1.conf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y extracting: file1.conf [root@rocky8 data]# lltotal 8-rw-r--r-- 1 root root 0 Aug 2 21:02 file1.conf-rw-r--r-- 1 root root 0 Aug 2 21:07 file1.conf.orig-rw-r--r-- 1 root root 198 Aug 2 22:06 file1.conf.zip-rw-r--r-- 1 root root 0 Aug 2 21:02 file2.conf-rw-r--r-- 1 root root 0 Aug 2 21:07 file2.conf.orig-rw-r--r-- 1 root root 0 Aug 2 21:02 file3.conf-rw-r--r-- 1 root root 0 Aug 2 21:07 file3.conf.orig-rw-r--r-- 1 root root 0 Aug 2 21:02 file4.conf-rw-r--r-- 1 root root 0 Aug 2 21:07 file4.conf.orig-rw-r--r-- 1 root root 1511 Jul 30 05:11 passwd-rw-r--r-- 1 root root 0 Aug 1 22:06 yuankun.txt[root@rocky8 data]# 范例: 非交互式加密和解密 123456789[root@rocky8 data]# zip -P 123456 file2.conf.zip file2.conf # p是大P adding: file2.conf (stored 0%)# 解压[root@rocky8 data]# unzip file2.conf.zip Archive: file2.conf.zip[file2.conf.zip] file2.conf password: replace file2.conf? [y]es, [n]o, [A]ll, [N]one, [r]ename: y extracting: file2.conf [root@rocky8 data]# 3 打包和解包3.1 tartar 即 Tape ARchive 磁带归档，可以对目录和多个文件打包一个文件，并且可以压缩，保留文件属性不丢失，常用于备份功能，推荐使用对应的文件是 .tar 后缀格式 12345678910tar [-ABcdgGhiklmMoOpPrRsStuUvwWxzZ][-b &lt;区块数目&gt;][-C &lt;目的目录&gt;][-f &lt;备份文件&gt;][-F&lt;Script文件&gt;][-K &lt;文件&gt;][-L &lt;媒体容量&gt;][-N &lt;日期时间&gt;][-T &lt;范本文件&gt;][-V &lt;卷册名称&gt;][-X&lt;范本文件&gt;][-&lt;设备编号&gt;&lt;存储密度&gt;][--after-date=&lt;日期时间&gt;][--atime-preserve][--backuup=&lt;备份方式&gt;][--checkpoint][--concatenate][--confirmation][--delete][--exclude=&lt;范本样式&gt;][--force-local][--group=&lt;群组名称&gt;][--help][--ignore-failed-read][--new-volume-script=&lt;Script文件&gt;][--newer-mtime][--no-recursion][--null][--numeric-owner][--owner=&lt;用户名称&gt;][--posix][--erve][--preserve-order][--preserve-permissions][--record-size=&lt;区块数目&gt;][--recursive-unlink][--remove-files][--rsh-command=&lt;执行指令&gt;][--same-owner][--suffix=&lt;备份字尾字符串&gt;][--totals][--use-compress-program=&lt;执行指令&gt;][--version][--volno-file=&lt;编号文件&gt;][文件或目录...] 常用选项： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576-A或--catenate 新增文件到已存在的备份文件。-b&lt;区块数目&gt;或--blocking-factor=&lt;区块数目&gt; 设置每笔记录的区块数目，每个区块大小为12Bytes。-B或--read-full-records 读取数据时重设区块大小。-c或--create 建立新的备份文件。-C&lt;目的目录&gt;或--directory=&lt;目的目录&gt; 切换到指定的目录。-d或--diff或--compare 对比备份文件内和文件系统上的文件的差异。-f&lt;备份文件&gt;或--file=&lt;备份文件&gt; 指定备份文件。-F&lt;Script文件&gt;或--info-script=&lt;Script文件&gt; 每次更换磁带时，就执行指定的Script文件。-g或--listed-incremental 处理GNU格式的大量备份。-G或--incremental 处理旧的GNU格式的大量备份。-h或--dereference 不建立符号连接，直接复制该连接所指向的原始文件。-i或--ignore-zeros 忽略备份文件中的0 Byte区块，也就是EOF。-k或--keep-old-files 解开备份文件时，不覆盖已有的文件。-K&lt;文件&gt;或--starting-file=&lt;文件&gt; 从指定的文件开始还原。-l或--one-file-system 复制的文件或目录存放的文件系统，必须与tar指令执行时所处的文件系统相同，否则不予复制。-L&lt;媒体容量&gt;或-tape-length=&lt;媒体容量&gt; 设置存放每体的容量，单位以1024 Bytes计算。-m或--modification-time 还原文件时，不变更文件的更改时间。-M或--multi-volume 在建立，还原备份文件或列出其中的内容时，采用多卷册模式。-N&lt;日期格式&gt;或--newer=&lt;日期时间&gt; 只将较指定日期更新的文件保存到备份文件里。-o或--old-archive或--portability 将资料写入备份文件时使用V7格式。-O或--stdout 把从备份文件里还原的文件输出到标准输出设备。-p或--same-permissions 用原来的文件权限还原文件。-P或--absolute-names 文件名使用绝对名称，不移除文件名称前的&quot;/&quot;号。-r或--append 新增文件到已存在的备份文件的结尾部分。-R或--block-number 列出每个信息在备份文件中的区块编号。-s或--same-order 还原文件的顺序和备份文件内的存放顺序相同。-S或--sparse 倘若一个文件内含大量的连续0字节，则将此文件存成稀疏文件。-t或--list 列出备份文件的内容。-T&lt;范本文件&gt;或--files-from=&lt;范本文件&gt; 指定范本文件，其内含有一个或多个范本样式，让tar解开或建立符合设置条件的文件。-u或--update 仅置换较备份文件内的文件更新的文件。-U或--unlink-first 解开压缩文件还原文件之前，先解除文件的连接。-v或--verbose 显示指令执行过程。-V&lt;卷册名称&gt;或--label=&lt;卷册名称&gt; 建立使用指定的卷册名称的备份文件。-w或--interactive 遭遇问题时先询问用户。-W或--verify 写入备份文件后，确认文件正确无误。-x或--extract或--get 从备份文件中还原文件。-X&lt;范本文件&gt;或--exclude-from=&lt;范本文件&gt; 指定范本文件，其内含有一个或多个范本样式，让ar排除符合设置条件的文件。-z或--gzip或--ungzip 通过gzip指令处理备份文件。-Z或--compress或--uncompress 通过compress指令处理备份文件。-&lt;设备编号&gt;&lt;存储密度&gt; 设置备份用的外围设备编号及存放数据的密度。--after-date=&lt;日期时间&gt; 此参数的效果和指定&quot;-N&quot;参数相同。--atime-preserve 不变更文件的存取时间。--backup=&lt;备份方式&gt;或--backup 移除文件前先进行备份。--checkpoint 读取备份文件时列出目录名称。--concatenate 此参数的效果和指定&quot;-A&quot;参数相同。--confirmation 此参数的效果和指定&quot;-w&quot;参数相同。--delete 从备份文件中删除指定的文件。--exclude=&lt;范本样式&gt; 排除符合范本样式的文件。--group=&lt;群组名称&gt; 把加入设备文件中的文件的所属群组设成指定的群组。--help 在线帮助。--ignore-failed-read 忽略数据读取错误，不中断程序的执行。--new-volume-script=&lt;Script文件&gt; 此参数的效果和指定&quot;-F&quot;参数相同。--newer-mtime 只保存更改过的文件。--no-recursion 不做递归处理，也就是指定目录下的所有文件及子目录不予处理。--null 从null设备读取文件名称。--numeric-owner 以用户识别码及群组识别码取代用户名称和群组名称。--owner=&lt;用户名称&gt; 把加入备份文件中的文件的拥有者设成指定的用户。--posix 将数据写入备份文件时使用POSIX格式。--preserve 此参数的效果和指定&quot;-ps&quot;参数相同。--preserve-order 此参数的效果和指定&quot;-A&quot;参数相同。--preserve-permissions 此参数的效果和指定&quot;-p&quot;参数相同。--record-size=&lt;区块数目&gt; 此参数的效果和指定&quot;-b&quot;参数相同。--recursive-unlink 解开压缩文件还原目录之前，先解除整个目录下所有文件的连接。--remove-files 文件加入备份文件后，就将其删除。--rsh-command=&lt;执行指令&gt; 设置要在远端主机上执行的指令，以取代rsh指令。--same-owner 尝试以相同的文件拥有者还原文件。--suffix=&lt;备份字尾字符串&gt; 移除文件前先行备份。--totals 备份文件建立后，列出文件大小。--use-compress-program=&lt;执行指令&gt; 通过指定的指令处理备份文件。--version 显示版本信息。--volno-file=&lt;编号文件&gt; 使用指定文件内的编号取代预设的卷册编号。 范例：打包并压缩 1tar zcvf filename.tar.gz filename 范例：解压缩 1tar xf filename.tar.gz 3.2 splitsplit 命令可以分割一个文件为多个文件范例： 123456#分割大的 tar 文件为多份小文件split -b Size –d tar-file-name prefix-name示例:split -b 1M mybackup.tgz mybackup-parts#切换成的多个小分文件使用数字后缀split -b 1M –d mybackup.tgz mybackup-parts 将多个切割的小文件合并成一个大文件 1cat mybackup-parts* &gt; mybackup.tar.gz","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"软件测试面试题","slug":"软件测试面试题","date":"2022-07-31T17:30:11.000Z","updated":"2022-11-15T10:06:27.979Z","comments":true,"path":"2022/08/01/软件测试面试题/","link":"","permalink":"http://snippet.itshare.work/2022/08/01/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E9%9D%A2%E8%AF%95%E9%A2%98/","excerpt":"收集软件测试一些基础面试题!欢迎补充.","text":"1、软件测试流程 需求评审 测试计划编写 测试用例编写 测试用例评审 执行测试用例(搭建测试环境) 编写测试报告 2、缺陷定义 需求要求的功能没有实现 实现了需求没有要求的功能（画蛇添足） 软件中出现了指明不应出现的错误 需求虽未明确指明，但是应该实现的功能没有实现 3、黑盒测试用例设计方法 等价类划分法 123用户名长度为6-10位有效输入：6-10 可以穷举无效输入：&lt;6 可以穷举，&gt;10 穷举？？？？ 边界值 123用户名长度为6-10位有效边界值：6、7、8、9、10无效边界值：&lt;6 和 &gt;10 场景分析法(ATM取款) 正交表法 状态迁移法12明确需求中有多少个状态 比如订单状态：待发货、已发货、签收、申请取消、拒收等 判定表 1某系统对修改密码有如下要求：首先输入原密码，原密码正确后才能输入新密码与确认密码，否则系统提示原密码错误。输入新密码与确认密码，检查通过后修改密码成功。新密码要求6-10位，由字母+数字组成，如果不合法提示新密码不满足复杂度要求；如果确认密码与新密码不一致，提示确认密码必须与新密码一致。请使用判定表法编写测试用例。 4、六大测试分类 功能性测试（Functionality）：关注功能是否正确。 可用性测试（Usability）：关注产品是否好用。 兼容性测试（Compatibility）：关注产品是否适用多种平台。 可靠性测试（Reliability）：关注产品是否稳定可靠。 安全性测试（Security）：关注产品是否存在漏洞。 性能测试（Performance）：关注产品是否能够高效运行。 5、测试用例包含那些内容 测试用例编号 测试用例标题 前置条件 测试用例操作步骤 预期结果 优先级 6、怎么保证测试覆盖率123456789测试用例覆盖率很难达到100%，越复杂的功能越难保证，只能说尽量提高测试覆盖率。通过以下手段可以提高覆盖率：(1)编写测试用例前，检查相关需求、设计文档是否有问题（功能描述不清，设计逻辑缺陷），如有问题找相关设计或者产品问清楚。(2)功能列表包含新增和修改功能点，性能需求也要列出来（因为要整理对应的性能测试用例），同时还需要对既有功能进行一个梳理，检查是否会与其他功能有交互，整理出影响点。(3)把功能列表发给组员，并找时间进行会议评审，主要对功能等进行查漏补缺。(4)最后才行进测试用例编写，注意编写规范。(5)编写完毕后，把测试用例发给组员，开会进行评审，主要对检查点、用例规范进行查漏补缺。(6)执行测试用例过程中，发现用例不完善或者错误，需对测试用例进行及时的修改与调优(7)测试完毕后对漏测的bug进行测试用例补充。 7、软件测试方法 按是否清楚程序的内部逻辑：白盒测试、灰盒测试、黑盒测试 按测试执行的方式：手工测试、自动化测试 按是否允许被测软件：静态测试、动态测试 8、开发对缺陷不认可如何处理123(1)检查提交的BUG描述是否清楚、是否复现(2)查阅需求、设计文档看是否有对该问题有描述，如果没有查看类似软件是否存在该问题(3)如果还是不能将情况汇报给领导，并说明BUG的情况以及自己认为是BUG的理由 9、BUG不可复现怎么办先在出现该问题上的环境上尽量重现，保持浏览器、账号、操作步骤环境一致。如果还是不能重现，把bug记录到BUG管理平台，详细记录BUG的操作步骤、特征、环境账号、操作截图、出现错误截图和日志截图等，并注明是偶现。如果BUG优先级比较高，项目时间允许，让开发协助重现。如果项目时间不允许，记录到BUG管理平台后续跟进。 10、如何判断BUG是前端还是后端问题123(1)界面：文字错误、排版混乱、兼容问题前端问题(2)通过抓包对接口返回信息进行分析，分析出缺陷一般为后端问题(3)后端查看日志 11、接口测试流程 获取接口文档、分析接口 编写接口测试用例 测试用例评审 执行测试用例(添加线程组、添加HTTP请求，根据接口文档填写相关请求参数、参数值，断言、添加查看结果树，看接口返回信息以预期信息是否一致) 提交、跟踪缺陷和回归测试 编写测试报告 12、测试报告内容 测试范围 测试时间 测试人员 测试策略 缺陷统计与分析 上线风险 遗留问题 测试是否通过 13、职业规划12- 短期学习公司的业务，然后上手自己的工作，做好自己的本职工作，适应公司节奏- 长期来看，我会根据公司的发展需要继续提升自己的某项专业能力，把学习到的测试技能更好的应用到工作中去 14、说出自己的缺点虽然已经有两年的工作经历，但是还是认为自己的经验还不是很丰富，后期呢我也会多多加深自己的测试技术。 15、做测试自己最大的优势(1)站在客户的角度思考问题，好的技术人员除了技术过硬外，还要懂得从用户的角度出发，要了解用户，所以我在工作中，揣摩用户的使用习惯，表达自己对产品的使用感受，在测试过程中除了提交BUG，也会偶尔反馈一些优化建议。 (2)比较有责任心。领导交付给我一个任务。每天下班之前反馈进度，保证项目进度。遇到问题主动去协调不同部门的同事解决问题。 16、UI自动化元素过程中定位不到的原因 元素表达式编写错误 元素未完全加载出来 元素嵌套在iframe中 元素在新窗口中 脚本流程与实际流程不符合 元素不在当前页 17、UI自动化八种定位方式 id name class_name、 tag_name(标签名称)、 link_text(定位a标签)、 partial_link_text(定位a标签模糊)、 Xpath(基于路径定位) css(元素选择器) 18、UI自动化三种等待方式 强制等待如sleep(5)，一定会等待5秒才会继续执行下面的代码 显示等待只针对当前元素，在指定条件内不断查找元素，直到找到元素或者超时报错 隐式等待在指定的时间范围内查找元素，直到找到元素或者超时(报错 no suchelement)，特点是全局的 19、UI自动化测试框架组成结构 测试用例&#x2F;测试数据 基础方法（包含PO分层，数据驱动） 工具包 测试报告 测试日志 20、PO模式减少代码重复，增加代码可读性，更容易维护。包含对象层、操作层、业务层。 封装driver 封装页面元素定位方法 封装页面元素操作，如输入用户名、密码等 根据封装页面元素操作方法组合成业务 21、linux常用命令123456789101112131415161718192021tail -f #查看日志文件cd #切换目录ls #查看当前目录文件df #查看磁盘使用情况top #查看服务器资源使用情况ps #查看进程使用情况netstat #查看端口占用情况find #查找cp #复制tar #解压缩mv #重命名kill #gerp #查找文档vi #功能强大的纯文本编辑器unzip #解压缩mkdir #创建文件touch #创建新的空文件tail -n 100 filename #查看文件100行head -n 200filename |tail -n 100 #查看文件100行到200行chmod #用来变更文件或目录的权限cat #显示文件内容 22、印象最深的BUG(1)登录页面，输入密码后，点击密码明文显示后，点击登录提示密码错误。前端页面发现密码并没有错误。后通过抓包将密码MD5解密后发现密码少了一位。最后得出输入密码后点击密码明文显示后密码会自动减少一位 (2)最近测试的商城项目，员工为销售的订单管理页面，查看订单详情，将URL中的订单更改为其他销售下的订单号，然后可以成功查看其他销售下的订单详情。 23、问面试官的问题 薪资组成结构 试用期缴纳社保吗 12薪还是13薪等 工作内容是啥 入职是否有培训？公司是否提供专业学习机会 请问您在贵公司工作多久了 考核方式 问团队气氛，了解你的公司 比如:咱们团队多少人？工作年限大概是多久呀？问题：面试的最后，面试官会说你有什么要问我的吗？那么我们需要注意哪些？答：1）不要问跟工作无关的问题。2）问工作内容，明确你的职能。比如：如果得到这份工作，以后谁来带我呢？如果成为贵公司的一员，你们希望我短期内解决什么问题呢？未来一年，我们部门的工作目标是什么？岗位的主要职责我已经明白了，公司对我还有什么其他的要求吗？3)问工作潜力，打听你的未来比如:入职后的几个月，我会参加哪些培训呢？这个岗位在咱们公司的晋升路径是什么样的？您对我这个岗位三到五年的职责规划有什么建议吗？4)问团队气氛，了解你的公司比如:咱们团队多少人？工作年限大概是多久呀？您觉得最能代表咱们公司的员工是怎样的呢？能带我参观一下咱们的办公区域吗？5)问工作体验，拉近跟面试官的距离您在这里工作多久了？您最喜欢这家公司的什么地方？最不喜欢什么地方？能给我大概讲讲公司的企业文化吗？能给我举一个公司团队合作的例子吗？如果再给您一次机会，您还会选择这家公司吗？ 24、产品上线标准 测试用例是否全部百分之百执行完毕，如果还有未执行完毕的用例，是什么原因没有全部执行完，例如时间的原因，或者是优先级比较低的一个应用性测试用例 剩余的bug数量和严重程度的这个等级要达到一定的标准，比如说不存在致命性、严重程度的这样一个bug，建议或不影响使用的遗留问题需要经过产品经理和测试经理协同制定这个可用的一个数量 上线前的最后回归测试是否完成 25、遇到frame框架页面怎么处理问:遇到frame框架页面怎么处理?答:1.先定位到frame;2.再用driver.switch_to.frame()跳转进frame进行操作;3.操作完后使用driver.swith_to.default_content()跳转出来frame 26、UI自动化测试用例怎么设计 27、如何去提升UI自动化测试用例的稳定性?答:1.使用xpath表达式定位元素时，使用相对路径;2.定位元素时尽量使用显式等待，等要操作的元素出现之后再执行下面的操作;3.多用try捕获异常、处理异常;4.降低用例间的耦合;5.尽量使用单独的测试环境，避免其他类型的测试同步进行，对数据造成干扰;6.脚本执行失败后加入重试机制;7.用例执行结束后对测试场景进行还原，避免影响其他测试用例的执行 28、元素定位到了，却点击无效(也没报错），如何解决?答:可以使用js进行点击操作例如: 12js = &#x27;document.getElementByld(&quot;baidu&quot;).click()&#x27;driver.execute_script(js) 29、微信视频聊天测试点传送门 30、unittest是什么？unittest是python内置的单元测试框架，具备编写用例、组织用例、执行用例、输出报告等自动化框架的条件。使用unittest前需要了解该框架的五个概念: 即test case,test suite,testLoader，test runner,test fixture。 test case ：一个完整的测试单元，执行该测试单元可以完成对某一个问题的验证，完整体现在：测试前环境准备(setUp)，执行测试代码(run)，及测试后环境还原(tearDown)； test suite ：多个测试用例的集合，测试套件或测试计划； testLoader ：加载TestCase到TestSuite中的，其中loadTestsFrom__()方法用于寻找TestCase，并创建它们的实例，然后添加到TestSuite中，返回TestSuite实例； test runner ：执行测试用例，并将测试结果保存到TextTestResult实例中，包括运行了多少测试用例， 成功了多少，失败了多少等信息； test fixture：一个测试用例的初始化准备及环境还原，主要是setUp() 和 setDown()方法； 31、unitest的工作原理通过unittest类调用分析，可将框架的工作流程概况如下： 编写TestCase，由TestLoader加载TestCase到TestSuite，然后由TextTestRunner来运行TestSuite，最后将运行的结果保存在TextTestResult中。 计算机网络基础1.描述用浏览器访问 www.baidu.com 的过程1.浏览器向DNS服务器发出解析域名的请求；2.DNS服务器将”","categories":[{"name":"软件测试面经","slug":"软件测试面经","permalink":"http://snippet.itshare.work/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E9%9D%A2%E7%BB%8F/"}],"tags":[{"name":"软件测试工程师面试基础","slug":"软件测试工程师面试基础","permalink":"http://snippet.itshare.work/tags/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%9F%BA%E7%A1%80/"}],"keywords":[{"name":"软件测试面经","slug":"软件测试面经","permalink":"http://snippet.itshare.work/categories/%E8%BD%AF%E4%BB%B6%E6%B5%8B%E8%AF%95%E9%9D%A2%E7%BB%8F/"}]},{"title":"文本处理工具和正则表达式","slug":"文本处理工具和正则表达式","date":"2022-07-26T12:09:30.000Z","updated":"2022-12-16T14:57:11.557Z","comments":true,"path":"2022/07/26/文本处理工具和正则表达式/","link":"","permalink":"http://snippet.itshare.work/2022/07/26/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"本文将介绍Linux下使用Shell处理文本时最常用的工具并结合正则表达式处理文本。","text":"1.文本编辑工具之神VIM1.1使用vim初步1.1.1vim命令格式1vim [option]··· FILE ··· 常用选项： 1+# 打开文件后，让光标处于第#行的行首，+默认行尾 范例： 1vim +10 passwd 1234567+/PATTERN 让光标处于第一个被PATTERN匹配到的行行首-b file 二进制方式打开文件-d file1 file2… 比较多个文件，相当于 vimdiff-m file 只读打开文件-e file 直接进入ex模式，相当于执行ex file-y file Easy mode (like &quot;evim&quot;, modeless)，直接可以操作文件，ctrl+o:wq|q! 保存和不保存退出 说明： 如果该文件存在，文件被打开并显示内容 如果该文件不存在，当编辑后第一次存盘时创建它 1.1.2三种主要模式三种常见模式： 命令或普通(Normal)模式：默认模式，可以实现移动光标，剪切&#x2F;粘贴文本 插入(Insert)或编辑模式：用于修改文本 扩展命令(extended command )或命令(末)行模式：保存，退出等 命令模式–》插入模式 123456i insert, 在光标所在处输入I 在当前光标所在行的行首输入a append, 在光标所在处后面输入A 在当前光标所在行的行尾输入o 在当前光标所在行的下方打开一个新行O 在当前光标所在行的上方打开一个新行 插入模式 — ESC—–&gt; 命令模式 命令模式 —- : —-&gt; 扩展命令模式 扩展命令模式 —-ESC,enter—-&gt; 命令模式 范例: 插入颜色字符 123451 切换至插入模式2 按ctrl+v+[ 三个键,显示^[3 后续输入颜色信息,如:^[[32mhello^[[0m4 切换至扩展命令模式,保存退出5 cat 文件可以看到下面显示 1.2扩展命令模式按“:”（冒号）进入Ex模式，创建一个命令提示符：处于底部的屏幕左侧 1.2.1扩展模式基本命令123456w 写（存）磁盘文件wq 写入并退出x 写入并退出X 加密q 退出q！ 不存盘退出，即使更改都将丢失 读取文件内容到当前文件中 用法： 1r filename # 读文件内容到当前文件中 范例： 123# 将当前目录下的b文件的内容读取到当前文件中vim a.txt:r b.txt 将当前文件内容写入另一个文件 用法： 1w filename # 将当前文件内容写入另一个文件 范例： 123# 将当前文件(a.txt文件)内容写入到b.txt中去vim a.txtw c.txt 执行命令 用法： 1!command #执行命令 范例： 读入命令的输入 用法： 1r!command #读入命令的输入 范例：执行hostname命令输入到当前文件中 1.2.2地址定界格式： 1:start_pos,end_pos CMD 1.2.2.1地址定界格式1234567891011# #具体第#行，例如2表示第2行#,# #从左侧#表示起始行，到右侧#表示结尾行#,+# #从左侧#表示的起始行，加上右侧#表示的行数，范例：2,+3 表示2到5行. #当前行$ #最后一行.,$-1 #当前行到倒数第二行% #全文, 相当于1,$/pattern/ #从当前行向下查找，直到匹配pattern的第一行,即:正则表达式/pat1/,/pat2/ #从第一次被pat1模式匹配到的行开始，一直到第一次被pat2匹配到的行结束#,/pat/ #从指定行开始，一直找到第一个匹配pattern的行结束/pat/,$ #向下找到第一个匹配patttern的行到整个文件的结尾的所有行 1.2.2.2地址定界后跟一个编辑命令123456d #删除y #复制w file #将范围内的行另存至指定文件中r file #在指定位置插入指定文件中的所有内容t#行号 将前面指定的行复制到#行后m#行号 将前面指定的行移动到#行后 范例： 删除文件内容第几行到第几行 1:1,3d #删除第一行到第三行 复制文件全部内容 12:.,$y# 通过键盘上下键选择要复制在什么地方，选择后位置后按p键复制 删除文件全部内容 1:%d 1.2.3查找和替换格式： 1s/查找的内容/替换为内容/修饰符 说明： 123要查找的内容：可使用基本正则表达式模式替换为的内容：不能使用模式，但可以使用\\1, \\2, ...等后向引用符号；还可以使用“&amp;”引用前面查找时查找到的整个内容 修饰符： 123i #忽略大小写g #全局替换，默认情况下，每一行只替换第一次出现gc #全局替换，每次替换前询问 查找替换中的分隔符&#x2F;可替换为其它字符，如：#,@范例： 12s@/etc@/var@gs#/boot#/#i 复制&#x2F;etc&#x2F;passwd到家目录下，将文件内的root全部替换为ROOT 1:%s/root/ROOT/g 1.2.4定制vim的工作特性扩展命令模式的配置只是对当前vim进程有效，可将配置存放在文件中持久保存配置文件： 12/etc/vimrc #全局~/.vimrc #个人 1.2.4.1行号12显示：set number，简写 set nu取消显示：set nonumber, 简写 set nonu 1.2.4.2忽略字符的大小写12启用：set ignorecase，简写 set ic不忽略：set noic 1.2.4.3自动缩进12启用：set autoindent，简写 set ai禁用：set noai 1.2.4.4复制保留格式12启用：set paste禁用：set nopaste 1.2.4.5显示Tab ^I和换行符 和$显示12启用：set list禁用：set nolist 1.2.4.6高亮搜索12启用：set hlsearch禁用：set nohlsearch 简写：nohl 1.2.4.7语法高亮12启用：syntax on禁用：syntax off 1.2.4.8文件格式123启用windows格式：set fileformat=dos启用unix格式：set fileformat=unix简写 set ff=dos|unix 1.2.4.9Tab 用空格代替123启用：set expandtab 默认为8个空格代替Tab禁用：set noexpandtab简写：set et 1.2.4.10Tab用指定空格的个数代替12启用：set tabstop=# 指定#个空格代替Tab简写：set ts=4 1.2.4.11设置缩进宽度1234#向右缩进 命令模式&gt;&gt;#向左缩进 命令模式&lt;&lt;#设置缩进为4个字符set shiftwidth=4 1.2.4.12设置文本宽度12set textwidth=65 (vim only) #从左向右计数set wrapmargin=15 #从右到左计数 1.2.4.13 设置光标所在行的标识线12启用：set cursorline，简写 set cul禁用：set nocursorline 1.2.4.14加密12启用： set key=password禁用： set key= 1.2.4.15了解更多set帮助 12:help option-list:set or :set all 1.3命令模式1.3.1退出vim12ZZ 保存退出ZQ 不保存退出 1.3.2光标跳转 字符间跳转 12345h: 左l: 右j: 下k: 上#COMMAND：跳转由#指定的个数的字符 如：3l 单词间跳转 1234w：下一个单词的词首e：当前或下一单词的词尾b：当前或前一个单词的词首#COMMAND：由#指定一次跳转的单词数 当前页跳转 123456H：页首M：页中间行L：页底zt：将光标所在当前行移到屏幕顶端zz：将光标所在当前行移到屏幕中间zb：将光标所在当前行移到屏幕底端 行首行尾 123^ 跳转至行首的第一个非空白字符0 跳转至行首$ 跳转至行尾 行间移动 1234#G 或者扩展命令模式下:# 跳转至由第#行G 最后一行1G, gg 第一行 句间移动 12) 下一句( 上一句 段落间移动 12&#125; 下一段&#123; 上一段 命令模式翻屏操作 1234Ctrl+f 向文件尾部翻一屏,相当于PagedownCtrl+b 向文件首部翻一屏,相当于PageupCtrl+d 向文件尾部翻半屏Ctrl+u 向文件首部翻半屏 1.3.3字符编辑12345x 剪切光标处的字符 # p键可复制剪切的字符#x 剪切光标处起始的#个字符xp 交换光标所在处的字符及其后面字符的位置~ 转换大小写J 删除当前行后的换行符 1.3.4替换12r 只替换光标所在处的一个字符R 切换成REPLACE模式（在末行出现-- REPLACE -- 提示）,按ESC回到命令模式 1.3.5删除命令1234567891011d 删除命令，可结合光标跳转字符，实现范围删除d$ 删除到行尾d^ 删除到非空行首d0 删除到行首dwdedb#COMMANDdd： 剪切光标所在的行#dd 多行删除D：从当前光标位置一直删除到行尾，等同于d$ 1.3.6复制命令1234567891011y 复制，行为相似于d命令y$y0y^yeywyb#COMMANDyy：复制行#yy 复制多行Y：复制整行 1.3.7粘贴命令12p 缓冲区存的如果为整行，则粘贴当前光标所在行的下方；否则，则粘贴至当前光标所在处的后面P 缓冲区存的如果为整行，则粘贴当前光标所在行的上方；否则，则粘贴至当前光标所在处的前面 1.3.8查找1234/PATTERN：从当前光标所在处向文件尾部查找?PATTERN：从当前光标所在处向文件首部查找n：与命令同方向N：与命令反方向 1.3.9撤销更改123456u 撤销最近的更改，相当于windows中ctrl+z#u 撤销之前多次更改U 撤消光标落在这行后所有此行的更改Ctrl-r 重做最后的“撤消”更改，相当于windows中crtl+y. 重复前一个操作#. 重复前一个操作#次 1.3.10高级用法常见Command：y 复制、d 删除、gU 变大写、gu 变小写范例： 12340y$ 命令0 → 先到行头y → 从这里开始拷贝$ → 拷贝到本行最后一个字符 范例：粘贴“wang”100次 1100iwang [ESC] 12345di&quot; 光标在” “之间，则删除” “之间的内容yi( 光标在()之间，则复制()之间的内容vi[ 光标在[]之间，则选中[]之间的内容dtx 删除字符直到遇见光标之后的第一个 x 字符ytx 复制字符直到遇见光标之后的第一个 x 字符 1.4可视化模式在末行有”– VISUAL – “指示，表示在可视化模式允许选择的文本块 v 面向字符，– VISUAL – V 面向整行，– VISUAL LINE – ctrl-v 面向块，– VISUAL BLOCK –可视化键可用于与移动键结合使用w ) } 箭头等突出显示的文字可被删除，复制，变更，过滤，搜索，替换等范例：在文件指定行的行首插入# 1234561、先将光标移动到指定的第一行的行首2、输入ctrl+v 进入可视化模式3、向下移动光标，选中希望操作的每一行的第一个字符4、输入大写字母 I 切换至插入模式5、输入 #6、按 ESC 键 范例：在指定的块位置插入相同的内容 123451、光标定位到要操作的地方2、CTRL+v 进入“可视块”模式，选取这一列操作多少行3、SHIFT+i(I)4、输入要插入的内容5、按 ESC 键 1.5多文件模式12345678vim FILE1 FILE2 FILE3 ...:next 下一个:prev 前一个:first 第一个:last 最后一个:wall 保存所有:qall 不保存退出所有:wqall保存退出所有 1.6多窗口模式1.6.1多文件分割1234vim -o|-O FILE1 FILE2 ...-o: 水平或上下分割-O: 垂直或左右分割（vim only）在窗口间切换：Ctrl+w, Arrow 1.6.2单文件窗口12345Ctrl+w,s：split, 水平分割，上下分屏Ctrl+w,v：vertical, 垂直分割，左右分屏ctrl+w,q：取消相邻窗口ctrl+w,o：取消全部窗口:wqall 退出 1.7帮助1234:help:help topicUse :q to exit help#vimtutor 2.常见文本处理工具2.1文件内容查看命令2.1.1查看文本文件内容2.1.1.1 catcat可以查看文本内容 格式： 1cat [OPTION]... [FILE]... 常见选项： 12345-E：显示行结束符$-A：显示所有控制符-n：对显示出的每一行进行编号-b：非空行编号-s：压缩连续的空行成一行 2.1.1.2 nl显示行号，相当于cat -b 1234567[root@rocky8 ~]# nl data.txt 1 1 2 2 3 3 4 4 5 5[root@rocky8 ~]# 2.1.1.3 tac逆向显示文本内容 1234567891011121314[root@rocky8 ~]# cat data.txt 12345[root@rocky8 ~]# tac data.txt 54321[root@rocky8 ~]# 2.1.1.4 rev将同一行的内容逆向显示 1234567[root@rocky8 ~]# cat readme.txt 1 2 3 4 5 6a b c d e f[root@rocky8 ~]# rev readme.txt 6 5 4 3 2 1f e d c b a[root@rocky8 ~]# 2.1.2查看非文本文件内容范例：hexdump 123456hexdump -C -n 512 /dev/sda00000000 eb 63 90 10 8e d0 bc 00 b0 b8 00 00 8e d8 8e c0 |.c..............|echo &#123;a..z&#125; | tr -d &#x27; &#x27;|hexdump -C00000000 61 62 63 64 65 66 67 68 69 6a 6b 6c 6d 6e 6f 70 |abcdefghijklmnop|00000010 71 72 73 74 75 76 77 78 79 7a 0a |qrstuvwxyz.|0000001b 2.2. 分页查看文件内容2.2.1 more可以实现分页查看文件，可以配合管道符实现输出信息的分页 格式： 1more [OPTIONS...] FILE... 选项： 1-d: 显示翻页及退出提示 范例： 1more passwd 使用空格键往下查看，可显示进度百分比，“q”退出 2.2.2 lessless 也可以实现分页查看文件或STDIN输出，less 命令是man命令使用的分页器查看时有用的命令包括： 12/文本 搜索 文本n/N 跳到下一个 或 上一个匹配 范例：#less 配合管道对其它命令的执行结果进行分页显示 1cat passwd |less 2.3显示文本前面的或后面的内容2.3.1 head可以显示文件或标准输入的前面行格式： 1head [OPTION]... [FILE]... 选项： 123-c # 指定获取前#字节-n # 指定获取前#行,#如果为负数,表示从文件头取到倒数第#前-# 同上 范例：查看passwd文件前三行 12345[root@rocky8 ~]# head -n 3 passwd root:x:0:0:root:/root:/bin/bashroot:x:0:0:root:/root:/bin/bashroot:x:0:0:root:/root:/bin/bash[root@rocky8 ~]# 范例：查看倒数三行 12345[root@rocky8 ~]# head -3 passwd root:x:0:0:root:/root:/bin/bashroot:x:0:0:root:/root:/bin/bashroot:x:0:0:root:/root:/bin/bash[root@rocky8 ~]# 范例：查看首行到倒数第三行内容 1head -n -3 passwd 2.3.2 tailtail 和head 相反，查看文件或标准输入的倒数行格式: 1tail [OPTION]... [FILE]... 常用选项： 12345678-c # 指定获取后#字节-n # 指定获取后#行,如果#是负数,表示从第#行开始到文件结束-# 同上-f 跟踪显示文件fd新追加的内容,常用日志监控，相当于 --follow=descriptor,当文件删除再新建同名文件,将无法继续跟踪文件-F 跟踪文件名，相当于--follow=name --retry，当文件删除再新建同名文件,将可以继续跟踪文件tailf 类似 tail –f，当文件不增长时并不访问文件,节约资源,CentOS8已经无此工具 2.4按列抽取文本 cutcut 命令可以提取文本文件或STDIN数据的指定列格式: 1cut [OPTION]... [FILE]... 常用选项 12345678-d DELIMITER: 指明分隔符，默认tab-f FILEDS:#: 第#个字段,例如:3#,#[,#]：离散的多个字段，例如:1,3,6#-#：连续的多个字段, 例如:1-6混合使用：1-3,7-c 按字符切割--output-delimiter=STRING指定输出分隔符 2.5合并多个文件 pastepaste 合并多个文件同行号的列到一行格式 1paste [OPTION]... [FILE]... 常用选项： 12-d #分隔符：指定分隔符，默认用TAB-s #所有行合成一行显示 范例： 123456789[root@rocky8 ~]# echo &#123;a..d&#125;&gt;alpha.log[root@rocky8 ~]# cat alpha.log a b c d[root@rocky8 ~]# echo &#123;1..4&#125;&gt;seq.log[root@rocky8 ~]# cat seq.log 1 2 3 4[root@rocky8 ~]# paste alpha.log seq.log a b c d 1 2 3 4[root@rocky8 ~]# 1234567891011121314151617[root@rocky8 ~]# cat alpha.log abcd[root@rocky8 ~]# echo &#123;1..4&#125; |tr &quot; &quot; &quot;\\n&quot;&gt;seq.log[root@rocky8 ~]# cat seq.log 1234[root@rocky8 ~]# paste -d: alpha.log seq.log a:1b:2c:3d:4[root@rocky8 ~]# 2.6分析文本的工具文本数据统计：wc整理文本：sort比较文件：diff和patch 2.6.1 收集文本统计数据 wcwc 命令可用于统计文件的行总数、单词总数、字节总数和字符总数可以对文件或STDIN中的数据统计常用选项 12345-l 只计数行数-w 只计数单词总数-c 只计数字节总数-m 只计数字符总数-L 显示文件中最长行的长度 范例： 123456789101112131415[root@rocky8 ~]# wc /etc/passwd 30 58 1511 /etc/passwd 行数 单词数 字节数 [root@rocky8 ~]# wc -l /etc/passwd30 /etc/passwd[root@rocky8 ~]# wc -w /etc/passwd58 /etc/passwd[root@rocky8 ~]# wc -c /etc/passwd1511 /etc/passwd[root@rocky8 ~]# wc -m /etc/passwd1511 /etc/passwd[root@rocky8 ~]# wc -L /etc/passwd85 /etc/passwd[root@rocky8 ~]# 2.6.2 文本排序 sort把整理过的文本显示在STDOUT，不改变原始文件格式： 1sort [options] file(s) 常用选项: 12345678-r 执行反方向（由上至下）整理-R 随机排序-n 执行按数字大小整理-h 人类可读排序,如: 2K 1G-f 选项忽略（fold）字符串中的字符大小写-u 选项（独特，unique），合并重复项，即去重-t c 选项使用c做为字段界定符-k # 选项按照使用c字符分隔的 # 列来整理能够使用多次 范例: 123#统计日志访问量[root@centos8 data]#cut -d&quot; &quot; -f1 /var/log/nginx/access_log |sort -u|wc -l201 范例：统计分区利用率 1df| tr -s &#x27; &#x27; &#x27;%&#x27;|cut -d% -f5|sort -nr|head -n1 2.6.3 去重uniq命令从输入中删除前后相接的重复的行格式： 1uniq [OPTION]... [FILE]... 常见选项： 123-c: 显示每行重复出现的次数-d: 仅显示重复过的行-u: 仅显示不曾重复的行 uniq常和sort 命令一起配合使用：范例： 1sort userlist.txt | uniq -c 范例：统计日志访问量最多的请求 123456789[root@centos8 data]#cut -d&quot; &quot; -f1 access_log |sort |uniq -c|sort -nr |head -34870 172.20.116.2283429 172.20.116.2082834 172.20.0.222[root@centos8 data]#lastb -f btmp-34 | tr -s &#x27; &#x27; |cut -d &#x27; &#x27; -f3|sort |uniq -c|sort -nr | head -386294 58.218.92.3743148 58.218.92.2618036 112.85.42.201 范例：并发连接最多的远程主机IP 1234[root@centos8 ~]#ss -nt|tail -n+2 |tr -s &#x27; &#x27; : |cut -d: -f6|sort|uniq -c|sort -nr |head -n27 10.0.0.12 10.0.0.7 范例：取两个文件的相同和不同的行 1234567891011121314151617181920212223[root@centos8 data]#cat test1.txtab1c[root@centos8 data]#cat test2.txtbefc12#取文件的共同行[root@centos8 data]#cat test1.txt test2.txt | sort |uniq -d1bc#取文件的不同行[root@centos8 data]#cat test1.txt test2.txt | sort |uniq -u2aef 2.6.4 比较文件2.6.4.1 diffdiff命令比较两个文件之间的区别 1-u 选项来输出&quot;统一的(unified)&quot;diff格式文件，最适用于补丁文件 范例： 1234567891011121314151617[root@rocky8 data]# cat a.txt abcd[root@rocky8 data]# cat b.txt a2cd[root@rocky8 data]# diff a.txt b.txt 2c2&lt; b---&gt; 2[root@rocky8 data]# 2.6.4.2 patchpatch 复制在其它文件中进行的改变（要谨慎使用） 1-b 选项来自动备份改变了的文件 范例： 12diff -u foo.conf foo2.conf &gt; foo.patchpatch -b foo.conf foo.patch 2.6.4.3vimdiff相当于 vim -d 范例： 1234567891011121314[root@rocky8 data]# cat a.txta2cd[root@rocky8 data]# cat b.txt a2cd[root@rocky8 data]# vimdiff a.txt b.txt 2 files to edit[root@rocky8 data]# 2.6.4.3cmp范例：查看二进制文件的不同 12345678910111213141516171819[root@centos8 data]#ll /usr/bin/dir /usr/bin/ls-rwxr-xr-x. 1 root root 166448 May 12 2019 /usr/bin/dir-rwxr-xr-x. 1 root root 166448 May 12 2019 /usr/bin/ls[root@centos8 data]#ll /usr/bin/dir /usr/bin/ls -i201839444 -rwxr-xr-x. 1 root root 166448 May 12 2019 /usr/bin/dir201839465 -rwxr-xr-x. 1 root root 166448 May 12 2019 /usr/bin/ls[root@centos8 data]#diff /usr/bin/dir /usr/bin/lsBinary files /usr/bin/dir and /usr/bin/ls differ[root@centos8 ~]#cmp /bin/dir /bin/ls/bin/dir /bin/ls differ: byte 737, line 2#跳过前735个字节,观察后面30个字节[root@centos8 ~]#hexdump -s 735 -Cn 30 /bin/ls000002df 00 05 6d da 3f 1b 77 91 91 63 a7 de 55 63 a2 b9 |..m.?.w..c..Uc..|000002ef d9 d2 45 55 4c 00 00 00 00 03 00 00 00 7d |..EUL........&#125;|000002fd[root@centos8 ~]#hexdump -s 735 -Cn 30 /bin/dir000002df 00 f1 21 4e f2 19 7e ef 38 0d 9b 3e d7 54 08 39 |..!N..~.8..&gt;.T.9|000002ef e4 74 4d 69 25 00 00 00 00 03 00 00 00 7d |.tMi%........&#125;|000002fd 练习1、找出ifconfig “网卡名” 命令结果中本机的IPv4地址 12[root@rocky8 data]# ifconfig | tail -n +2 |head -n1|tr -s &quot; &quot;|cut -d &quot; &quot; -f3192.168.37.13 2、查出分区空间使用率的最大百分比值 12[root@rocky8 data]# df |tr -s &quot; &quot; | cut -d &quot; &quot; -f5|sort -nr|head -n126% 3、查出用户UID最大值的用户名、UID及shell类型 4、查出&#x2F;tmp的权限，以数字方式显示5、统计当前连接本机的每个远程主机IP的连接数，并按从大到小排序 3 正则表达式REGEXP： Regular Expressions，由一类特殊字符及文本字符所编写的模式，其中有些字符（元字符）不表示字符字面意义，而表示控制或通配的功能，类似于增强版的通配符功能，但与通配符不同，通配符功能是用来处理文件名，而正则表达式是处理文本内容中字符正则表达式被很多程序和开发语言所广泛支持：vim, less,grep,sed,awk, nginx,mysql 等正则表达式分两类： 基本正则表达式：BRE Basic Regular Expressions 扩展正则表达式：ERE Extended Regular Expressions 正则表达式引擎：采用不同算法，检查处理正则表达式的软件模块，如：PCRE（Perl Compatible RegularExpressions）正则表达式的元字符分类：字符匹配、匹配次数、位置锚定、分组帮助：man 7 regex 3.1基本正则表达式元字符3.1 .1字符匹配12345678910111213141516171819202122. 匹配任意单个字符(除了\\n)，可以是一个汉字或其它国家的文字[] 匹配指定范围内的任意单个字符，示例：[wang] [0-9] [a-z] [a-zA-Z][^] 匹配指定范围外的任意单个字符,示例：[^wang][:alnum:] 字母和数字[:alpha:] 代表任何英文大小写字符，亦即 A-Z, a-z[:lower:] 小写字母,示例:[[:lower:]],相当于[a-z][:upper:] 大写字母[:blank:] 空白字符（空格和制表符）[:space:] 包括空格、制表符(水平和垂直)、换行符、回车符等各种类型的空白,比[:blank:]包含的范围广[:cntrl:] 不可打印的控制字符（退格、删除、警铃...）[:digit:] 十进制数字[:xdigit:]十六进制数字[:graph:] 可打印的非空白字符[:print:] 可打印字符[:punct:] 标点符号-----------------\\s #匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [\\f\\r\\t\\v]。注意 Unicode正则表达式会匹配全角空格符\\S #匹配任何非空白字符。等价于 [^\\f\\r\\t\\v]\\w #匹配一个字母,数字,下划线,汉字,其它国家文字的字符，等价于[_[:alnum:]字]\\W #匹配一个非字母,数字,下划线,汉字,其它国家文字的字符，等价于[^_[:alnum:]字] 案例： 1234567891011[root@rocky8 data]# ls /etc/ | grep &#x27;rc[.0-6]&#x27;rc0.drc1.drc2.drc3.drc4.drc5.drc6.drc.drc.local[root@rocky8 data]# 3.1.2 匹配次数用在要指定次数的字符后面，用于指定前面的字符要出现的次数 12345678* #匹配前面的字符任意次，包括0次，贪婪模式：尽可能长的匹配.* #任意长度的任意字符\\? #匹配其前面的字符出现0次或1次,即:可有可无\\+ #匹配其前面的字符出现最少1次,即:肯定有且 &gt;=1 次\\&#123;n\\&#125; #匹配前面的字符n次\\&#123;m,n\\&#125; #匹配前面的字符至少m次，至多n次\\&#123;,n\\&#125; #匹配前面的字符至多n次,&lt;=n\\&#123;n,\\&#125; #匹配前面的字符至少n次 范例: 取IP地址 12[root@rocky8 data]# ifconfig ens160 | grep -o &quot;[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;\\.[0-9]\\&#123;1,3\\&#125;&quot; | head -n1192.168.37.130 3.1.3 位置锚定1234^ 行首$ 行尾\\&lt;或者\\b 语首\\&gt;,或者\\b 语尾 案例： 行首 123[root@rocky8 data]# grep &quot;^root&quot; passwd root:x:0:0:root:/root:/bin/bash[root@rocky8 data]# 案例： 行尾 123456[root@rocky8 data]# grep &quot;bash$&quot; passwd root:x:0:0:root:/root:/bin/bashyuankun:x:1000:1000:yuankun:/home/yuankun:/bin/bashtest:x:1002:1001::/home/test:/bin/bashtest1:x:1003:1003::/home/test1:/bin/bash[root@rocky8 data]# 案例：语首 123[root@rocky8 data]# echo &#x27;yuankunsir&#x27; | grep &quot;\\&lt;yuan&quot;yuankunsir[root@rocky8 data]# 案例： 语尾 123[root@rocky8 data]# echo &#x27;yuankunsir&#x27; | grep &quot;sir\\&gt;&quot;yuankunsir[root@rocky8 data]# 3.1.4 分组其他123456() 分组后向引用：\\1, \\2, ... 注意: \\0 表示正则表达式匹配的所有字符| 或者a|b #a或bC|cat #C或cat(C|c)at #Cat或cat 案例：分组 123# abc至少出现三次[root@rocky8 data]# echo &#x27;abcabcabc&#x27; | grep &quot;\\(abc\\)\\&#123;3,\\&#125;&quot;abcabcabc 案例：或者 12[root@rocky8 data]# echo &#x27;abc&#x27; |grep &#x27;a\\|b&#x27;abc 4 文本处理三剑客grep 命令主要对文本的（正则表达式）行基于模式进行过滤sed：stream editor，文本编辑工具awk：Linux上的实现gawk，文本报告生成器 4.1 文本处理三剑客之grepgrep: Global search REgular expression and Print out the line作用：文本搜索工具，根据用户指定的“模式”对目标文本逐行进行匹配检查；打印匹配到的行模式：由正则表达式字符及文本字符所编写的过滤条件帮助: 1https://man7.org/linux/man-pages/man1/grep.1.html 格式： 1grep [OPTIONS] PATTERN [FILE...] 常见选项： 12345678910111213141516171819--color=auto 对匹配到的文本着色显示-m # 匹配#次后停止-v 显示不被pattern匹配到的行,即取反-i 忽略字符大小写-n 显示匹配的行号-c 统计匹配的行数-o 仅显示匹配到的字符串-q 静默模式，不输出任何信息-A # after, 后#行-B # before, 前#行-C # context, 前后各#行-e 实现多个选项间的逻辑or关系,如：grep –e ‘cat &#x27; -e ‘dog&#x27; file-w 匹配整个单词-E 使用ERE，相当于egrep-F 不支持正则表达式，相当于fgrep-P 支持Perl格式的正则表达式-f file 根据模式文件处理-r 递归目录，但不处理软链接-R 递归目录，但处理软链接 案例：-m 123[root@rocky8 data]# grep -m1 root passwd root:x:0:0:root:/root:/bin/bash[root@rocky8 data]# 案例：-v 1grep -v root passwd 案例：-i 1234[root@rocky8 data]# grep -i root passwd root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin[root@rocky8 data]# 案例：-n 1234[root@rocky8 data]# grep -n root passwd 1:root:x:0:0:root:/root:/bin/bash10:operator:x:11:0:operator:/root:/sbin/nologin[root@rocky8 data]# 案例：-o 123456[root@rocky8 data]# grep -o bash passwd bashbashbashbash[root@rocky8 data]# 案例：-q 1234[root@rocky8 data]# grep -q root passwd [root@rocky8 data]# echo $?0[root@rocky8 data]# 案例：-A 123456789101112131415161718[root@rocky8 data]# cat a.txt abcdefghjkl[root@rocky8 data]# grep -A3 a a.txt abcd[root@rocky8 data]# 案例: -B 123456789101112131415161718[root@rocky8 data]# cat a.txt abcdefghjkl[root@rocky8 data]# grep -B3 f a.txt cdef[root@rocky8 data]# 案例： -C 12345678910111213141516171819[root@rocky8 data]# cat a.txt abcdefghjkl[root@rocky8 data]# grep -C2 f a.txt defgh[root@rocky8 data]# 案例： -e 12345[root@rocky8 data]# grep -e root -e yuankun passwd root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologinyuankun:x:1000:1000:yuankun:/home/yuankun:/bin/bash[root@rocky8 data]# 案例： -w 1234[root@rocky8 data]# grep -w root passwd root:x:0:0:root:/root:/bin/bashoperator:x:11:0:operator:/root:/sbin/nologin[root@rocky8 data]# 案例： -f 12# 取两个文件的相同行grep -f a.txt b.txt 4.2 文本处理工具之sed4.2.1 sed基本用法格式: 1sed [option]... &#x27;script;script;...&#x27; [inputfile...] 常用选项 1234567891011-n 不输出模式空间内容到屏幕，即不自动打印-e 多点编辑-f FILE 从指定文件中读取编辑脚本-r, -E 使用扩展正则表达式-i.bak 备份文件并原处编辑-s 将多个文件视为独立文件，而不是单个连续的长文件流#说明:-ir 不支持-i -r 支持-ri 支持-ni 危险选项,会清空文件 script格式： 1&#x27;地址命令&#x27; 地址格式： 123456789101112131. 不给地址：对全文进行处理2. 单地址：#：指定的行，$：最后一行/pattern/：被此处模式所能够匹配到的每一行3. 地址范围：#,# #从#行到第#行，3，6 从第3行到第6行#,+# #从#行到+#行，3,+4 表示从3行到第7行/pat1/,/pat2/#,/pat//pat/,#4. 步进：~1~2 奇数行2~2 偶数行 命令： 1234567891011p 打印当前模式空间内容，追加到默认输出之后Ip 忽略大小写输出d 删除模式空间匹配的行，并立即启用下一轮循环a [\\]text 在指定行后面追加文本，支持使用\\n实现多行追加i [\\]text 在行前面插入文本c [\\]text 替换行为单行或多行文本w file 保存模式匹配的行至指定文件r file 读取指定文件的文本至模式空间中匹配到的行后= 为模式空间中的行打印行号! 模式空间中匹配行取反处理q 结束或退出sed 查找和替换： 123456s/pattern/string/修饰符 查找替换,支持使用其它分隔符，可以是其它形式：s@@@，s###替换修饰符：g 行内全局替换p 显示替换成功的行w /PATH/FILE 将替换成功的行保存至文件中I,i 忽略大小写 范例： 12345678# sed默认会将输入信息输出到屏幕[root@rocky8 data]# sed &quot;&quot;hellohelloyuanyuandatadata 案例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# 打印第三行，默认会输出所有，-n选项不输出模式空间内容到屏幕，即不自动打印[root@rocky8 data]# seq 10 | sed &#x27;3p&#x27;123345678910# p 打印当前模式空间内容，追加到默认输出之后[root@rocky8 data]# seq 10 | sed -n &#x27;3p&#x27;3[root@rocky8 data]# # 删除第三行[root@rocky8 data]# seq 10 | sed &#x27;3d&#x27;1245678910[root@rocky8 data]# # 输出第三行至最后一行[root@rocky8 data]# seq 10 | sed -n &#x27;3,$p&#x27;345678910[root@rocky8 data]# # 输出奇数行[root@rocky8 etc]# seq 10 | sed -n &#x27;1~2p&#x27;13579# 输出偶数行[root@rocky8 etc]# seq 10 | sed -n &#x27;2~2p&#x27;246810[root@rocky8 etc]# # 追加，在偶数行追加hello[root@rocky8 etc]# seq 10 | sed &#x27;2~2ahello&#x27;12hello34hello56hello78hello910hello 案例：行前和行首添加文本 1234567891011121314[root@rocky8 data]# cat data.txt hello my name is lihua[root@rocky8 data]# sed -i &#x27;/hello/a12138&#x27; data.txt [root@rocky8 data]# cat data.txt hello my name is lihua12138[root@rocky8 data]# sed -i &#x27;/hello/i12138&#x27; data.txt [root@rocky8 data]# cat data.txt 12138hello my name is lihua12138 案例：替换行为单行或多行文本 123456789101112[root@rocky8 data]# cat data.txt 852 a852 b852 c[root@rocky8 data]# sed -i &#x27;/852/c hello&#x27; data.txt [root@rocky8 data]# cat data.txt hellohellohello[root@rocky8 data]# 案例：保存模式匹配的行至指定文件 12345678910[root@rocky8 data]# cat a.txt [root@rocky8 data]# seq 10 | sed -n &#x27;1~2w a.txt&#x27;[root@rocky8 data]# cat a.txt 13579[root@rocky8 data]# 案例：读取指定文件的文本至模式空间中匹配到的行后 123456789101112131415161718192021222324252627[root@rocky8 data]# seq 10 | sed &#x27;1~2r /etc/issue&#x27;1\\SKernel \\r on an \\m23\\SKernel \\r on an \\m45\\SKernel \\r on an \\m67\\SKernel \\r on an \\m89\\SKernel \\r on an \\m10[root@rocky8 data]# 案例：! 模式空间中匹配行取反处理 12345678# 1~2奇数行，加上！取反就是偶数行[root@rocky8 data]# seq 10 | sed -n &#x27;1~2!p&#x27;246810[root@rocky8 data]# 4.3 文本处理工具之awk","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"权限管理及文本编辑工具","slug":"权限管理及文本编辑工具","date":"2022-07-25T12:34:34.000Z","updated":"2022-12-16T14:56:41.688Z","comments":true,"path":"2022/07/25/权限管理及文本编辑工具/","link":"","permalink":"http://snippet.itshare.work/2022/07/25/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E5%8F%8A%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%B7%A5%E5%85%B7/","excerpt":"新建文件和目录的默认权限","text":"1.新建文件和目录的默认权限umask 的值可以用来保留在创建文件权限实现方式： 新建文件的默认权限: 666-umask，如果所得结果某位存在执行（奇数）权限，则将其权限+1,偶数不变 新建目录的默认权限: 777-umask 非特权用户umask默认是002 root的umask默认是022 查看umask 12345umask#模式方式显示umask –S#输出可被调用umask –p 修改umask 1umask #bash 范例： 123bashumask 002umask u=rw,g=r,o= 持久保存umask: 全局设置：&#x2F;etc&#x2F;bashrc 用户设置：~&#x2F;.bashrc 创建临时权限为000的文件三种方法： 方法一 1touch a.txt;chmod 000 a.txt 方法二 1umask 777;touch a.txt;umask 022 方法三 1(umask 777;touch a.txt)","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"Linux运维面试葵花宝典","slug":"TheInterviewQuestions","date":"2022-07-23T12:57:17.000Z","updated":"2022-12-16T14:59:19.737Z","comments":true,"path":"2022/07/23/TheInterviewQuestions/","link":"","permalink":"http://snippet.itshare.work/2022/07/23/TheInterviewQuestions/","excerpt":"收集运维面试题目，减少试错成本","text":"df和du的区别？ 12df 查看是文件系统的空间使用，包括元数据和数据，删除文件后，如果此文件正在使用，不会立即释放空间du 查看是文件数据空间使用，不包括元数据，删除文件后空间立即释放 RAID0，1，5，6，10,01级别区别 12341 磁盘利用率2 最少几盘硬盘实现3 容错性，防止几块硬盘损坏4 性能好坏？ 如何判断linux系统网线是联通的还是断了 1234# link ok 说明网线是联通的root@ubuntu200404:~# mii-tool ens33ens33: negotiated 1000baseT-FD flow-control, link okroot@ubuntu200404:~# 三次握手过程以及为什么是三次握手 探测ip冲突arping命令 12345678910[root@centos7 /]# arping 192.168.179.129ARPING 192.168.179.129 from 192.168.179.130 ens33Unicast reply from 192.168.179.129 [00:0C:29:7C:80:CD] 0.689msUnicast reply from 192.168.179.129 [00:0C:29:7C:80:CD] 0.797msUnicast reply from 192.168.179.129 [00:0C:29:7C:80:CD] 0.746msUnicast reply from 192.168.179.129 [00:0C:29:7C:80:CD] 0.874msUnicast reply from 192.168.179.129 [00:0C:29:7C:80:CD] 0.712msUnicast reply from 192.168.179.129 [00:0C:29:7C:80:CD] 0.845msUnicast reply from 192.168.179.129 [00:0C:29:7C:80:CD] 0.706msUnicast reply from 192.168.179.129 [00:0C:29:7C:80:CD] 0.741ms 简述 TCP&#x2F;IP三次握手和四次挥手的工作原理?Centos7,8 Linux操作系统如何临时和永久配置IP地址?请写出操作步骤用一行命令找出ifconfig命令结果中的IP地址? 1ifconfig | grep inet |grep -v inet6 | tr -s &quot; &quot; | cut -d&quot; &quot; -f3 使用tcpdump 监听主机为192.168.1.1,tcp端口为80的数据,同时将输出结果保存成文件?写一个She11脚本,实现判断192.168.1.0&#x2F;24网络里,当前在线的IP有哪些，能ping 通则认为在线 123456789101112# 变量NET=192.168.1.0# 清空文件内容cat /dev/null &gt; hosts.txt# 循环for i in &#123;1..254&#125;;do# ping 1秒钟不回应则认为不通 if ping -c1 -W1 $NET.$i;then# 屏幕打印，并将结果重定向到hosts.txt中 echo $NET.$i is up | tee -a hosts.txt fidone 写一个扫描某个主机端口的状态的脚本 性能监控解释uptime top w命令第一行 uptime 1234# uptime命令[root@rocky ~]# uptime 21:14:45 up 1:31, 2 users, load average: 0.02, 0.01, 0.00 w命令 1234567# w命令[root@rocky ~]# w 21:15:57 up 1:32, 2 users, load average: 0.00, 0.00, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot tty1 - 06Aug22 1:19m 0.10s 0.10s -bashroot pts/0 192.168.179.1 19:45 1.00s 0.06s 0.00s w[root@rocky ~]# top命令 21:15:57 up 1:32 2 users load average: 0.00, 0.00, 0.00 当前系统时间 系统运行了多长时间 登录的用户数 系统1分钟、5分钟、15分钟的平均负载，一般不会超过1，超过5时建议警报 top命令详解 面试题4.1 解释top命令每一行的意义4.2 如果查看一个进程的是否是多线程4.3 如果实现秒级的计划任务4.4 说明cron计划任务的格式 iptables有几个表以及每个表有几个链？五表五链 MySQL相关面试题 面试题: VARCHAR(50) 能存放几个 UTF8 编码的汉字？ 12345存放的汉字个数与版本相关。mysql 4.0以下版本，varchar(50) 指的是 50 字节，如果存放 UTF8 格式编码的汉字时（每个汉字3字节），只能存放16 个。mysql 5.0以上版本，varchar(50) 指的是 50 字符，无论存放的是数字、字母还是 UTF8 编码的汉字，都可以存放 50 个。 MyISAM与MyISAM 的区别 面试题: InnoDB中一颗的B+树可以存放多少行数据？ 1234567假设定义一颗B+树高度为2，即一个根节点和若干叶子节点。那么这棵B+树的存放总行记录数=根节点指针数*单个叶子记录的行数。这里先计算叶子节点，B+树中的单个叶子节点的大小为16K，假设每一条目为1K，那么记录数即为16(16k/1K=16)，然后计算非叶子节点能够存放多少个指针，假设主键ID为bigint类型，那么长度为8字节，而指针大小在InnoDB中是设置为6个字节，这样加起来一共是14个字节。那么通过页大小/(主键ID大小+指针大小），即16384/14=1170个指针，所以一颗高度为2的B+树能存放16*1170=18720条这样的记录。根据这个原理就可以算出一颗高度为3的B+树可以存放16*1170*1170=21902400条记录。所以在InnoDB中B+树高度一般为2-3层，它就能满足千万级的数据存储 事务特性 ACID特性：A：atomicity 原子性；整个事务中的所有操作要么全部成功执行，要么全部失败后回滚C：consistency一致性；数据库总是从一个一致性状态转换为另一个一致性状态,类似于能量守恒定律(N50周启皓语录)I：Isolation隔离性；一个事务所做出的操作在提交之前，是不能为其它事务所见；隔离有多种隔离级别，实现并发D：durability持久性；一旦事务提交，其所做的修改会永久保存于数据库中 事务隔离级别 MySQL 主从数据不一致造成主从不一致的原因** 主库binlog格式为Statement，同步到从库执行后可能造成主从不一致。 主库执行更改前有执行set sql_log_bin&#x3D;0，会使主库不记录binlog，从库也无法变更这部分数据。 从节点未设置只读，误操作写入数据 主库或从库意外宕机，宕机可能会造成binlog或者relaylog文件出现损坏，导致主从不一致 主从实例版本不一致，特别是高版本是主，低版本为从的情况下，主数据库上面支持的功能，从数 据库上面可能不支持该功能 主从sql_mode 不一致 MySQL自身bug导致 主从不一致修复方法 将从库重新实现虽然这也是一种解决方法，但是这个方案恢复时间比较慢，而且有时候从库也是承担一部分的查询操作的，不能贸然重建。 使用percona-toolkit工具辅助PT工具包中包含pt-table-checksum和pt-table-sync两个工具，主要用于检测主从是否一致以及修复数据不一致情况。这种方案优点是修复速度快，不需要停止主从辅助，缺点是需要知识积累，需要时间去学习，去测试，特别是在生产环境，还是要小心使用关于使用方法，可以参考下面链接：https://www.cnblogs.com/feiren/p/7777218.html 手动重建不一致的表在从库发现某几张表与主库数据不一致，而这几张表数据量也比较大，手工比对数据不现实，并且重做整个库也比较慢，这个时候可以只重做这几张表来修复主从不一致这种方案缺点是在执行导入期间需要暂时停止从库复制，不过也是可以接受的","categories":[],"tags":[],"keywords":[]},{"title":"Linux文件管理","slug":"文件管理","date":"2022-07-23T08:37:00.000Z","updated":"2022-12-16T14:57:22.576Z","comments":true,"path":"2022/07/23/文件管理/","link":"","permalink":"http://snippet.itshare.work/2022/07/23/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/","excerpt":"Linux中的所有数据都被保存在文件中，所有的文件被分配到不同的目录。目录是一种类似于树的结构，称为文件系统;当你使用Linux时，大部分时间都会和文件打交道，通过本节可以了解基本的文件操作，如创建文件、删除文件、复制文件、重命名文件以及为文件创建链接等。","text":"文件管理 # 1.文件系统目录结构 1.1常见的文件系统目录功能 1234567891011121314151617181920212223242526272829303132333435363738/boot：引导文件存放目录，内核文件(vmlinuz)、引导加载器(bootloader, grub)都存放于此目录/bin：所有用户使用的基本命令；不能关联至独立分区，OS启动即会用到的程序/sbin：管理类的基本命令；不能关联至独立分区，OS启动即会用到的程序/lib：启动时程序依赖的基本共享库文件以及内核模块文件(/lib/modules)/lib64：专用于x86_64系统上的辅助共享库文件存放位置/etc：配置文件目录/home/USERNAME：普通用户家目录/root：管理员的家目录/media：便携式移动设备挂载点/mnt：临时文件系统挂载点/dev：设备文件及特殊文件存储位置b: block device，随机访问c: character device，线性访问/opt：第三方应用程序的安装位置/srv：系统上运行的服务用到的数据/tmp：临时文件存储位置/usr: universal shared, read-only databin: 保证系统拥有完整功能而提供的应用程序sbin:lib：32位使用lib64：只存在64位系统include: C程序的头文件(header files)share：结构化独立的数据，例如doc, man等local：第三方应用程序的安装位置bin, sbin, lib, lib64, etc, share/var: variable data filescache: 应用程序缓存数据目录lib: 应用程序状态信息数据local：专用于为/usr/local下的应用程序存储可变数据lock: 锁文件log: 日志目录及文件opt: 专用于为/opt下的应用程序存储可变数据run: 运行中的进程相关数据,通常用于存储进程pid文件spool: 应用程序数据池tmp: 保存系统两次重启之间产生的临时数据/proc: 用于输出内核与进程信息相关的虚拟文件系统/sys：用于输出当前系统上硬件设备相关信息虚拟文件系统/selinux: security enhanced Linux，selinux相关的安全策略等信息的存储位置 1.2Linux下的文件类型 -普通文件 d 目录文件directory I 符号链接文件link b 块设备block c 字符设备character p 管道文件pipe s 套接字文件socket 注意:面试题目容易出现 2.文件操作命令2.1相对路径和绝对路径 绝对路径以正斜杠&#x2F; 即根目录开始完整的文件的位置路径可用于任何想指定一个文件名的时候 相对路径名不以斜线开始一般情况下，是指相对于当前工作目录的路径，特殊场景下，是相对于某目录的位置可以作为一个简短的形式指定一个文件名 基名：basename，只取文件名而不要路径 目录名：dirname，只取路径，不要文件名范例: 2.2更改目录命令 cd ： change directory 改变目录选项：-P 切换至物理路径，而非软链接目录可以使用绝对或相对路径切换至父目录： cd ..切换至当前用户主目录： cd切换至以前的工作目录： cd - 2.3列出目录内容ls 命令可以列出当前目录的内容或指定目录用法： 1ls [options] [files_or_dirs] 常见选项： 123456789101112-a 包含隐藏文件-l 显示额外的信息-R 目录递归-ld 目录和符号链接信息-1 文件分行显示-S 按从大到小排序-t 按mtime排序-u 配合-t选项，显示并按atime从新到旧排序-U 按目录存放顺序显示-X 按文件后缀排序-F 对不同类型文件显示时附加不同的符号：*/=&gt;@|-C 文件多时，以多列的方式显示文件，默认是一列（标准输出） 说明： 12ls 查看不同后缀文件时的颜色由 /etc/DIR_COLORS 和@LS_COLORS变量定义ls -l 看到文件的大小,不一定是实际文件真正占用空间的大小 2.4查看文件状态用法： 1stat filename 每个文件有三个时间戳： access time 访问时间，atime，读取文件内容 modify time 修改时间，mtime，改变文件内容（数据） change time 改变时间，ctime，元数据发生改变 2.5查看文件内容用法： 1file [options] filename 常用选项： -b 列出文件辨识结果时，不显示文件名称 -f filelist 列出文件filelist中文件名的文件类型 -F 使用指定分隔符号替换输出文件名后默认的”:”分隔符 -L 查看对应软链接对应文件的文件类型 –help 显示命令在线帮助 2.6文件通配符模式常见的通配符如下 123456789101112* 匹配零个或多个字符，但不匹配 &quot;.&quot; 开头的文件，即隐藏文件? 匹配任何单个字符,一个汉字也算一个字符~ 当前用户家目录~mage 用户mage家目录[0-9] 匹配数字范围[a-z] 一个字母[A-Z] 一个字母[wang] 匹配列表中的任何的一个字符[^wang] 匹配列表中的所有字符以外的字符[^a-z] 匹配列表中的所有字符以外的字符. 和 ~+ 当前工作目录~- 前一个工作目录 2.7批量修改文件名利用 rename 可以批量修改文件名格式： 1rename [options] &lt;expression&gt; &lt;replacement&gt; &lt;file&gt;... 范例： 1234#为所有的f开头包含conf的文件加上.bak后缀：rename &#x27;conf&#x27; &#x27;conf.bak&#x27; f*#去掉所有的bak后缀：rename &#x27;.bak&#x27; &#x27;&#x27; *.bak 3.硬链接和软链接3.1硬链接硬链接本质上就给一个文件起一个新的名称，实质是同一个文件硬链接特性 创建硬链接会在对应的目录中增加额外的记录项以引用文件 对应于同一文件系统上一个物理文件 每个目录引用相同的inode号 创建时链接数递增 删除文件时：rm命令递减计数的链接，文件要存在，至少有一个链接数，当链接数为零时，该文件被删除 不能跨越驱动器或分区 不支持对目录创建硬链接 格式： 1ln filename [linkname] 3.2软链接一个符号链接指向另一个文件,就像 windows 中快捷方式，软链接文件和原文件本质上不是同一个文件软链接特点 一个符号链接的内容是它引用文件的名称 可以对目录创建软链接 可以跨分区的文件实现 指向的是另一个文件的路径；其大小为指向的路径字符串的长度；不增加或减少目标文件inode的引用计数 在创建软链接时, 如果源文件使用相对路径，是相对于软链接文件的路径，而非相对于当前工作目录,但是软链接的路径如果是相对路径,则是相对于当前工作目录格式： 1ln -s filename [linkname] 范例： 查看软链接 123rm -rf /data/dirlink #只删除软链接本身,不会删除源目录内容rm -rf /data/dirlink/ #删除源目录的文件,但不会删除链接文件,此方法非常危险#注意: 删除此软链接务必不要加-r选项 4.硬链接和软链接区别 本质： 硬链接：本质是同一个文件 软链接：本质不是同一个文件 跨设备 硬链接：不支持 软链接：支持 inode 硬链接：相同 软链接：不同 链接数 硬链接：创建新的硬链接,链接数会增加,删除硬链接,链接数减少 软链接：创建或删除,链接数不会变化 文件夹 硬链接：不支持 软链接：支持 相对路径 硬链接：原始文件相对路径是相对于当前工作目录 软链接：原始文件的相对路径是相对于链接文件的相对路径 删除源文件 硬链接：只是链接数减一,但链接文件的访问不受影响 软链接：链接文件将无法访问 文件类型 硬链接：和源文件相同 软链接：链接文件,和源文件无关 文件大小 硬链接: 和源文件相同 软链接: 源文件的路径的长度 5.生产案例 案例1：提示空间满 No space left on device，但 df 可以看到空间很多，为什么？123456789解决方法：节点编号用完了，增加节点编号增加不了，说明你的磁盘上的文件都是小文件；1、删除不用的文件和文件夹释放inode2、迁移数据到新磁盘然后格式化重新指定inode知识点：1.Linux下一个文件夹或者一个文件就会占用一个inode资源2.inode资源数量是在格式化磁盘的时候就指定的（可以不指定，但也会有一个值），要更改这个数量必须格式化磁盘3.如果某个磁盘的inode资源用尽，即便磁盘有空间，也不能进行任何文件或者文件夹的新增4.删除一个文件夹或者文件就能释放一个inode资源 案例2：提示空间快满，使用 rm 删除了很大的无用文件后，df仍然看到空间不足，为什么？如何解决？123有其他程序在使用该文件，可以清空该文件内容。使用&gt;清空文件内容&gt; filename# &gt; test.log 6.重定向和管道6.1 标准输入和输出程序：指令+数据读入数据：Input输出数据：Output打开的文件都有一个fd: file descriptor (文件描述符)Linux给程序提供三种 I&#x2F;O 设备 标准输入（STDIN） －0 默认接受来自终端窗口的输入 标准输出（STDOUT）－1 默认输出到终端窗口 标准错误（STDERR） －2 默认输出到终端窗口 6.2标准的输出和错误重定向格式： 1命令 操作符号 文件名 支持的操作符号包括： 12341&gt; 或 &gt; 把STDOUT重定向到文件2&gt; 把STDERR重定向到文件&amp;&gt; 把标准输出和错误都重定向&gt;&amp; 和上面功能一样，建议使用上面方式 以上的文件如果已经存在，文件内容则会覆盖 12# &gt;&gt; 可以在原有的基础内容上追加内容&gt;&gt; 追加标准输出重定向至文件 12&gt;&gt; 追加标准错误重定向至文件 6.3将标准输出和错误输出指定向不同的文件格式： 1COMMAND &gt; /path/to/file.log 2&gt; /path/to/error.log 6.4合并标准输出和错误输出为同一个数据流进行重定向1234&amp;&gt; 覆盖重定向&amp;&gt;&gt; 追加重定向COMMAND &gt; /path/to/file.out 2&gt;&amp;1 （顺序很重要）COMMAND &gt;&gt; /path/to/file.out 2&gt;&amp;1 错误案例 6.5标准输入重定向实现标准输入重定向的符号 12COMMAND 0&lt; FILECOMMAND &lt; FILE 面试题： 123# 求1+2+···+10的和seq -s+ 10 &gt; seq.logbc &lt; seq.log 123扩展：求1*2*···*10的值：seq -s* 10 &gt;seq.logbc &lt; seq.log 6.5.1tr命令tr 转换和删除字符 1tr [option] ··· SET1 [SET2] 选项： 123456789101112131415161718192021222324-d --delete：删除所有属于第一字符集的字符-s --squeeze-repeats：把连续重复的字符以单独一个字符表示,即去重-t --truncate-set1：将第一个字符集对应字符转化为第二字符集对应的字符-c –C --complement：取字符集的补集\\NNN character with octal value NNN (1 to 3 octal digits)\\\\ backslash\\a audible BEL\\b backspace\\f form feed\\n new line\\r return\\t horizontal tab\\v vertical tab[:alnum:]：字母和数字[:alpha:]：字母[:digit:]：数字[:lower:]：小写字母[:upper:]：大写字母[:space:]：空白字符[:print:]：可打印字符[:punct:]：标点符号[:graph:]：图形字符[:cntrl:]：控制（非打印）字符[:xdigit:]：十六进制字符 范例： 删除字符,删除’abcd’中的’a’ 1echo abcd | tr -d &#x27;a&#x27; 将’aaabbbccc‘中字符去重 1echo aaabbbccc |tr -s &#x27;abc&#x27; 输入df将空格用”+”替换 1df | tr -s &#x27; &#x27; + 6.5.2多行重定向使用 “&lt;&lt;终止词” 命令从键盘把多行重导向给STDIN，直到终止词位置之前的所有文本都发送给STDIN，有时被称为就地文本（here documents）其中终止词可以是任何一个或多个符号，比如：!，@，$，EOF（End Of File），magedu等，其中EOF比较常用 范例： 6.5.3高级重定向6.5.3.1 cmd1 &lt; &lt;(cmd2)名称为 Process substitution ,是由两个部分组成&lt;(cmd2) 表示把cmd2的输出写入一个临时文件, 注意：&lt;和（之间无空格cmd1 &lt; 这是一个标准的stdin重定向把两个合起来，就是把cmd2的输出stdout传递给cmd1作为输入stdin, 中间通过临时文件做传递 6.5.3.2cmd1&lt;&lt;&lt;’string’含义是 here-string ，表示传给给cmd的stdin的内容从这里开始是一个字符串。范例： 1bc &lt;&lt;&lt;&#x27;2+4&#x27; 6.6 tee命令tee命令用于读取标准输入的数据，并将其内容输出成文件。 tee指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。 选项： 1-a 追加 7.用户和组相关概念7.1 用户Linux中每个用户是通过 User Id （UID）来唯一标识的 管理员：root, 0 普通用户：1-60000 自动分配 系统用户：1-499 （CentOS 6以前）, 1-999 （CentOS 7以后）对守护进程获取资源进行权限分配 登录用户：500+ （CentOS6以前）, 1000+（CentOS7以后）给用户进行交互式登录使用 7.2 用户组Linux中可以将一个或多个用户加入用户组中，用户组是通过Group ID（GID） 来唯一标识的。 管理员组：root, 0 普通组： 系统组：1-499（CentOS 6以前）, 1-999（CentOS7以后）, 对守护进程获取资源进行权限分配 普通组：500+（CentOS 6以前）, 1000+（CentOS7以后）, 给用户使用 7.3 用户和组的关系 用户的主要组(primary group)：用户必须属于一个且只有一个主组，默认创建用户时会自动创建和用户名同名的组，做为用户的主要组，由于此组中只有一个用户，又称为私有组 用户的附加组(supplementary group)： 一个用户可以属于零个或多个辅助组，附属组 范例： 12[root@rocky8 home]# id yuankunuid=1000(yuankun) gid=1000(yuankun) groups=1000(yuankun) 7.4用户和组的配置文件7.4.1用户和组的主要配置文件 &#x2F;etc&#x2F;passwd：用户及其属性信息(名称、UID、主组ID等） &#x2F;etc&#x2F;shadow：用户密码及其相关属性 &#x2F;etc&#x2F;group：组及其属性信息 &#x2F;etc&#x2F;gshadow：组密码及其相关属性 7.4.2 passwd文件格式 login name：登录用名（yuankun） passwd：密码 (x) UID：用户身份编号 (1000) GID：登录默认所在组编号 (1000) GECOS：用户全名或注释 home directory：用户主目录 (&#x2F;home&#x2F;wang) shell：用户默认使用shell (&#x2F;bin&#x2F;bash) 7.4.3shadow文件格式 登录用名 用户密码:一般用sha512加密 从1970年1月1日起到密码最近一次被更改的时间 密码再过几天可以被变更（0表示随时可被变更） 密码再过几天必须被变更（99999表示永不过期） 密码过期前几天系统提醒用户（默认为一周） 密码过期几天后帐号会被锁定 从1970年1月1日算起，多少天后帐号失效 7.4.4group文件格式 群组名称：就是群组名称 群组密码：通常不需要设定，密码是被记录在 &#x2F;etc&#x2F;gshadow GID：就是群组的 ID 以当前组为附加组的用户列表(分隔符为逗号) 7.4.5gshadow文件格式 群组名称：就是群的名称 群组密码： 组管理员列表：组管理员的列表，更改组密码和成员 以当前组为附加组的用户列表：多个用户间用逗号分隔 7.5 用户和组管理命令 用户管理命令 useradd(添加用户) usermod(修改用户) userdel(删除用户) 组账号维护命令 groupadd groupmod groupdel 面试题：添加新用户后家目录下的文件来源什么地方？ 来源于&#x2F;etc&#x2F;skel,进入&#x2F;etc&#x2F;skel下查看文件和进入test用户的家目录下查看文件是一致的 7.5.1用户创建useradd命令可以创建新的linux用户 格式： 1useradd [options] login 常见的选项： 123456789101112-u UID-o 配合-u 选项，不检查UID的唯一性-g GID 指明用户所属基本组，可为组名，也可以GID-c &quot;COMMENT“ 用户的注释信息-d HOME_DIR 以指定的路径(不存在)为家目录-s SHELL 指明用户的默认shell程序，可用列表在/etc/shells文件中-G GROUP1[,GROUP2,...] 为用户指明附加组，组须事先存在-N 不创建私用组做主组，使用users组做主组-r 创建系统用户 CentOS 6之前: ID&lt;500，CentOS7 以后: ID&lt;1000-m 创建家目录，用于系统用户-M 不创建家目录，用于非系统用户-p 指定加密的密码 范例: 12[root@rocky8 home]# groupadd apache[root@rocky8 home]# useradd -r -u 48 -g apache -s /sbin/nologin -d /var/www -c &quot;Apache&quot; apache useradd命令默认值设置由&#x2F;etc&#x2F;default&#x2F;useradd定义 123456789[root@centos8 ~]#cat /etc/default/useradd# useradd defaults fileGROUP=100HOME=/homeINACTIVE=-1 #对应/etc/shadow文件第7列，即用户密码过期后的帐号锁定的宽限期,-1表示不锁定EXPIRE= #对应/etc/shadow文件第8列，即用户帐号的有效期SHELL=/bin/bashSKEL=/etc/skel #用于生成新建用户家目录的模版文件CREATE_MAIL_SPOOL=yes 7.5.2用户属性修改usermod命令可以修改用户属性 格式： 1usermod [options] login 常见选项： 123456789101112-u UID: 新UID-g GID: 新主组-G GROUP1[,GROUP2,...[,GROUPN]]]：新附加组，原来的附加组将会被覆盖；若保留原有，则要同时使用-a选项-s SHELL：新的默认SHELL-c &#x27;COMMENT&#x27;：新的注释信息-d HOME: 新家目录不会自动创建；若要创建新家目录并移动原家数据，同时使用-m选项-l login_name: 新的名字-L: lock指定用户,在/etc/shadow 密码栏的增加 !-U: unlock指定用户,将 /etc/shadow 密码栏的 ! 拿掉-e YYYY-MM-DD: 指明用户账号过期日期-f INACTIVE: 设定非活动期限，即宽限期 范例：创建test用户，使用id username查看用户的uid,然后修改其uid 123456[root@rocky8 home]# useradd test #添加tes用户[root@rocky8 home]# id test #查看用户信息uid=1001(test) gid=1001(test) groups=1001(test)[root@rocky8 home]# usermod -u 1002 test # 将uid修改为1002[root@rocky8 home]# id test #查看用户信息修改成功uid=1002(test) gid=1001(test) groups=1001(test) 7.5.4删除用户userdel可以删除用户 格式： 1userdel [options] login 常见的选项： 12-f, --force 强制-r, --remove 删除用户家目录和邮箱 范例： 12userdel -f test #强制删除userdel -rf test # 删除家目录和邮箱 7.5.5查看用户相关IDid命令可以查看用户的UID、GID等信息 1id [options] [username] 常见选项： 1234-u: 显示UID-g: 显示GID-G: 显示用户所属的组的ID-n: 显示名称，需配合ugG使用 范例： 123456789[root@rocky8 home]# id testuid=1002(test) gid=1001(test) groups=1001(test)[root@rocky8 home]# id -u test1002[root@rocky8 home]# id -g test1001[root@rocky8 home]# id -G test1001[root@rocky8 home]# 7.5.6查看linux所有用户 查看&#x2F;etc&#x2F;passwd getent passwd 7.5.7切换用户su: 即 switch user，命令可以切换用户身份，并且以指定用户的身份执行命令格式： 1su [options...] [-] [user [args...]] 常见的选项 12-l --login su -l UserName 相当于 su - UserName-c, --command &lt;command&gt; pass a single command to the shell with -c 切换用户的方式： su UserName：非登录式切换，即不会读取目标用户的配置文件，不改变当前工作目录，即不完全切换 su - UserName：登录式切换，会读取目标用户的配置文件，切换至自已的家目录，即完全切换说明：root su至其他用户无须密码；非root用户切换时需要密码注意：su 切换新用户后，使用 exit 退回至旧的用户身份，而不要再用 su 切换至旧用户，否则会生成很多的bash子进程，环境可能会混乱。 换个身份执行命令： 1su - username -c &#x27;command&#x27; 范例： 123456789101112131415161718[root@rocky8 skel]# su - test -c &#x27;touch test.log&#x27;[root@rocky8 skel]# su test[test@rocky8 skel]$ lltotal 0[test@rocky8 skel]$ ls -a. .. .bash_logout .bash_profile .bashrc[test@rocky8 skel]$ cd /home/[test@rocky8 home]$ lltotal 0drwx------. 2 test test 99 Jul 24 11:38 testdrwx------. 2 test1 test1 78 Jul 24 11:24 test1drwx------. 2 yuankun yuankun 114 Jul 23 08:24 yuankun[test@rocky8 home]$ cd test[test@rocky8 ~]$ lltotal 0-rw-rw-r--. 1 test test 0 Jul 24 11:38 test.log[test@rocky8 ~]$ 7.5.8设置密码passwd 可以修改用户密码 格式： 1passwd [options] username 常见选项： 12345678910-d：删除指定用户密码-l：锁定指定用户-u：解锁指定用户-e：强制用户下次登录修改密码-f：强制操作-n mindays：指定最短使用期限-x maxdays：最大使用期限-w warndays：提前多少天开始警告-i inactivedays：非活动期限--stdin：从标准输入接收用户密码,Ubuntu无此选项 范例：非交互式修改用户密码 12345678910#此方式更通用，适用于各种Linux版本，如:ubunturoot@ununtu2004:/home# echo -e &#x27;123456\\n123456&#x27; | passwd testNew password: Retype new password: passwd: password updated successfullyroot@ununtu2004:/home# #适用于红帽系列的Linux版本[root@rocky8 home]# echo -e &#x27;123456&#x27;| passwd --stdin testChanging password for user test.passwd: all authentication tokens updated successfully.[root@rocky8 home]# 7.6文件权限管理7.6.1文件所有者和属组属性操作7.6.1.1设置文件的所有者chownchown 命令可以修改文件的属主，也可以修改文件属组格式： 12chown [OPTION]... [OWNER][:[GROUP]] FILE...chown [OPTION]... --reference=RFILE FILE... 用法说明： 12345OWNER #只修改所有者OWNER:GROUP #同时修改所有者和属组:GROUP #只修改属组，冒号也可用 . 替换--reference=RFILE #参考指定的的属性，来修改-R #递归，此选项慎用，非常危险！ 范例： 修改所有者 1234567891011121314151617[root@rocky8 home]# touch data.log[root@rocky8 home]# ll # data.log所有者为roottotal 0-rw-r--r--. 1 root root 0 Jul 24 13:16 data.logdrwx------. 2 gentoo gentoo 62 Jul 24 12:39 gentoodrwx------. 2 test test 99 Jul 24 11:38 testdrwx------. 2 test1 test1 78 Jul 24 11:24 test1drwx------. 2 yuankun yuankun 114 Jul 23 08:24 yuankun[root@rocky8 home]# chown yuankun data.log # 修改所有者为yuankun[root@rocky8 home]# lltotal 0-rw-r--r--. 1 yuankun root 0 Jul 24 13:16 data.logdrwx------. 2 gentoo gentoo 62 Jul 24 12:39 gentoodrwx------. 2 test test 99 Jul 24 11:38 testdrwx------. 2 test1 test1 78 Jul 24 11:24 test1drwx------. 2 yuankun yuankun 114 Jul 23 08:24 yuankun[root@rocky8 home]# 修改所属组 1chown :bin data.log 同时修改所有者和所属组 12345678910111213[root@rocky8 home]# touch test.log[root@rocky8 home]# [root@rocky8 home]# [root@rocky8 home]# chown yuankun:bin test.log # 冒号用.替换也可以[root@rocky8 home]# lltotal 0-rw-r--r--. 1 yuankun bin 0 Jul 24 13:16 data.logdrwx------. 2 gentoo gentoo 62 Jul 24 12:39 gentoodrwx------. 2 test test 99 Jul 24 11:38 testdrwx------. 2 test1 test1 78 Jul 24 11:24 test1-rw-r--r--. 1 yuankun bin 0 Jul 24 13:22 test.logdrwx------. 2 yuankun yuankun 114 Jul 23 08:24 yuankun[root@rocky8 home]# 修改为参考的所有者户所属组 1chown --reference=root.log data.log 递归修改 1chown -R yuankun:yuankun ./data/mysql/ 7.6.1.2设置文件的属组信息chgrpchgrp 命令可以只修改文件的属组格式: 12chgrp [OPTION]... GROUP FILE...chgrp [OPTION]... --reference=RFILE FILE... -R 递归 范例： 1chgrp yuankun data.log 7.6.2文件权限每个文件针对每类访问者都定义了三种权限 123r Readable 4w Writable 2x eXcutable 1 对文件的权限 123456789r 可使用文件查看类工具，比如：cat，可以获取其内容w 可修改其内容,文件的是否被删除和文件的权限无关x 可以把此文件提请内核启动为一个进程，即可以执行（运行）此文件（此文件的内容必须是可执行）文件权限常见组合--- 0r 4r-x 5rw 6rwx 7 对目录的权限 12345678910r 可以使用ls查看此目录中文件名列表,但无法看到文件的属性meta信息,包括inode号,不能查看文件的内容w 可在此目录中创建文件，也可删除此目录中的文件，而和此被删除的文件的权限无关x 可以cd进入此目录，可以使用ls -l file或stat file 查看此目录中指定文件的元数据，当预先知道文件名称时,也可以查看文件的内容,属于目录的可访问的最小权限X 分配给目录或有部分x权限的文件的x权限，对无任意x权限的文件则不会分配x权限目录权限常见组合- 不能访问目录r-x 只读目录rwx 可读也可写目录 面试题：Linux中的目录和文件的权限区别？分别说明读，写和执行权限的区别? 修改文件权限chmod 面试题：执行 cp &#x2F;etc&#x2F;issue &#x2F;data&#x2F;dir&#x2F; 所需要的最小权限？","categories":[],"tags":[{"name":"Linux从入门到放弃","slug":"Linux从入门到放弃","permalink":"http://snippet.itshare.work/tags/Linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83/"}],"keywords":[]},{"title":"linux基础和常用命令","slug":"linux基础和常用命令","date":"2022-07-18T13:12:03.000Z","updated":"2022-12-16T14:58:08.468Z","comments":true,"path":"2022/07/18/linux基础和常用命令/","link":"","permalink":"http://snippet.itshare.work/2022/07/18/linux%E5%9F%BA%E7%A1%80%E5%92%8C%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"Linux 是一套免费使用、开源的类 Unix 操作系统。 Linux 存在着许多不同的发行版本，但它们都使用了 Linux 内核 。","text":"1.冯诺依曼体系1946年美籍匈牙利数学家冯·诺依曼于提出存储程序原理，把程序本身当作数据来对待，程序和该程序处理的数据用同样的方式储存。 冯·诺依曼体系的要点是： 数字计算机的数制采用二进制，bit 位, byte 字节 1 byte &#x3D;8 bit 计算机应该按照程序顺序执行 计算机硬件由运算器、控制器、存储器、输入设备和输出设备五大部分组成 计算机的硬件五个组件 控制器: 指挥系统 运算器: 数学和逻辑运算 存储器: 存储信息 输入设备: 接收外部信息 输出设备: 输出计算机内部信息到外部设备 2.服务器按外观类型分类PC服务器常见的三种外观 塔式服务器 刀片式服务器 机架式服务器 3.操作系统和Linux安装**操作系统的作用 ** **主要作用 ** 硬件驱动 进程管理 内存管理 网络管理 安全管理 文件管理 **unix哲学思想 ** 一切都是一个文件(包括硬件) 小型，单一用途的程序 链接程序，共同完成复杂的任务(shell脚本) 避免令人困惑的用户界面 配置数据存储在文本中 4.常见面试题 5 .基础使用命令5.1 查看网络ip地址1ip a 5.2 重启1reboot 5.3 ubuntu roo账户进行远程登录修改方法 切换到root账户 1sudo -i 设置密码 1passwd 用户名 修改&#x2F;etc&#x2F;ssh&#x2F;sshd_config ,PermitRootlogin yes 重启sshd 1systemctl restart sshd 5.4 查看当前所在终端1tty 5.5 查看当前账户12345whoamiwho am i who 5.6 查看当前时间1date 5.7 修改时区 ,修改为北京时间12timedatectl set-timezone Asia/Shanghaidate # 查看当前时间 5.8 查看当前系统使用的shell 5.9 查看当前主机名1hostname 5.10修改当前主机名称，永久修改1hostnamectl set-hostname 名称 12# 临时修改，重启后变为修改前的主机名称hostname 主机名 5.11 查看所有内部命令1help 5.12 查看命令为内部还是外部命令123type 命令名称# 示例type cd 5.13 查看系统中所有别名1alias 5.14 设置别名123alias 别名名称 = &#x27;被设置别名的行为&#x27;# 示例alias cdnt = &#x27;cd /root&#x27; 5.15 删除别名1unalisa 别名名称 命令种类 alias(优先级最高) 内部命令(优先级低于alias) 外部命令(优先级最低) whatis whatis使用数据库来显示命令的简短描述 此工具在系统刚安装后不可立即使用，需要制作数据库后才可使用 执行下面的命令生成数据库 1234# centos7版本以后mandb# centos6版本之前makewhatis 5.16 内部命令查看帮助12# 使用type命令查看是否为内部命令，不是内部命令不能使用该命令help history 范例 5.17 外部命令使用帮助COMMAND –help 或者 COMMAND -h 范例 1date --help 5.18 man12man dateman 1 date 6.查看硬件信息6.1查看CPU信息1lscpu 12# 该命令也可以cat /proc/cpuinfo 6.2 查看内存信息123free -h# 或者cat /proc/meminfo 6.3 查看硬盘信息和分区情况1lsblk 7.查看系统信息7.1 查看系统架构1arch 7.2 查看内核版本1uname -r 7.3 查看操作系统发行版本1cat /etc/os-releases 1cat /etc/issue 7.4 修改登录后显示的内容12# 修改/etc/motd文件内容vi /etc/motd 7.5 查看硬件时间1clock 7.6重启和关机7.6.1重启 halt reboot 7.6.2 关机或重启12345678shutdown - r :重启- h :关机指定时间关机或重启shutdown -r 15:00 # 15:00重启shutdown -h 15:00 # 15:00关机shutdown -c # 取消","categories":[],"tags":[],"keywords":[]},{"title":"看完这篇还敢说你不会git生成ssh密钥","slug":"git-ssh","date":"2022-07-13T12:52:38.000Z","updated":"2022-12-16T14:57:47.995Z","comments":true,"path":"2022/07/13/git-ssh/","link":"","permalink":"http://snippet.itshare.work/2022/07/13/git-ssh/","excerpt":"我是一名软件测试工程师，工作中经常用到git。看完这篇掌握Git生成密钥(ssh)","text":"注：以下命令全部在git bash完成 1.查看是否配置邮箱和用户名1git config --global --list 如图所示，则代表已经配置完成 2.配置用户名和邮箱12git config --global user.name &quot;这里换上你的用户名&quot;git config --global user.email &quot;这里换上你的邮箱&quot; 3.查看是否已经生成密钥12cd ~/.sshls -a 如图所示，代表已经生成密钥 id_rsa文件是私钥，要保存好，放在本地，私钥可以生产公钥，反之不行。 id_rsa.pub文件是公钥，可以用于发送到其他服务器，或者git上 4.生成密钥 执行ssh-keygen -t rsa -c 1ssh-keygen -t rsa -c &quot;这是你的邮箱&quot; 点击enter,输入密码 点击enter，确认密码 如图，创建成功","categories":[],"tags":[],"keywords":[]},{"title":"Fluid主题如何添加按钮和标签","slug":"Fluid_hexo_server","date":"2022-07-08T13:47:30.000Z","updated":"2022-11-12T15:35:27.557Z","comments":true,"path":"2022/07/08/Fluid_hexo_server/","link":"","permalink":"http://snippet.itshare.work/2022/07/08/Fluid_hexo_server/","excerpt":"详细描述了hexo添加button的使用教程","text":"1.hexo添加Button方法你可以在 markdown 中加入如下的代码来使用 Button： 1&#123;% btn url, text, title %&#125; 或者使用 HTML 形式： 1&lt;a class=&quot;btn&quot; href=&quot;url&quot; title=&quot;title&quot;&gt;text&lt;/a&gt; url：跳转链接text：显示的文字title：鼠标悬停时显示的文字（可选） 1&lt;p class=&quot;note note-primary&quot;&gt;长河落日袁先生&lt;/p&gt; 长河落日袁先生 12&lt;p class=&quot;note note-success&quot;&gt;success&lt;/p&gt; success","categories":[],"tags":[],"keywords":[]}]}